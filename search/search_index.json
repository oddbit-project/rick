{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Rick","text":"<p>Rick is a comprehensive plumbing library for building microframework-based Python applications. It provides essential building blocks and utilities for constructing robust, maintainable applications without imposing architectural constraints.</p> <p>What Rick Is: - A collection of battle-tested utilities and components - Foundation for building custom frameworks and applications - Lightweight and modular with minimal dependencies - Python 3.10+ compatible</p> <p>What Rick Is Not: - Not a web framework (no HTTP/WSGI/ASGI functionality) - Not a database ORM (use RickDb for database operations) - Not opinionated about application structure</p>"},{"location":"#core-philosophy","title":"Core Philosophy","text":"<p>Rick follows these principles:</p> <ol> <li>Modularity - Use only what you need</li> <li>Simplicity - Clear, straightforward APIs</li> <li>Flexibility - Adapt to your architecture, not the other way around</li> <li>Reliability - Comprehensive test coverage and type support</li> <li>Performance - Efficient implementations with minimal overhead</li> </ol>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>pip install rick\n</code></pre>"},{"location":"#basic-example","title":"Basic Example","text":"<pre><code>from rick.base import Di\nfrom rick.form import RequestRecord, Field\nfrom rick.resource.config import EnvironmentConfig\nfrom rick.resource.redis import RedisCache\n# Dependency Injection\ndi = Di()\ndi.add('cache', RedisCache(host='localhost'))\ncache = di.get('cache')\n# Form Validation\nclass UserForm(RequestRecord):\ndef __init__(self):\nsuper().__init__()\nself.field('email', validators='required|email')\nself.field('password', validators='required|minlen:8')\nform = UserForm()\nif form.is_valid({'email': 'user@example.com', 'password': 'secret123'}):\nprint(\"Valid!\")\n# Configuration\nclass AppConfig(EnvironmentConfig):\nDB_HOST = 'localhost'\nDB_PORT = 5432\nDEBUG = False\nconfig = AppConfig().build()\n</code></pre>"},{"location":"#components","title":"Components","text":""},{"location":"#core-components","title":"Core Components","text":""},{"location":"#base-classes","title":"Base Classes","text":"<ul> <li>Dependency Injection (Di) - Service container with singleton and factory patterns</li> <li>Container Classes - Immutable and mutable data containers</li> <li>Registry - Thread-safe class registration and retrieval</li> <li>MapLoader - Dynamic class loading and instantiation</li> </ul>"},{"location":"#forms-and-validation","title":"Forms and Validation","text":"<ul> <li>RequestRecord - Request validation with nested record support</li> <li>Form - Full-featured forms with fieldsets and controls</li> <li>Field - Field definitions with validators and filters</li> <li>30+ Validators - Email, IP, UUID, numeric, string validators</li> <li>Filters - Input transformation and sanitization</li> </ul>"},{"location":"#serialization","title":"Serialization","text":""},{"location":"#serializers","title":"Serializers","text":"<ul> <li>JSON Serializer - Extended JSON encoding with Python type support</li> <li>ExtendedJsonEncoder for standard serialization</li> <li>CamelCaseJsonEncoder for JavaScript compatibility</li> <li>Supports datetime, Decimal, UUID, dataclasses</li> <li>MessagePack Serializer - Binary serialization with full type preservation</li> <li>Bidirectional encoding/decoding</li> <li>30-50% smaller than JSON</li> <li>2-4x faster serialization</li> <li>Full support for custom objects and dataclasses</li> </ul>"},{"location":"#resources","title":"Resources","text":""},{"location":"#configuration-management","title":"Configuration Management","text":"<ul> <li>EnvironmentConfig - Environment variable loading with type conversion</li> <li>JsonFileConfig - JSON configuration files</li> <li>TomlFileConfig - TOML configuration files</li> <li>HybridFileConfig - Auto-detect JSON or TOML</li> <li>Custom validation functions</li> <li>StrOrFile wrapper for loading secrets from files</li> </ul>"},{"location":"#caching","title":"Caching","text":"<ul> <li>RedisCache - Redis caching with pickle serialization</li> <li>CryptRedisCache - Encrypted Redis cache with Fernet256</li> <li>Custom serialization support (pickle, JSON, MessagePack)</li> <li>Key prefixing for namespace isolation</li> <li>TTL support for automatic expiration</li> <li>Full Redis client access for advanced operations</li> </ul>"},{"location":"#console-output","title":"Console Output","text":"<ul> <li>AnsiColor - ANSI color formatting with 16 colors</li> <li>ConsoleWriter - High-level console writer</li> <li>Semantic output methods (success, error, warning, header)</li> <li>Text attributes (bold, dim, underline, reversed)</li> <li>Separate stdout and stderr streams</li> </ul>"},{"location":"#other-resources","title":"Other Resources","text":"<ul> <li>Event Manager - Event dispatching and handling</li> <li>Stream Processing - MultiPartReader for multipart/form-data</li> <li>File Operations - File handling utilities</li> </ul>"},{"location":"#security-and-cryptography","title":"Security and Cryptography","text":""},{"location":"#crypto","title":"Crypto","text":"<ul> <li>Fernet256 - 256-bit encryption (adapted from cryptography library)</li> <li>MultiFernet256 - Multi-key encryption support</li> <li>BCrypt - Password hashing</li> <li>Buffer Utilities - Hash functions (SHA1, SHA256, SHA512)</li> </ul>"},{"location":"#mixins","title":"Mixins","text":"<ul> <li>Injectable - Dependency injection integration</li> <li>Runnable - Runnable interface for services</li> <li>Translator - Internationalization and localization support</li> </ul>"},{"location":"#feature-highlights","title":"Feature Highlights","text":""},{"location":"#dependency-injection","title":"Dependency Injection","text":"<pre><code>from rick.base import Di\n# Create DI container\ndi = Di()\n# Register singleton\ndi.add('config', config_instance)\n# Register factory\ndef create_logger(di_instance):\nreturn {'name': 'logger'}\ndi.add('logger', create_logger)\n# Retrieve services\nconfig = di.get('config')\nlogger = di.get('logger')\n</code></pre>"},{"location":"#form-validation","title":"Form Validation","text":"<pre><code>from rick.form import RequestRecord\nclass RegistrationForm(RequestRecord):\ndef __init__(self):\nsuper().__init__()\nself.field('username', validators='required|alphanum|minlen:3')\nself.field('email', validators='required|email')\nself.field('password', validators='required|minlen:8')\nself.field('age', validators='required|int|between:18,120')\ndef validate_username(self, data, field):\n# Custom validation\nif data['username'] in ['admin', 'root']:\nself.add_error('username', 'Username not allowed')\nreturn False\nreturn True\nform = RegistrationForm()\nif form.is_valid(request_data):\n# Process valid data\nuser_data = form.get_data()\nelse:\n# Handle errors\nerrors = form.get_errors()\n</code></pre>"},{"location":"#configuration-management_1","title":"Configuration Management","text":"<pre><code>from rick.resource.config import EnvironmentConfig, StrOrFile\nclass ProductionConfig(EnvironmentConfig):\n# Database settings\nDB_HOST = 'localhost'\nDB_PORT = 5432\nDB_PASSWORD = StrOrFile(None)  # Load from file\n# Application settings\nDEBUG = False\nSECRET_KEY = StrOrFile(None)\nMAX_WORKERS = 4\ndef validate_database(self, data: dict):\n\"\"\"Ensure database is properly configured\"\"\"\nif not data.get('db_host'):\nraise ValueError(\"Database host is required\")\n# Environment variables override defaults\n# export DB_HOST=production-server\n# export DB_PASSWORD=/secrets/db-password.txt\nconfig = ProductionConfig().build()\n</code></pre>"},{"location":"#redis-caching","title":"Redis Caching","text":"<pre><code>from rick.resource.redis import RedisCache, CryptRedisCache\nfrom rick.serializer.msgpack import msgpack\n# Standard cache with MessagePack\ncache = RedisCache(\nhost='localhost',\nserializer=msgpack.packb,\ndeserializer=msgpack.unpackb,\nprefix='myapp:'\n)\ncache.set('user:123', user_data, ttl=3600)\nuser = cache.get('user:123')\n# Encrypted cache for sensitive data\nsecure_cache = CryptRedisCache(\nkey='your-64-character-encryption-key-here-must-be-exactly-64ch',\nhost='localhost'\n)\nsecure_cache.set('api_token', {'token': 'secret123'})\n</code></pre>"},{"location":"#serialization_1","title":"Serialization","text":"<pre><code>from rick.serializer.json.json import ExtendedJsonEncoder, CamelCaseJsonEncoder\nfrom rick.serializer.msgpack import msgpack\nimport json\nfrom datetime import datetime\nfrom decimal import Decimal\n# JSON serialization\ndata = {\n'timestamp': datetime.now(),\n'amount': Decimal('123.45'),\n'status': 'active'\n}\n# Standard JSON\njson_str = json.dumps(data, cls=ExtendedJsonEncoder)\n# CamelCase for JavaScript\njson_str = json.dumps(data, cls=CamelCaseJsonEncoder)\n# MessagePack - faster and smaller\npacked = msgpack.packb(data)\nrestored = msgpack.unpackb(packed)  # Full type preservation\n</code></pre>"},{"location":"#console-output_1","title":"Console Output","text":"<pre><code>from rick.resource.console import ConsoleWriter, AnsiColor\n# High-level semantic output\nconsole = ConsoleWriter()\nconsole.header('Application Startup')\nconsole.success('Database connected')\nconsole.warn('Cache disabled')\nconsole.error('Plugin failed to load')\n# Low-level color formatting\ncolor = AnsiColor()\nprint(color.red('Error:', attr='bold') + ' Operation failed')\nprint(color.green('Success', 'white', ['bold', 'underline']))\n</code></pre>"},{"location":"#architecture-pattern","title":"Architecture Pattern","text":"<p>Rick follows a modular architecture where each component is independent:</p> <pre><code>rick/\n\u251c\u2500\u2500 base/          # DI, Registry, Containers\n\u251c\u2500\u2500 form/          # Forms and RequestRecord\n\u251c\u2500\u2500 validator/     # Validation rules\n\u251c\u2500\u2500 filter/        # Input filters\n\u251c\u2500\u2500 serializer/    # JSON and MessagePack\n\u251c\u2500\u2500 resource/      # External resources\n\u2502   \u251c\u2500\u2500 config/    # Configuration loaders\n\u2502   \u251c\u2500\u2500 redis/     # Redis caching\n\u2502   \u251c\u2500\u2500 console/   # Console output\n\u2502   \u2514\u2500\u2500 stream/    # Stream processing\n\u251c\u2500\u2500 crypto/        # Encryption utilities\n\u251c\u2500\u2500 event/         # Event system\n\u251c\u2500\u2500 mixin/         # Reusable mixins\n\u2514\u2500\u2500 util/          # General utilities\n</code></pre>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Forms - Form handling and request validation</li> <li>Validators - Available validation rules</li> <li>Serializers - JSON and MessagePack serialization</li> <li>Resources - Caching, configuration, console, and more</li> <li>Mixins - Translation and other mixins</li> </ul>"},{"location":"#related-projects","title":"Related Projects","text":"<ul> <li>RickDb - Database abstraction layer</li> <li>Flask - Web framework (recommended for HTTP functionality)</li> </ul> <p>Rick is released under an open-source license. See the LICENSE file for details.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li>Request Validation - Validate incoming requests</li> <li>Configuration Management - Load and validate configuration</li> <li>Redis Caching - Implement caching strategies</li> <li>Serialization - Efficient data encoding</li> <li>Console Output - Build beautiful CLI applications</li> </ol>"},{"location":"crypto/","title":"Cryptography","text":"<p>Rick provides cryptographic utilities for encryption, hashing, and password management. The crypto module offers secure implementations for common cryptographic operations without the complexity of using cryptography libraries directly.</p>"},{"location":"crypto/#overview","title":"Overview","text":"<p>The crypto module includes:</p> <ul> <li>Fernet256 - Symmetric encryption using AES-256 with HMAC authentication</li> <li>MultiFernet256 - Multi-key encryption support for key rotation</li> <li>BcryptHasher - Secure password hashing with bcrypt</li> <li>Buffer Hashing - SHA-1, SHA-256, SHA-512, and BLAKE2 hash utilities</li> </ul>"},{"location":"crypto/#components","title":"Components","text":""},{"location":"crypto/#encryption","title":"Encryption","text":"<p>Rick provides Fernet256, a 256-bit encryption implementation based on the Fernet specification:</p> <ul> <li>Fernet256 - Symmetric encryption with AES-256-CBC</li> <li>MultiFernet256 - Multi-key support for key rotation</li> <li>Authenticated encryption (encrypt-then-MAC)</li> <li>Built-in timestamp verification</li> <li>TTL (time-to-live) support</li> </ul>"},{"location":"crypto/#password-hashing","title":"Password Hashing","text":"<p>Secure password hashing using bcrypt:</p> <ul> <li>BcryptHasher - Password hashing and verification</li> <li>Configurable rounds (work factor)</li> <li>Automatic salt generation</li> <li>Constant-time comparison</li> <li>Rehash detection for security upgrades</li> </ul>"},{"location":"crypto/#hash-utilities","title":"Hash Utilities","text":"<p>Buffer hashing utilities for files and streams:</p> <ul> <li>Buffer Hashing - SHA-1, SHA-256, SHA-512, BLAKE2</li> <li>Stream-based hashing</li> <li>Support for BytesIO objects</li> <li>Hexadecimal digest output</li> </ul>"},{"location":"crypto/#quick-examples","title":"Quick Examples","text":""},{"location":"crypto/#encryption-with-fernet256","title":"Encryption with Fernet256","text":"<pre><code>from rick.crypto import Fernet256\n# Generate a key\nkey = Fernet256.generate_key()\n# Create cipher\ncipher = Fernet256(key)\n# Encrypt data\nplaintext = b\"Secret message\"\ntoken = cipher.encrypt(plaintext)\n# Decrypt data\ndecrypted = cipher.decrypt(token)\nassert decrypted == plaintext\n</code></pre>"},{"location":"crypto/#password-hashing-with-bcrypt","title":"Password Hashing with Bcrypt","text":"<pre><code>from rick.crypto import BcryptHasher\nhasher = BcryptHasher(rounds=12)\n# Hash a password\npassword = \"user_password_123\"\npw_hash = hasher.hash(password)\n# Verify password\nis_valid = hasher.is_valid(password, pw_hash)\nassert is_valid is True\n# Check if rehash needed (for security upgrades)\nif hasher.need_rehash(pw_hash):\nnew_hash = hasher.hash(password)\n</code></pre>"},{"location":"crypto/#buffer-hashing","title":"Buffer Hashing","text":"<pre><code>from rick.crypto import sha256_hash, sha512_hash\nfrom io import BytesIO\ndata = BytesIO(b\"Data to hash\")\n# SHA-256\nhash_256 = sha256_hash(data)\n# SHA-512\nhash_512 = sha512_hash(data)\n</code></pre>"},{"location":"crypto/#use-cases","title":"Use Cases","text":""},{"location":"crypto/#secure-data-storage","title":"Secure Data Storage","text":"<pre><code>from rick.crypto import Fernet256\nfrom rick.resource.redis import CryptRedisCache\n# Use Fernet256 with encrypted Redis cache\nkey = Fernet256.generate_key()\ncache = CryptRedisCache(\nkey=key.decode('utf-8'),\nhost='localhost'\n)\n# Store sensitive data\ncache.set('api_token', {'token': 'secret_key_123'})\n</code></pre>"},{"location":"crypto/#password-management","title":"Password Management","text":"<pre><code>from rick.crypto import BcryptHasher\nhasher = BcryptHasher(rounds=12)\n# User registration\ndef register_user(username, password):\npw_hash = hasher.hash(password)\n# Store username and pw_hash in database\nreturn pw_hash\n# User login\ndef login_user(username, password, stored_hash):\nif hasher.is_valid(password, stored_hash):\n# Check if hash needs upgrade\nif hasher.need_rehash(stored_hash):\nnew_hash = hasher.hash(password)\n# Update database with new_hash\nreturn True\nreturn False\n</code></pre>"},{"location":"crypto/#file-integrity-verification","title":"File Integrity Verification","text":"<pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\ndef verify_file(file_path, expected_hash):\nwith open(file_path, 'rb') as f:\nbuffer = BytesIO(f.read())\ncomputed_hash = sha256_hash(buffer)\nreturn computed_hash == expected_hash\n</code></pre>"},{"location":"crypto/#security-considerations","title":"Security Considerations","text":""},{"location":"crypto/#encryption_1","title":"Encryption","text":"<ul> <li>Key Management: Store encryption keys securely (environment variables, key vaults)</li> <li>Key Rotation: Use MultiFernet256 for zero-downtime key rotation</li> <li>TTL: Set appropriate TTL values for time-sensitive data</li> <li>Transport: Always use encrypted transport (TLS) in addition to encryption at rest</li> </ul>"},{"location":"crypto/#password-hashing_1","title":"Password Hashing","text":"<ul> <li>Rounds: Use at least 12 rounds for bcrypt (default)</li> <li>Rehashing: Regularly check and upgrade hashes as computational power increases</li> <li>Timing: The implementation uses constant-time comparison to prevent timing attacks</li> <li>No Plain Text: Never log or store passwords in plain text</li> </ul>"},{"location":"crypto/#hash-functions","title":"Hash Functions","text":"<ul> <li>SHA-1: Considered weak for cryptographic purposes, use SHA-256 or higher</li> <li>SHA-256: Suitable for general cryptographic hashing</li> <li>SHA-512: Recommended for high-security applications</li> <li>BLAKE2: Modern, fast alternative to SHA-2 family</li> </ul>"},{"location":"crypto/#best-practices","title":"Best Practices","text":""},{"location":"crypto/#key-generation","title":"Key Generation","text":"<pre><code>from rick.crypto import Fernet256\n# Generate key securely\nkey = Fernet256.generate_key()\n# Store in environment variable or key vault\n# NEVER hard-code keys in source code\nimport os\nos.environ['ENCRYPTION_KEY'] = key.decode('utf-8')\n</code></pre>"},{"location":"crypto/#password-policy","title":"Password Policy","text":"<pre><code>from rick.crypto import BcryptHasher\nclass PasswordPolicy:\ndef __init__(self):\n# Higher rounds = more secure but slower\n# Adjust based on your security requirements\nself.hasher = BcryptHasher(rounds=12)\ndef is_strong(self, password):\n\"\"\"Validate password strength\"\"\"\nif len(password) &lt; 8:\nreturn False\nif not any(c.isupper() for c in password):\nreturn False\nif not any(c.isdigit() for c in password):\nreturn False\nreturn True\ndef hash_password(self, password):\nif not self.is_strong(password):\nraise ValueError(\"Password does not meet requirements\")\nreturn self.hasher.hash(password)\n</code></pre>"},{"location":"crypto/#key-rotation-with-multifernet","title":"Key Rotation with MultiFernet","text":"<pre><code>from rick.crypto import Fernet256, MultiFernet256\n# Current key\nkey_new = Fernet256.generate_key()\n# Previous key (for decryption)\nkey_old = b'old_key_here...'\n# Create multi-fernet with both keys\ncipher = MultiFernet256([\nFernet256(key_new),  # Primary key (for encryption)\nFernet256(key_old),  # Old key (for decryption only)\n])\n# Decrypt with either key, encrypt with new key\ntoken = cipher.encrypt(b\"data\")\n# Rotate old encrypted data to new key\nold_token = b\"encrypted_with_old_key\"\nnew_token = cipher.rotate(old_token)\n</code></pre>"},{"location":"crypto/#documentation-sections","title":"Documentation Sections","text":"<ul> <li>Fernet256 - Symmetric encryption documentation</li> <li>BcryptHasher - Password hashing documentation</li> <li>Buffer Hashing - Hash utilities documentation</li> </ul>"},{"location":"crypto/#related-components","title":"Related Components","text":"<ul> <li>CryptRedisCache - Encrypted Redis cache using Fernet256</li> <li>EnvironmentConfig - Secure configuration with StrOrFile</li> </ul>"},{"location":"crypto/#external-dependencies","title":"External Dependencies","text":"<p>The crypto module relies on:</p> <ul> <li>cryptography - Low-level cryptographic primitives</li> <li>bcrypt - Password hashing library</li> </ul> <p>These are automatically installed when you install Rick.</p>"},{"location":"crypto/#standards-compliance","title":"Standards Compliance","text":"<ul> <li>Fernet256: Based on Fernet specification with 256-bit keys</li> <li>Bcrypt: Standard bcrypt algorithm with configurable work factor</li> <li>SHA: NIST standard hash functions (SHA-1, SHA-256, SHA-512)</li> <li>BLAKE2: RFC 7693 compliant</li> </ul>"},{"location":"crypto/bcrypt/","title":"BcryptHasher","text":"<p>BcryptHasher provides secure password hashing using the bcrypt algorithm with configurable work factor (rounds). It includes automatic salt generation, constant-time comparison, and rehash detection for security upgrades.</p>"},{"location":"crypto/bcrypt/#overview","title":"Overview","text":"<p>Bcrypt is specifically designed for password hashing with these features:</p> <ul> <li>Adaptive cost - Configurable work factor that can increase as hardware improves</li> <li>Automatic salt - Random salt generated for each password</li> <li>Slow by design - Intentionally slow to resist brute-force attacks</li> <li>Timing-safe comparison - Prevents timing attacks during verification</li> </ul>"},{"location":"crypto/bcrypt/#basic-usage","title":"Basic Usage","text":""},{"location":"crypto/bcrypt/#hashing-passwords","title":"Hashing Passwords","text":"<pre><code>from rick.crypto import BcryptHasher\nhasher = BcryptHasher(rounds=12)\n# Hash a password\npassword = \"user_password_123\"\npw_hash = hasher.hash(password)\nprint(pw_hash)\n# Output: $2b$12$randomsalt...hashedpassword\n</code></pre>"},{"location":"crypto/bcrypt/#verifying-passwords","title":"Verifying Passwords","text":"<pre><code>from rick.crypto import BcryptHasher\nhasher = BcryptHasher(rounds=12)\npassword = \"user_password_123\"\npw_hash = hasher.hash(password)\n# Verify correct password\nis_valid = hasher.is_valid(password, pw_hash)\nprint(is_valid)  # True\n# Verify incorrect password\nis_valid = hasher.is_valid(\"wrong_password\", pw_hash)\nprint(is_valid)  # False\n</code></pre>"},{"location":"crypto/bcrypt/#checking-for-rehash","title":"Checking for Rehash","text":"<pre><code>from rick.crypto import BcryptHasher\n# Current hasher with 14 rounds\nhasher = BcryptHasher(rounds=14)\n# Old hash created with 12 rounds\nold_hash = \"$2b$12$...\"\n# Check if rehash is needed\nif hasher.need_rehash(old_hash):\n# Re-hash password with current rounds\nnew_hash = hasher.hash(password)\n# Update database with new_hash\n</code></pre>"},{"location":"crypto/bcrypt/#api-reference","title":"API Reference","text":""},{"location":"crypto/bcrypt/#bcrypthasher-class","title":"BcryptHasher Class","text":""},{"location":"crypto/bcrypt/#__init__roundsnone-prefixnone","title":"<code>__init__(rounds=None, prefix=None)</code>","text":"<p>Initialize a BcryptHasher with specified configuration.</p> <p>Parameters:</p> <ul> <li><code>rounds</code> (int, optional): Number of bcrypt rounds (work factor). Default: 12<ul> <li>Valid range: 4-31</li> <li>Each increment doubles the computation time</li> <li>Recommended minimum: 12</li> </ul> </li> <li><code>prefix</code> (str, optional): Bcrypt prefix/version. Default: \"2b\"<ul> <li>\"2a\": Compatible with most systems</li> <li>\"2b\": Current standard (recommended)</li> <li>\"2y\": PHP compatibility</li> </ul> </li> </ul> <p>Example:</p> <pre><code># Default configuration (12 rounds, 2b prefix)\nhasher = BcryptHasher()\n# Custom configuration\nhasher = BcryptHasher(rounds=14, prefix=\"2b\")\n</code></pre>"},{"location":"crypto/bcrypt/#hashpassword","title":"<code>hash(password)</code>","text":"<p>Hash a password using bcrypt.</p> <p>Parameters:</p> <ul> <li><code>password</code> (str): Cleartext password to hash</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: Bcrypt hash string</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: If password is empty</li> </ul> <p>Example:</p> <pre><code>pw_hash = hasher.hash(\"my_secure_password\")\n</code></pre> <p>Note: The password is first hashed with SHA-256 before bcrypt to handle passwords longer than 72 bytes.</p>"},{"location":"crypto/bcrypt/#is_validpassword-pw_hash","title":"<code>is_valid(password, pw_hash)</code>","text":"<p>Verify a password against a hash.</p> <p>Parameters:</p> <ul> <li><code>password</code> (str): Cleartext password to verify</li> <li><code>pw_hash</code> (str): Bcrypt hash to check against</li> </ul> <p>Returns:</p> <ul> <li><code>bool</code>: True if password matches hash, False otherwise</li> </ul> <p>Example:</p> <pre><code>if hasher.is_valid(user_password, stored_hash):\nprint(\"Password correct\")\nelse:\nprint(\"Invalid password\")\n</code></pre> <p>Security: Uses constant-time comparison to prevent timing attacks.</p>"},{"location":"crypto/bcrypt/#need_rehashpw_hash-prefixnone","title":"<code>need_rehash(pw_hash, prefix=None)</code>","text":"<p>Check if a hash needs to be rehashed with current configuration.</p> <p>Parameters:</p> <ul> <li><code>pw_hash</code> (str): Bcrypt hash to check</li> <li><code>prefix</code> (str, optional): Expected prefix. Default: uses instance prefix</li> </ul> <p>Returns:</p> <ul> <li><code>bool</code>: True if hash uses fewer rounds than current configuration</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: If hash is invalid or malformed</li> </ul> <p>Example:</p> <pre><code>hasher = BcryptHasher(rounds=14)\nold_hash = \"$2b$12$...\"  # Created with 12 rounds\nif hasher.need_rehash(old_hash):\n# Rounds increased from 12 to 14, should rehash\nnew_hash = hasher.hash(password)\n</code></pre>"},{"location":"crypto/bcrypt/#understanding-rounds-work-factor","title":"Understanding Rounds (Work Factor)","text":"<p>The rounds parameter determines how computationally expensive the hashing is:</p> Rounds Time (approx) Security Level 10 ~70ms Minimum acceptable 12 ~280ms Recommended default 14 ~1.1s High security 16 ~4.5s Very high security <pre><code>import time\nfrom rick.crypto import BcryptHasher\n# Test different round values\nfor rounds in [10, 12, 14]:\nhasher = BcryptHasher(rounds=rounds)\nstart = time.time()\nhasher.hash(\"test_password\")\nelapsed = time.time() - start\nprint(f\"Rounds {rounds}: {elapsed:.3f}s\")\n</code></pre>"},{"location":"crypto/bcrypt/#choosing-rounds","title":"Choosing Rounds","text":"<ul> <li>10 rounds: Fast but minimal security (legacy systems)</li> <li>12 rounds: Good balance (recommended for most applications)</li> <li>14 rounds: Higher security (financial/sensitive data)</li> <li>16+ rounds: Maximum security (acceptable UX impact for very sensitive systems)</li> </ul>"},{"location":"crypto/bcrypt/#hash-format","title":"Hash Format","text":"<p>Bcrypt hashes have the following format:</p> <pre><code>$2b$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW\n\u2514\u252c\u2518\u2514\u252c\u2518\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n \u2502  \u2502          Salt               Hash\n \u2502  Rounds\n Prefix\n</code></pre> <p>Components:</p> <ul> <li>Prefix: <code>$2b$</code> - Algorithm version</li> <li>Rounds: <code>12$</code> - Cost factor</li> <li>Salt: 22 characters - Random salt (base64)</li> <li>Hash: 31 characters - Password hash (base64)</li> </ul>"},{"location":"crypto/bcrypt/#complete-authentication-example","title":"Complete Authentication Example","text":"<pre><code>from rick.crypto import BcryptHasher\nclass UserAuthentication:\ndef __init__(self):\nself.hasher = BcryptHasher(rounds=12)\ndef register(self, username, password):\n\"\"\"Register a new user\"\"\"\n# Validate password strength\nif len(password) &lt; 8:\nraise ValueError(\"Password too short\")\n# Hash password\npw_hash = self.hasher.hash(password)\n# Store username and pw_hash in database\nreturn {\n'username': username,\n'password_hash': pw_hash\n}\ndef login(self, username, password, stored_hash):\n\"\"\"Authenticate user login\"\"\"\n# Verify password\nif not self.hasher.is_valid(password, stored_hash):\nreturn None\n# Check if hash needs upgrade\nif self.hasher.need_rehash(stored_hash):\nnew_hash = self.hasher.hash(password)\n# Update database with new_hash\nreturn {\n'authenticated': True,\n'rehash_needed': new_hash\n}\nreturn {\n'authenticated': True,\n'rehash_needed': None\n}\n# Usage\nauth = UserAuthentication()\n# Registration\nuser = auth.register(\"alice\", \"SecureP@ssw0rd!\")\n# Login\nresult = auth.login(\"alice\", \"SecureP@ssw0rd!\", user['password_hash'])\nif result and result['authenticated']:\nif result['rehash_needed']:\n# Update database with new hash\npass\n</code></pre>"},{"location":"crypto/bcrypt/#password-policy-implementation","title":"Password Policy Implementation","text":"<pre><code>from rick.crypto import BcryptHasher\nimport re\nclass PasswordPolicy:\ndef __init__(self, min_length=8, require_upper=True,\nrequire_lower=True, require_digit=True,\nrequire_special=True):\nself.hasher = BcryptHasher(rounds=12)\nself.min_length = min_length\nself.require_upper = require_upper\nself.require_lower = require_lower\nself.require_digit = require_digit\nself.require_special = require_special\ndef validate(self, password):\n\"\"\"Validate password against policy\"\"\"\nerrors = []\nif len(password) &lt; self.min_length:\nerrors.append(f\"Password must be at least {self.min_length} characters\")\nif self.require_upper and not re.search(r'[A-Z]', password):\nerrors.append(\"Password must contain uppercase letter\")\nif self.require_lower and not re.search(r'[a-z]', password):\nerrors.append(\"Password must contain lowercase letter\")\nif self.require_digit and not re.search(r'\\d', password):\nerrors.append(\"Password must contain digit\")\nif self.require_special and not re.search(r'[!@#$%^&amp;*(),.?\":{}|&lt;&gt;]', password):\nerrors.append(\"Password must contain special character\")\nreturn len(errors) == 0, errors\ndef hash_password(self, password):\n\"\"\"Hash password if it meets policy\"\"\"\nis_valid, errors = self.validate(password)\nif not is_valid:\nraise ValueError(\"Password policy violations: \" + \"; \".join(errors))\nreturn self.hasher.hash(password)\n# Usage\npolicy = PasswordPolicy(min_length=10)\ntry:\npw_hash = policy.hash_password(\"MyP@ssw0rd123\")\nprint(\"Password hashed successfully\")\nexcept ValueError as e:\nprint(f\"Error: {e}\")\n</code></pre>"},{"location":"crypto/bcrypt/#migration-from-weaker-hashes","title":"Migration from Weaker Hashes","text":"<p>If migrating from MD5, SHA-1, or other weak hashes:</p> <pre><code>from rick.crypto import BcryptHasher\nimport hashlib\nclass PasswordMigration:\ndef __init__(self):\nself.hasher = BcryptHasher(rounds=12)\ndef is_legacy_hash(self, pw_hash):\n\"\"\"Check if hash is legacy (MD5/SHA)\"\"\"\n# MD5 is 32 hex chars, SHA-1 is 40 hex chars\nreturn len(pw_hash) in [32, 40] and pw_hash.isalnum()\ndef verify_and_upgrade(self, password, stored_hash):\n\"\"\"Verify password and upgrade hash if legacy\"\"\"\nif self.is_legacy_hash(stored_hash):\n# Legacy hash - verify with old method\nmd5_hash = hashlib.md5(password.encode()).hexdigest()\nif md5_hash == stored_hash:\n# Upgrade to bcrypt\nnew_hash = self.hasher.hash(password)\nreturn {\n'valid': True,\n'upgrade_hash': new_hash\n}\nreturn {'valid': False, 'upgrade_hash': None}\nelse:\n# Modern bcrypt hash\nis_valid = self.hasher.is_valid(password, stored_hash)\n# Check if bcrypt needs rehash\nupgrade_hash = None\nif is_valid and self.hasher.need_rehash(stored_hash):\nupgrade_hash = self.hasher.hash(password)\nreturn {\n'valid': is_valid,\n'upgrade_hash': upgrade_hash\n}\n# Usage\nmigration = PasswordMigration()\n# Legacy MD5 hash\nlegacy_hash = \"5f4dcc3b5aa765d61d8327deb882cf99\"  # password: \"password\"\nresult = migration.verify_and_upgrade(\"password\", legacy_hash)\nif result['valid'] and result['upgrade_hash']:\n# Update database with bcrypt hash\nprint(\"Upgraded to bcrypt:\", result['upgrade_hash'])\n</code></pre>"},{"location":"crypto/bcrypt/#timing-attacks","title":"Timing Attacks","text":"<p>BcryptHasher uses <code>hmac.compare_digest()</code> for constant-time comparison:</p> <pre><code># Secure implementation (used internally)\nimport hmac\nreturn hmac.compare_digest(hash1, hash2)\n# Insecure comparison (DON'T use)\nreturn hash1 == hash2  # Vulnerable to timing attacks\n</code></pre>"},{"location":"crypto/bcrypt/#performance-considerations","title":"Performance Considerations","text":""},{"location":"crypto/bcrypt/#login-performance","title":"Login Performance","text":"<pre><code>from rick.crypto import BcryptHasher\nimport time\nhasher = BcryptHasher(rounds=12)\n# Hashing is intentionally slow\nstart = time.time()\npw_hash = hasher.hash(\"password\")\nprint(f\"Hash time: {time.time() - start:.3f}s\")\n# Verification has same cost\nstart = time.time()\nhasher.is_valid(\"password\", pw_hash)\nprint(f\"Verify time: {time.time() - start:.3f}s\")\n</code></pre>"},{"location":"crypto/bcrypt/#error-handling","title":"Error Handling","text":"<pre><code>from rick.crypto import BcryptHasher\nhasher = BcryptHasher(rounds=12)\ntry:\n# Empty password\nhasher.hash(\"\")\nexcept ValueError as e:\nprint(f\"Invalid password: {e}\")\ntry:\n# Invalid hash format\nhasher.need_rehash(\"invalid_hash\")\nexcept ValueError as e:\nprint(f\"Invalid hash: {e}\")\n# Verification never raises (returns False instead)\nis_valid = hasher.is_valid(\"password\", \"malformed_hash\")\nprint(is_valid)  # False\n</code></pre>"},{"location":"crypto/bcrypt/#related","title":"Related","text":"<ul> <li>Fernet256 - Symmetric encryption</li> <li>Buffer Hashing - Hash utilities</li> <li>HasherInterface - Hasher interface</li> </ul>"},{"location":"crypto/bcrypt/#hasherinterface","title":"HasherInterface","text":"<p>BcryptHasher implements the HasherInterface protocol:</p> <pre><code>class HasherInterface:\ndef hash(self, password: str) -&gt; str:\n\"\"\"Hash a password\"\"\"\npass\ndef is_valid(self, password: str, pw_hash: str) -&gt; bool:\n\"\"\"Verify password against hash\"\"\"\npass\ndef need_rehash(self, pw_hash, prefix=None):\n\"\"\"Check if hash needs upgrade\"\"\"\npass\n</code></pre> <p>This allows you to create custom hashers or swap implementations.</p>"},{"location":"crypto/buffer/","title":"Buffer Hashing","text":"<p>Buffer hashing utilities provide convenient functions for computing cryptographic hashes of data streams. These utilities are designed for hashing BytesIO objects, making them ideal for file integrity verification, data validation, and content addressing.</p>"},{"location":"crypto/buffer/#overview","title":"Overview","text":"<p>Rick provides hash utilities for the most common cryptographic hash functions:</p> <ul> <li>SHA-256 - Industry standard for general-purpose hashing</li> <li>SHA-512 - Higher security variant of SHA-2</li> <li>SHA-1 - Legacy support (not recommended for security)</li> <li>BLAKE2 - Modern, fast alternative to SHA-2</li> </ul> <p>All hash functions work with <code>BytesIO</code> objects and return hexadecimal digest strings.</p>"},{"location":"crypto/buffer/#basic-usage","title":"Basic Usage","text":""},{"location":"crypto/buffer/#sha-256-hash","title":"SHA-256 Hash","text":"<pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\n# Hash some data\ndata = BytesIO(b\"Hello, World!\")\nhash_value = sha256_hash(data)\nprint(hash_value)\n# Output: dffd6021bb2bd5b0af676290809ec3a53191dd81c7f70a4b28688a362182986f\n</code></pre>"},{"location":"crypto/buffer/#sha-512-hash","title":"SHA-512 Hash","text":"<pre><code>from rick.crypto import sha512_hash\nfrom io import BytesIO\ndata = BytesIO(b\"Hello, World!\")\nhash_value = sha512_hash(data)\nprint(hash_value)\n# Output: 374d794a95cdcfd8b35993185fef9ba368f160d8daf432d08ba9f1ed1e5abe6c...\n</code></pre>"},{"location":"crypto/buffer/#sha-1-hash","title":"SHA-1 Hash","text":"<pre><code>from rick.crypto import sha1_hash\nfrom io import BytesIO\ndata = BytesIO(b\"Hello, World!\")\nhash_value = sha1_hash(data)\nprint(hash_value)\n# Output: 0a0a9f2a6772942557ab5355d76af442f8f65e01\n</code></pre>"},{"location":"crypto/buffer/#blake2-hash","title":"BLAKE2 Hash","text":"<pre><code>from rick.crypto import blake2_hash\nfrom io import BytesIO\ndata = BytesIO(b\"Hello, World!\")\nhash_value = blake2_hash(data)\nprint(hash_value)\n# Output: 021ced8799296ceca557832ab941a50b4a11f83478cf141f51f933f653ab9fbc...\n</code></pre>"},{"location":"crypto/buffer/#api-reference","title":"API Reference","text":""},{"location":"crypto/buffer/#sha256_hashbuf","title":"<code>sha256_hash(buf)</code>","text":"<p>Compute SHA-256 hash of a buffer.</p> <p>Parameters:</p> <ul> <li><code>buf</code> (BytesIO): Buffer containing data to hash</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: Hexadecimal digest string (64 characters)</li> </ul> <p>Example:</p> <pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\ndata = BytesIO(b\"data to hash\")\ndigest = sha256_hash(data)\n</code></pre> <p>Note: The function automatically seeks to the beginning of the buffer before reading.</p>"},{"location":"crypto/buffer/#sha512_hashbuf","title":"<code>sha512_hash(buf)</code>","text":"<p>Compute SHA-512 hash of a buffer.</p> <p>Parameters:</p> <ul> <li><code>buf</code> (BytesIO): Buffer containing data to hash</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: Hexadecimal digest string (128 characters)</li> </ul> <p>Example:</p> <pre><code>from rick.crypto import sha512_hash\nfrom io import BytesIO\ndata = BytesIO(b\"data to hash\")\ndigest = sha512_hash(data)\n</code></pre>"},{"location":"crypto/buffer/#sha1_hashbuf","title":"<code>sha1_hash(buf)</code>","text":"<p>Compute SHA-1 hash of a buffer.</p> <p>Parameters:</p> <ul> <li><code>buf</code> (BytesIO): Buffer containing data to hash</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: Hexadecimal digest string (40 characters)</li> </ul> <p>Example:</p> <pre><code>from rick.crypto import sha1_hash\nfrom io import BytesIO\ndata = BytesIO(b\"data to hash\")\ndigest = sha1_hash(data)\n</code></pre> <p>Security Warning: SHA-1 is considered cryptographically broken and should not be used for security purposes. Use SHA-256 or higher instead.</p>"},{"location":"crypto/buffer/#blake2_hashbuf","title":"<code>blake2_hash(buf)</code>","text":"<p>Compute BLAKE2b hash of a buffer.</p> <p>Parameters:</p> <ul> <li><code>buf</code> (BytesIO): Buffer containing data to hash</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: Hexadecimal digest string (128 characters)</li> </ul> <p>Example:</p> <pre><code>from rick.crypto import blake2_hash\nfrom io import BytesIO\ndata = BytesIO(b\"data to hash\")\ndigest = blake2_hash(data)\n</code></pre> <p>Note: BLAKE2b is faster than SHA-2 and provides excellent security properties.</p>"},{"location":"crypto/buffer/#hash_buffermethod-buf","title":"<code>hash_buffer(method, buf)</code>","text":"<p>Generic hash function that supports any hashlib algorithm.</p> <p>Parameters:</p> <ul> <li><code>method</code> (str): Name of the hash algorithm (e.g., \"sha256\", \"md5\", \"sha384\")</li> <li><code>buf</code> (BytesIO): Buffer containing data to hash</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: Hexadecimal digest string</li> </ul> <p>Raises:</p> <ul> <li><code>RuntimeError</code>: If the specified method is not available in hashlib</li> </ul> <p>Example:</p> <pre><code>from rick.crypto.buffer import hash_buffer\nfrom io import BytesIO\ndata = BytesIO(b\"data to hash\")\n# Use SHA-256\nsha256 = hash_buffer(\"sha256\", data)\n# Use SHA-384\nsha384 = hash_buffer(\"sha384\", data)\n# Use MD5 (not recommended for security)\nmd5 = hash_buffer(\"md5\", data)\n</code></pre>"},{"location":"crypto/buffer/#file-hashing","title":"File Hashing","text":""},{"location":"crypto/buffer/#hashing-files","title":"Hashing Files","text":"<pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\ndef hash_file(file_path):\n\"\"\"Compute SHA-256 hash of a file\"\"\"\nwith open(file_path, 'rb') as f:\ndata = BytesIO(f.read())\nreturn sha256_hash(data)\n# Hash a file\nfile_hash = hash_file('/path/to/file.txt')\nprint(f\"File hash: {file_hash}\")\n</code></pre>"},{"location":"crypto/buffer/#verifying-file-integrity","title":"Verifying File Integrity","text":"<pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\ndef verify_file(file_path, expected_hash):\n\"\"\"Verify file integrity against expected hash\"\"\"\nwith open(file_path, 'rb') as f:\ndata = BytesIO(f.read())\ncomputed_hash = sha256_hash(data)\nreturn computed_hash == expected_hash\n# Verify a file\nis_valid = verify_file('/path/to/file.txt', 'expected_hash_here')\nif is_valid:\nprint(\"File integrity verified\")\nelse:\nprint(\"File has been modified or corrupted\")\n</code></pre>"},{"location":"crypto/buffer/#hashing-large-files","title":"Hashing Large Files","text":"<p>For large files, read in chunks to avoid memory issues:</p> <pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\nimport hashlib\ndef hash_large_file(file_path, chunk_size=8192):\n\"\"\"Hash large file by reading in chunks\"\"\"\nhasher = hashlib.sha256()\nwith open(file_path, 'rb') as f:\nwhile True:\nchunk = f.read(chunk_size)\nif not chunk:\nbreak\nhasher.update(chunk)\nreturn hasher.hexdigest()\n# Hash large file\nlarge_file_hash = hash_large_file('/path/to/large_file.bin')\n</code></pre>"},{"location":"crypto/buffer/#content-addressing","title":"Content Addressing","text":""},{"location":"crypto/buffer/#creating-content-addressable-storage","title":"Creating Content-Addressable Storage","text":"<pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\nimport os\nclass ContentStore:\ndef __init__(self, storage_dir):\nself.storage_dir = storage_dir\nos.makedirs(storage_dir, exist_ok=True)\ndef store(self, data):\n\"\"\"Store data and return its hash\"\"\"\nbuffer = BytesIO(data)\ncontent_hash = sha256_hash(buffer)\n# Store using hash as filename\nfile_path = os.path.join(self.storage_dir, content_hash)\nwith open(file_path, 'wb') as f:\nf.write(data)\nreturn content_hash\ndef retrieve(self, content_hash):\n\"\"\"Retrieve data by hash\"\"\"\nfile_path = os.path.join(self.storage_dir, content_hash)\nif not os.path.exists(file_path):\nreturn None\nwith open(file_path, 'rb') as f:\nreturn f.read()\n# Usage\nstore = ContentStore('/tmp/content_store')\n# Store data\ndata = b\"Important document content\"\ncontent_id = store.store(data)\nprint(f\"Stored with ID: {content_id}\")\n# Retrieve data\nretrieved = store.retrieve(content_id)\nassert retrieved == data\n</code></pre>"},{"location":"crypto/buffer/#data-validation","title":"Data Validation","text":""},{"location":"crypto/buffer/#checksum-validation","title":"Checksum Validation","text":"<pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\nclass DataValidator:\n@staticmethod\ndef create_checksum(data):\n\"\"\"Create checksum for data\"\"\"\nbuffer = BytesIO(data)\nreturn sha256_hash(buffer)\n@staticmethod\ndef validate(data, checksum):\n\"\"\"Validate data against checksum\"\"\"\ncomputed = DataValidator.create_checksum(data)\nreturn computed == checksum\n# Usage\nvalidator = DataValidator()\n# Create checksum\ndata = b\"Important data\"\nchecksum = validator.create_checksum(data)\n# Later, validate the data\nis_valid = validator.validate(data, checksum)\nif is_valid:\nprint(\"Data is intact\")\nelse:\nprint(\"Data has been corrupted\")\n</code></pre>"},{"location":"crypto/buffer/#download-verification","title":"Download Verification","text":"<pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\nimport urllib.request\ndef download_and_verify(url, expected_hash):\n\"\"\"Download file and verify its hash\"\"\"\n# Download file\nresponse = urllib.request.urlopen(url)\ncontent = response.read()\n# Compute hash\nbuffer = BytesIO(content)\ncomputed_hash = sha256_hash(buffer)\n# Verify\nif computed_hash != expected_hash:\nraise ValueError(f\"Hash mismatch! Expected {expected_hash}, got {computed_hash}\")\nreturn content\n# Download and verify\ntry:\ncontent = download_and_verify(\n'https://example.com/file.bin',\n'expected_sha256_hash_here'\n)\nprint(\"Download verified successfully\")\nexcept ValueError as e:\nprint(f\"Verification failed: {e}\")\n</code></pre>"},{"location":"crypto/buffer/#duplicate-detection","title":"Duplicate Detection","text":""},{"location":"crypto/buffer/#detecting-duplicate-files","title":"Detecting Duplicate Files","text":"<pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\nimport os\ndef find_duplicates(directory):\n\"\"\"Find duplicate files by hash\"\"\"\nhashes = {}\nduplicates = []\nfor root, dirs, files in os.walk(directory):\nfor filename in files:\nfile_path = os.path.join(root, filename)\n# Hash file\nwith open(file_path, 'rb') as f:\nbuffer = BytesIO(f.read())\nfile_hash = sha256_hash(buffer)\n# Check for duplicates\nif file_hash in hashes:\nduplicates.append((file_path, hashes[file_hash]))\nelse:\nhashes[file_hash] = file_path\nreturn duplicates\n# Find duplicates\ndupes = find_duplicates('/path/to/directory')\nfor dup1, dup2 in dupes:\nprint(f\"Duplicate found: {dup1} == {dup2}\")\n</code></pre>"},{"location":"crypto/buffer/#choosing-a-hash-algorithm","title":"Choosing a Hash Algorithm","text":""},{"location":"crypto/buffer/#sha-256","title":"SHA-256","text":"<ul> <li>Best for: General-purpose hashing, file integrity, data validation</li> <li>Output size: 256 bits (64 hex chars)</li> <li>Speed: Fast</li> <li>Security: High (recommended)</li> </ul> <pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\ndata = BytesIO(b\"data\")\nhash_value = sha256_hash(data)  # 64 characters\n</code></pre>"},{"location":"crypto/buffer/#sha-512","title":"SHA-512","text":"<ul> <li>Best for: High-security applications, password derivation</li> <li>Output size: 512 bits (128 hex chars)</li> <li>Speed: Moderate</li> <li>Security: Very high</li> </ul> <pre><code>from rick.crypto import sha512_hash\nfrom io import BytesIO\ndata = BytesIO(b\"data\")\nhash_value = sha512_hash(data)  # 128 characters\n</code></pre>"},{"location":"crypto/buffer/#blake2","title":"BLAKE2","text":"<ul> <li>Best for: High-performance applications, modern systems</li> <li>Output size: 512 bits (128 hex chars)</li> <li>Speed: Very fast (faster than SHA-2)</li> <li>Security: High</li> </ul> <pre><code>from rick.crypto import blake2_hash\nfrom io import BytesIO\ndata = BytesIO(b\"data\")\nhash_value = blake2_hash(data)  # 128 characters\n</code></pre>"},{"location":"crypto/buffer/#sha-1-legacy","title":"SHA-1 (Legacy)","text":"<ul> <li>Best for: Git commit IDs, legacy compatibility only</li> <li>Output size: 160 bits (40 hex chars)</li> <li>Speed: Fast</li> <li>Security: Broken (NOT recommended for security)</li> </ul> <pre><code>from rick.crypto import sha1_hash\nfrom io import BytesIO\ndata = BytesIO(b\"data\")\nhash_value = sha1_hash(data)  # 40 characters\n</code></pre>"},{"location":"crypto/buffer/#performance-comparison","title":"Performance Comparison","text":"<pre><code>from rick.crypto import sha256_hash, sha512_hash, sha1_hash, blake2_hash\nfrom io import BytesIO\nimport time\n# Prepare test data (1 MB)\ntest_data = BytesIO(b\"x\" * (1024 * 1024))\n# Benchmark each algorithm\nalgorithms = [\n(\"SHA-1\", sha1_hash),\n(\"SHA-256\", sha256_hash),\n(\"SHA-512\", sha512_hash),\n(\"BLAKE2\", blake2_hash),\n]\nfor name, hash_func in algorithms:\ntest_data.seek(0)\nstart = time.time()\nhash_value = hash_func(test_data)\nelapsed = time.time() - start\nprint(f\"{name}: {elapsed * 1000:.2f}ms, digest: {hash_value[:16]}...\")\n</code></pre>"},{"location":"crypto/buffer/#common-use-cases","title":"Common Use Cases","text":""},{"location":"crypto/buffer/#database-record-hashing","title":"Database Record Hashing","text":"<pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\nimport json\ndef hash_record(record):\n\"\"\"Create hash of database record\"\"\"\n# Serialize to JSON (deterministic order)\njson_data = json.dumps(record, sort_keys=True)\nbuffer = BytesIO(json_data.encode('utf-8'))\nreturn sha256_hash(buffer)\n# Usage\nrecord = {\n'id': 123,\n'name': 'Alice',\n'email': 'alice@example.com'\n}\nrecord_hash = hash_record(record)\nprint(f\"Record hash: {record_hash}\")\n</code></pre>"},{"location":"crypto/buffer/#api-response-validation","title":"API Response Validation","text":"<pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\nimport json\ndef validate_api_response(response_data, signature):\n\"\"\"Validate API response hasn't been tampered with\"\"\"\nbuffer = BytesIO(json.dumps(response_data, sort_keys=True).encode())\ncomputed_hash = sha256_hash(buffer)\nreturn computed_hash == signature\n# Server side: create signature\nresponse = {'status': 'success', 'data': [1, 2, 3]}\nbuffer = BytesIO(json.dumps(response, sort_keys=True).encode())\nsignature = sha256_hash(buffer)\n# Client side: validate\nis_valid = validate_api_response(response, signature)\n</code></pre>"},{"location":"crypto/buffer/#caching-with-hash-keys","title":"Caching with Hash Keys","text":"<pre><code>from rick.crypto import sha256_hash\nfrom io import BytesIO\nimport json\nclass CacheManager:\ndef __init__(self):\nself.cache = {}\ndef generate_key(self, *args, **kwargs):\n\"\"\"Generate cache key from function arguments\"\"\"\ndata = {\n'args': args,\n'kwargs': kwargs\n}\njson_data = json.dumps(data, sort_keys=True)\nbuffer = BytesIO(json_data.encode('utf-8'))\nreturn sha256_hash(buffer)\ndef get(self, *args, **kwargs):\nkey = self.generate_key(*args, **kwargs)\nreturn self.cache.get(key)\ndef set(self, value, *args, **kwargs):\nkey = self.generate_key(*args, **kwargs)\nself.cache[key] = value\n# Usage\ncache = CacheManager()\n# Cache result\ncache.set('result_data', user_id=123, action='fetch')\n# Retrieve from cache\ncached = cache.get(user_id=123, action='fetch')\n</code></pre>"},{"location":"crypto/buffer/#security-considerations","title":"Security Considerations","text":""},{"location":"crypto/buffer/#hash-function-selection","title":"Hash Function Selection","text":"<ul> <li>SHA-256: Recommended for general use</li> <li>SHA-512: Use for high-security applications</li> <li>BLAKE2: Good alternative to SHA-2, faster</li> <li>SHA-1: Avoid for security purposes (collisions found)</li> </ul>"},{"location":"crypto/buffer/#not-for-passwords","title":"Not for Passwords","text":"<p>Hash functions are NOT suitable for password hashing:</p> <pre><code># DON'T: Use hash functions for passwords\nfrom rick.crypto import sha256_hash\npassword_hash = sha256_hash(BytesIO(password.encode()))  # INSECURE\n# DO: Use BcryptHasher for passwords\nfrom rick.crypto import BcryptHasher\nhasher = BcryptHasher(rounds=12)\npassword_hash = hasher.hash(password)  # SECURE\n</code></pre>"},{"location":"crypto/buffer/#timing-attacks","title":"Timing Attacks","text":"<p>For comparing hashes, use constant-time comparison:</p> <pre><code>import hmac\ndef safe_compare(hash1, hash2):\n\"\"\"Compare hashes safely\"\"\"\nreturn hmac.compare_digest(hash1, hash2)\n# DON'T: Direct comparison (timing attack vulnerability)\nif computed_hash == stored_hash:\npass\n# DO: Constant-time comparison\nif safe_compare(computed_hash, stored_hash):\npass\n</code></pre>"},{"location":"crypto/buffer/#error-handling","title":"Error Handling","text":"<pre><code>from rick.crypto.buffer import hash_buffer\nfrom io import BytesIO\ntry:\n# Invalid hash method\nhash_buffer(\"invalid_method\", BytesIO(b\"data\"))\nexcept RuntimeError as e:\nprint(f\"Invalid hash method: {e}\")\n# Ensure buffer is seekable\ndata = BytesIO(b\"data\")\ntry:\nhash_value = sha256_hash(data)\nexcept Exception as e:\nprint(f\"Error hashing buffer: {e}\")\n</code></pre>"},{"location":"crypto/buffer/#related","title":"Related","text":"<ul> <li>BcryptHasher - Password hashing (use for passwords, not these functions)</li> <li>Fernet256 - Symmetric encryption</li> <li>Redis Cache - Uses hash functions internally</li> </ul>"},{"location":"crypto/buffer/#standards","title":"Standards","text":"<ul> <li>SHA-256: FIPS 180-4 compliant</li> <li>SHA-512: FIPS 180-4 compliant</li> <li>SHA-1: FIPS 180-1 (deprecated for cryptographic use)</li> <li>BLAKE2: RFC 7693 compliant</li> </ul>"},{"location":"crypto/fernet256/","title":"Fernet256","text":"<p>Fernet256 provides symmetric encryption using AES-256-CBC with HMAC-SHA256 authentication. It is based on the Fernet specification but uses 256-bit keys instead of 128-bit.</p>"},{"location":"crypto/fernet256/#overview","title":"Overview","text":"<p>Fernet256 offers authenticated encryption with the following features:</p> <ul> <li>AES-256-CBC encryption for data confidentiality</li> <li>HMAC-SHA256 for data integrity and authentication</li> <li>Timestamp verification to detect token age</li> <li>TTL support for automatic expiration</li> <li>URL-safe encoding for easy storage and transport</li> </ul>"},{"location":"crypto/fernet256/#basic-usage","title":"Basic Usage","text":""},{"location":"crypto/fernet256/#generating-keys","title":"Generating Keys","text":"<pre><code>from rick.crypto import Fernet256\n# Generate a new encryption key\nkey = Fernet256.generate_key()\n# Returns: base64-encoded 64-byte key\n# Save for later use\nprint(key.decode('utf-8'))\n</code></pre>"},{"location":"crypto/fernet256/#encrypting-data","title":"Encrypting Data","text":"<pre><code>from rick.crypto import Fernet256\nkey = Fernet256.generate_key()\ncipher = Fernet256(key)\n# Encrypt data (must be bytes)\nplaintext = b\"Secret message\"\ntoken = cipher.encrypt(plaintext)\nprint(token)  # base64-encoded encrypted token\n</code></pre>"},{"location":"crypto/fernet256/#decrypting-data","title":"Decrypting Data","text":"<pre><code>from rick.crypto import Fernet256\n# Using the same key from encryption\ncipher = Fernet256(key)\n# Decrypt token\ndecrypted = cipher.decrypt(token)\nassert decrypted == b\"Secret message\"\n</code></pre>"},{"location":"crypto/fernet256/#api-reference","title":"API Reference","text":""},{"location":"crypto/fernet256/#fernet256-class","title":"Fernet256 Class","text":""},{"location":"crypto/fernet256/#__init__key-backendnone","title":"<code>__init__(key, backend=None)</code>","text":"<p>Initialize a Fernet256 cipher with the given key.</p> <p>Parameters:</p> <ul> <li><code>key</code> (bytes): Base64-encoded 64-byte encryption key</li> <li><code>backend</code> (optional): Cryptography backend (uses default if not specified)</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: If key is not exactly 64 bytes after base64 decoding</li> </ul> <p>Example:</p> <pre><code>from rick.crypto import Fernet256\nkey = Fernet256.generate_key()\ncipher = Fernet256(key)\n</code></pre>"},{"location":"crypto/fernet256/#generate_key-classmethod","title":"<code>generate_key()</code> (classmethod)","text":"<p>Generate a new random Fernet256 key.</p> <p>Returns:</p> <ul> <li><code>bytes</code>: Base64-encoded 64-byte key suitable for Fernet256</li> </ul> <p>Example:</p> <pre><code>key = Fernet256.generate_key()\n# Save this key securely!\n</code></pre>"},{"location":"crypto/fernet256/#encryptdata","title":"<code>encrypt(data)</code>","text":"<p>Encrypt data and return a Fernet token.</p> <p>Parameters:</p> <ul> <li><code>data</code> (bytes): Plaintext data to encrypt</li> </ul> <p>Returns:</p> <ul> <li><code>bytes</code>: Base64-encoded Fernet token</li> </ul> <p>Raises:</p> <ul> <li><code>TypeError</code>: If data is not bytes</li> </ul> <p>Example:</p> <pre><code>token = cipher.encrypt(b\"secret data\")\n</code></pre>"},{"location":"crypto/fernet256/#decrypttoken-ttlnone","title":"<code>decrypt(token, ttl=None)</code>","text":"<p>Decrypt a Fernet token.</p> <p>Parameters:</p> <ul> <li><code>token</code> (bytes): Encrypted Fernet token</li> <li><code>ttl</code> (int, optional): Time-to-live in seconds. If set, token must be younger than TTL</li> </ul> <p>Returns:</p> <ul> <li><code>bytes</code>: Decrypted plaintext</li> </ul> <p>Raises:</p> <ul> <li><code>InvalidToken</code>: If token is invalid, tampered with, or expired</li> </ul> <p>Example:</p> <pre><code># Decrypt without TTL\nplaintext = cipher.decrypt(token)\n# Decrypt with 1-hour TTL\nplaintext = cipher.decrypt(token, ttl=3600)\n</code></pre>"},{"location":"crypto/fernet256/#extract_timestamptoken","title":"<code>extract_timestamp(token)</code>","text":"<p>Extract the timestamp from a token without decrypting.</p> <p>Parameters:</p> <ul> <li><code>token</code> (bytes): Fernet token</li> </ul> <p>Returns:</p> <ul> <li><code>int</code>: Unix timestamp when token was created</li> </ul> <p>Raises:</p> <ul> <li><code>InvalidToken</code>: If token is invalid or tampered with</li> </ul> <p>Example:</p> <pre><code>import time\ntimestamp = cipher.extract_timestamp(token)\nage = int(time.time()) - timestamp\nprint(f\"Token is {age} seconds old\")\n</code></pre>"},{"location":"crypto/fernet256/#encrypt_at_timedata-current_time","title":"<code>encrypt_at_time(data, current_time)</code>","text":"<p>Encrypt data with a specific timestamp (for testing).</p> <p>Parameters:</p> <ul> <li><code>data</code> (bytes): Plaintext data</li> <li><code>current_time</code> (int): Unix timestamp to use</li> </ul> <p>Returns:</p> <ul> <li><code>bytes</code>: Base64-encoded Fernet token</li> </ul>"},{"location":"crypto/fernet256/#decrypt_at_timetoken-ttl-current_time","title":"<code>decrypt_at_time(token, ttl, current_time)</code>","text":"<p>Decrypt a token at a specific time (for testing).</p> <p>Parameters:</p> <ul> <li><code>token</code> (bytes): Encrypted token</li> <li><code>ttl</code> (int): Time-to-live in seconds</li> <li><code>current_time</code> (int): Unix timestamp to use for validation</li> </ul> <p>Returns:</p> <ul> <li><code>bytes</code>: Decrypted plaintext</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: If ttl is None</li> <li><code>InvalidToken</code>: If token is invalid or expired</li> </ul>"},{"location":"crypto/fernet256/#ttl-time-to-live","title":"TTL (Time-To-Live)","text":"<p>TTL allows you to enforce token expiration:</p> <pre><code>from rick.crypto import Fernet256\nimport time\ncipher = Fernet256(Fernet256.generate_key())\n# Encrypt data\ndata = b\"expires soon\"\ntoken = cipher.encrypt(data)\n# Decrypt immediately (works)\ndecrypted = cipher.decrypt(token, ttl=5)\nprint(decrypted)  # b\"expires soon\"\n# Wait 6 seconds\ntime.sleep(6)\n# Try to decrypt (fails)\ntry:\ncipher.decrypt(token, ttl=5)\nexcept cipher.InvalidToken:\nprint(\"Token expired!\")\n</code></pre>"},{"location":"crypto/fernet256/#string-encryption","title":"String Encryption","text":"<p>Fernet256 works with bytes. For strings, encode/decode:</p> <pre><code>from rick.crypto import Fernet256\ncipher = Fernet256(Fernet256.generate_key())\n# Encrypt string\ntext = \"Hello, World!\"\ntoken = cipher.encrypt(text.encode('utf-8'))\n# Decrypt to string\ndecrypted = cipher.decrypt(token).decode('utf-8')\nassert decrypted == text\n</code></pre>"},{"location":"crypto/fernet256/#encrypting-complex-data","title":"Encrypting Complex Data","text":"<p>Use pickle or JSON for complex Python objects:</p> <pre><code>from rick.crypto import Fernet256\nimport pickle\nimport json\ncipher = Fernet256(Fernet256.generate_key())\n# Using pickle\ndata = {'user': 'alice', 'roles': ['admin', 'user']}\ntoken = cipher.encrypt(pickle.dumps(data))\ndecrypted = pickle.loads(cipher.decrypt(token))\n# Using JSON\ndata = {'user': 'bob', 'age': 30}\ntoken = cipher.encrypt(json.dumps(data).encode('utf-8'))\ndecrypted = json.loads(cipher.decrypt(token).decode('utf-8'))\n</code></pre>"},{"location":"crypto/fernet256/#token-format","title":"Token Format","text":"<p>Fernet256 tokens are URL-safe base64-encoded and contain:</p> <pre><code>Version (1 byte) || Timestamp (8 bytes) || IV (16 bytes) || Ciphertext (variable) || HMAC (32 bytes)\n</code></pre> <ul> <li>Version: 0x81 (identifies Fernet256)</li> <li>Timestamp: Unix timestamp (8 bytes, big-endian)</li> <li>IV: Random initialization vector (16 bytes)</li> <li>Ciphertext: AES-256-CBC encrypted data</li> <li>HMAC: HMAC-SHA256 signature (32 bytes)</li> </ul>"},{"location":"crypto/fernet256/#multifernet256","title":"MultiFernet256","text":"<p>MultiFernet256 supports multiple encryption keys for key rotation without downtime.</p>"},{"location":"crypto/fernet256/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from rick.crypto import Fernet256, MultiFernet256\n# Create multiple keys\nkey1 = Fernet256.generate_key()\nkey2 = Fernet256.generate_key()\n# Create multi-fernet (first key is primary)\nmulti = MultiFernet256([\nFernet256(key1),  # Primary key for encryption\nFernet256(key2),  # Secondary key for decryption\n])\n# Encryption uses primary key\ntoken = multi.encrypt(b\"data\")\n# Decryption tries all keys\ndecrypted = multi.decrypt(token)\n</code></pre>"},{"location":"crypto/fernet256/#key-rotation","title":"Key Rotation","text":"<pre><code>from rick.crypto import Fernet256, MultiFernet256\n# Current production key\nkey_current = Fernet256.generate_key()\n# New key for rotation\nkey_new = Fernet256.generate_key()\n# Create multi-fernet with new key first\nmulti = MultiFernet256([\nFernet256(key_new),  # New key (encrypts)\nFernet256(key_current),  # Old key (decrypts)\n])\n# Old tokens encrypted with key_current\nold_token = b\"encrypted_with_old_key...\"\n# Rotate to new key\nnew_token = multi.rotate(old_token)\n# New token is now encrypted with key_new\n# but has the same timestamp as old_token\n</code></pre>"},{"location":"crypto/fernet256/#multifernet256-api","title":"MultiFernet256 API","text":""},{"location":"crypto/fernet256/#__init__fernets","title":"<code>__init__(fernets)</code>","text":"<p>Create a MultiFernet256 instance.</p> <p>Parameters:</p> <ul> <li><code>fernets</code> (list): List of Fernet256 instances</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: If fernets list is empty</li> </ul>"},{"location":"crypto/fernet256/#encryptmsg","title":"<code>encrypt(msg)</code>","text":"<p>Encrypt using the first (primary) Fernet instance.</p> <p>Parameters:</p> <ul> <li><code>msg</code> (bytes): Data to encrypt</li> </ul> <p>Returns:</p> <ul> <li><code>bytes</code>: Encrypted token</li> </ul>"},{"location":"crypto/fernet256/#decryptmsg-ttlnone","title":"<code>decrypt(msg, ttl=None)</code>","text":"<p>Decrypt using any Fernet instance.</p> <p>Parameters:</p> <ul> <li><code>msg</code> (bytes): Token to decrypt</li> <li><code>ttl</code> (int, optional): Time-to-live in seconds</li> </ul> <p>Returns:</p> <ul> <li><code>bytes</code>: Decrypted data</li> </ul> <p>Raises:</p> <ul> <li><code>InvalidToken</code>: If no key can decrypt the token</li> </ul>"},{"location":"crypto/fernet256/#rotatemsg","title":"<code>rotate(msg)</code>","text":"<p>Re-encrypt a token with the primary key.</p> <p>Parameters:</p> <ul> <li><code>msg</code> (bytes): Token encrypted with any key</li> </ul> <p>Returns:</p> <ul> <li><code>bytes</code>: Token encrypted with primary key (preserves timestamp)</li> </ul> <p>Raises:</p> <ul> <li><code>InvalidToken</code>: If token cannot be decrypted</li> </ul>"},{"location":"crypto/fernet256/#use-cases","title":"Use Cases","text":""},{"location":"crypto/fernet256/#encrypted-configuration","title":"Encrypted Configuration","text":"<pre><code>from rick.crypto import Fernet256\nimport json\nclass EncryptedConfig:\ndef __init__(self, key):\nself.cipher = Fernet256(key)\ndef save(self, config, filename):\nencrypted = self.cipher.encrypt(\njson.dumps(config).encode('utf-8')\n)\nwith open(filename, 'wb') as f:\nf.write(encrypted)\ndef load(self, filename):\nwith open(filename, 'rb') as f:\nencrypted = f.read()\ndecrypted = self.cipher.decrypt(encrypted)\nreturn json.loads(decrypted.decode('utf-8'))\n</code></pre>"},{"location":"crypto/fernet256/#secure-session-tokens","title":"Secure Session Tokens","text":"<pre><code>from rick.crypto import Fernet256\nimport pickle\nimport time\nclass SessionManager:\ndef __init__(self, secret_key):\nself.cipher = Fernet256(secret_key)\nself.ttl = 3600  # 1 hour\ndef create_token(self, user_id, data):\nsession = {\n'user_id': user_id,\n'created': int(time.time()),\n'data': data\n}\nreturn self.cipher.encrypt(pickle.dumps(session))\ndef verify_token(self, token):\ntry:\nsession = pickle.loads(\nself.cipher.decrypt(token, ttl=self.ttl)\n)\nreturn session\nexcept Fernet256.InvalidToken:\nreturn None\n</code></pre>"},{"location":"crypto/fernet256/#encrypted-database-fields","title":"Encrypted Database Fields","text":"<pre><code>from rick.crypto import Fernet256\nclass EncryptedField:\ndef __init__(self, key):\nself.cipher = Fernet256(key)\ndef encrypt(self, value):\nif value is None:\nreturn None\nreturn self.cipher.encrypt(\nvalue.encode('utf-8')\n).decode('ascii')\ndef decrypt(self, encrypted):\nif encrypted is None:\nreturn None\nreturn self.cipher.decrypt(\nencrypted.encode('ascii')\n).decode('utf-8')\n# Usage\nfield = EncryptedField(Fernet256.generate_key())\n# Store in database\nencrypted_ssn = field.encrypt(\"123-45-6789\")\n# Retrieve from database\nssn = field.decrypt(encrypted_ssn)\n</code></pre>"},{"location":"crypto/fernet256/#security-considerations","title":"Security Considerations","text":""},{"location":"crypto/fernet256/#key-management","title":"Key Management","text":"<ul> <li>Never hard-code keys in source code</li> <li>Store keys securely in environment variables or key vaults</li> <li>Rotate keys regularly using MultiFernet256</li> <li>Use different keys for different purposes/environments</li> </ul>"},{"location":"crypto/fernet256/#best-practices","title":"Best Practices","text":"<ul> <li>Always use TTL for session tokens and temporary data</li> <li>Re-encrypt periodically to refresh timestamps</li> <li>Validate tokens before using decrypted data</li> <li>Use secure random for key generation (provided by <code>generate_key()</code>)</li> </ul>"},{"location":"crypto/fernet256/#limitations","title":"Limitations","text":"<ul> <li>Not for large files - Entire payload is loaded into memory</li> <li>No compression - Compress data before encryption if needed</li> <li>Fixed algorithm - Cannot change cipher without re-encrypting</li> </ul>"},{"location":"crypto/fernet256/#error-handling","title":"Error Handling","text":"<pre><code>from rick.crypto import Fernet256, InvalidToken\ncipher = Fernet256(Fernet256.generate_key())\ntry:\n# Attempt decryption\ndata = cipher.decrypt(token, ttl=3600)\nexcept InvalidToken:\n# Token is invalid, tampered, or expired\nprint(\"Invalid or expired token\")\nexcept ValueError as e:\n# Invalid parameters\nprint(f\"Configuration error: {e}\")\nexcept TypeError as e:\n# Wrong data type\nprint(f\"Type error: {e}\")\n</code></pre>"},{"location":"crypto/fernet256/#performance","title":"Performance","text":"<p>Fernet256 is suitable for small to medium-sized data:</p> <ul> <li>Encryption: ~1-5 ms for 1KB data</li> <li>Decryption: ~1-5 ms for 1KB data</li> <li>Memory: Entire payload in memory</li> </ul> <p>For large files, consider:</p> <ul> <li>Streaming encryption (not supported by Fernet256)</li> <li>Hybrid encryption (encrypt symmetric key with Fernet256)</li> <li>Chunked encryption</li> </ul>"},{"location":"crypto/fernet256/#related","title":"Related","text":"<ul> <li>MultiFernet256 - Multi-key encryption</li> <li>CryptRedisCache - Uses Fernet256 internally</li> <li>Buffer Hashing - Hash utilities</li> </ul>"},{"location":"filters/","title":"Filters","text":"<p>Filter classes are helper classes used to transform a specific source value (tipically a string) into a specific data type, such as a string into a datetime object. The lifecycle of filter class objects is usually managed via a Registry, but many contexts that accept a filter name will also accept a custom filter class.</p> <p>These classes don't perform any validation of the passed values; if the conversion operation fails, they will silently return None. </p>"},{"location":"filters/#using-filters","title":"Using filters","text":"<p>While Filters are often use within the scope of a Form, FieldRecord or RequestRecord, they can also be used in standalone: <pre><code>from datetime import datetime\nfrom rick.filter import registry as filter_registry\n# retrieve a filter to convert a string to a datetime object\nfilter = filter_registry.get('datetime')\n# use the filter to convert the string to an object\nresult = filter.transform('2022-05-31T15:11Z')\n# console output: True\nprint(isinstance(result, datetime))\n</code></pre></p>"},{"location":"filters/#creating-filters","title":"Creating Filters","text":"<p>Filter classes must extend the Filter base class, and implement the appropriate behaviour in the overridden transform() method:</p> <pre><code>from datetime import datetime\nfrom rick.filter import registry as filter_registry, Filter\nfrom typing import Any\nfrom dataclasses import dataclass\n# our new Dude type\n@dataclass\nclass Dude:\ngreeting: str\n# add our new filter to registry, with the name 'dude'\n@filter_registry.register_cls('dude')\nclass DudeFilter(Filter):\ndef transform(self, src: Any) -&gt; Dude:\n# all values are now dude objects!\nreturn Dude(greeting=\"Hey dude!\")\n# retrieve a filter to convert a string to a \"dude\"\nfilter = filter_registry.get('dude')\n# use the filter to convert the string to a dude\nresult = filter.transform('the quick brown fox jumps over the lazy dog')\n# console output: \"Hey Dude!\"\nprint(result.greeting)\n</code></pre>"},{"location":"forms/","title":"Working with Forms","text":"<p>Rick provides powerful form handling and request validation capabilities through two main classes:</p> <ul> <li>Form - Full-featured forms with fieldsets, controls, and HTML form support</li> <li>RequestRecord - Lightweight request validation for APIs and data processing</li> </ul>"},{"location":"forms/#overview","title":"Overview","text":""},{"location":"forms/#form","title":"Form","text":"<p>Form is a generic form component designed for building and validating HTML forms. It supports:</p> <ul> <li>Field declaration with validation rules</li> <li>Field groups (fieldsets) for organizing complex forms</li> <li>Custom validation methods</li> <li>Form controls (buttons, etc.)</li> <li>HTTP method and action URL configuration</li> <li>Agnostic design (no rendering - bring your own template engine)</li> </ul>"},{"location":"forms/#requestrecord","title":"RequestRecord","text":"<p>RequestRecord is a lightweight class focused on structured request data validation. It's ideal for:</p> <ul> <li>API request validation</li> <li>Data processing pipelines</li> <li>Nested data structures</li> <li>Object binding</li> <li>Microservices and REST APIs</li> </ul>"},{"location":"forms/#quick-start","title":"Quick Start","text":""},{"location":"forms/#simple-form","title":"Simple Form","text":"<pre><code>from rick.form import Form\n# Create form\nform = Form()\nform.field(\"text\", \"username\", \"Username\", validators=\"required|alphanum|minlen:3\")\nform.field(\"email\", \"email\", \"Email\", validators=\"required|email\")\nform.field(\"password\", \"password\", \"Password\", validators=\"required|minlen:8\")\n# Validate data\ndata = {\n\"username\": \"alice\",\n\"email\": \"alice@example.com\",\n\"password\": \"SecurePass123\"\n}\nif form.is_valid(data):\nprint(f\"Welcome {form.get('username')}!\")\nelse:\nprint(f\"Errors: {form.get_errors()}\")\n</code></pre>"},{"location":"forms/#simple-requestrecord","title":"Simple RequestRecord","text":"<pre><code>from rick.form import RequestRecord, field\nclass UserRequest(RequestRecord):\nfields = {\n'username': field(validators='required|alphanum|minlen:3'),\n'email': field(validators='required|email'),\n'age': field(validators='numeric|between:18,120'),\n}\n# Validate request data\nrequest = UserRequest()\ndata = {'username': 'alice', 'email': 'alice@example.com', 'age': '25'}\nif request.is_valid(data):\nprint(\"Valid request!\")\nuser_data = request.get_data()\n</code></pre>"},{"location":"forms/#form-features","title":"Form Features","text":""},{"location":"forms/#adding-fields","title":"Adding Fields","text":"<pre><code>form = Form()\n# Basic field\nform.field(\"text\", \"name\", \"Full Name\", validators=\"required\")\n# Field with multiple validators\nform.field(\"text\", \"age\", \"Age\", validators=\"required|numeric|between:18,120\")\n# Optional field (no 'required' validator)\nform.field(\"text\", \"phone\", \"Phone\", validators=\"numeric\")\n</code></pre>"},{"location":"forms/#using-fieldsets","title":"Using Fieldsets","text":"<pre><code>form = Form()\n# Personal information fieldset\npersonal = form.fieldset(\"personal\", \"Personal Information\")\npersonal.field(\"text\", \"first_name\", \"First Name\", validators=\"required\")\npersonal.field(\"text\", \"last_name\", \"Last Name\", validators=\"required\")\n# Contact information fieldset\ncontact = form.fieldset(\"contact\", \"Contact Information\")\ncontact.field(\"email\", \"email\", \"Email\", validators=\"required|email\")\ncontact.field(\"text\", \"phone\", \"Phone\", validators=\"numeric\")\n</code></pre>"},{"location":"forms/#adding-controls","title":"Adding Controls","text":"<pre><code>form = Form()\nform.field(\"text\", \"username\", \"Username\", validators=\"required\")\nform.field(\"password\", \"password\", \"Password\", validators=\"required\")\n# Add form controls (buttons)\nform.control(\"submit\", \"login\", \"Login\")\nform.control(\"button\", \"cancel\", \"Cancel\")\n</code></pre>"},{"location":"forms/#form-configuration","title":"Form Configuration","text":"<pre><code>form = Form()\nform.set_action(\"/api/users\")\nform.set_method(Form.METHOD_POST)\n# Available methods:\n# - Form.METHOD_POST\n# - Form.METHOD_PUT\n# - Form.METHOD_PATCH\n# - Form.METHOD_SEARCH\n</code></pre>"},{"location":"forms/#custom-validation","title":"Custom Validation","text":"<p>Custom validator methods are executed automatically after standard field validation passes. The method name must follow the pattern <code>validator_&lt;field_id&gt;()</code>.</p> <p>Note: Custom validators only run if all field validators pass first. This ensures you don't need to repeat basic validation logic in your custom methods.</p>"},{"location":"forms/#basic-custom-validation","title":"Basic Custom Validation","text":"<pre><code>from rick.form import Form\nfrom rick.mixin import Translator\nclass RegistrationForm(Form):\ndef __init__(self):\nsuper().__init__()\nself.field('text', 'username', 'Username', validators=\"required|alphanum\")\nself.field('password', 'password', 'Password', validators=\"required|minlen:8\")\nself.field('password', 'confirm', 'Confirm Password', validators=\"required\")\ndef validator_confirm(self, data, t: Translator):\n\"\"\"Validate password confirmation\"\"\"\nif data['password'] != data['confirm']:\nself.add_error('confirm', 'Passwords do not match')\nreturn False\nreturn True\ndef validator_username(self, data, t: Translator):\n\"\"\"Check if username is available\"\"\"\n# Simulate database check\ntaken_usernames = ['admin', 'root', 'system']\nif data['username'].lower() in taken_usernames:\nself.add_error('username', 'Username not available')\nreturn False\nreturn True\n</code></pre>"},{"location":"forms/#multi-field-validation","title":"Multi-Field Validation","text":"<pre><code>from rick.form import Form\nfrom rick.mixin import Translator\nclass DateRangeForm(Form):\ndef __init__(self):\nsuper().__init__()\nself.field('date', 'start_date', 'Start Date', validators=\"required\")\nself.field('date', 'end_date', 'End Date', validators=\"required\")\ndef validator_end_date(self, data, t: Translator):\n\"\"\"Ensure end date is after start date\"\"\"\nstart = data.get('start_date', '')\nend = data.get('end_date', '')\nif start and end and end &lt; start:\nself.add_error('end_date', 'End date must be after start date')\nreturn False\nreturn True\n</code></pre>"},{"location":"forms/#working-with-form-data","title":"Working with Form Data","text":""},{"location":"forms/#getting-field-values","title":"Getting Field Values","text":"<pre><code>form = Form()\nform.field(\"text\", \"name\", \"Name\", validators=\"required\")\nform.field(\"email\", \"email\", \"Email\", validators=\"required|email\")\ndata = {\"name\": \"Alice\", \"email\": \"alice@example.com\"}\nif form.is_valid(data):\n# Get individual field\nname = form.get('name')\n# Get all data as dict\nall_data = form.get_data()\n</code></pre>"},{"location":"forms/#setting-field-values","title":"Setting Field Values","text":"<pre><code>form = Form()\nform.field(\"text\", \"name\", \"Name\")\nform.field(\"email\", \"email\", \"Email\")\n# Set values programmatically\nform.set(\"name\", \"Bob\")\nform.set(\"email\", \"bob@example.com\")\nprint(form.get('name'))  # Output: Bob\n</code></pre>"},{"location":"forms/#validation-errors","title":"Validation Errors","text":"<p>After validation fails, retrieve errors using <code>get_errors()</code>:</p> <pre><code>form = Form()\nform.field(\"text\", \"username\", \"Username\", validators=\"required|minlen:3\")\nform.field(\"email\", \"email\", \"Email\", validators=\"required|email\")\ndata = {\"username\": \"ab\", \"email\": \"invalid\"}\nif not form.is_valid(data):\nerrors = form.get_errors()\n# {\n#   'username': {'minlen': 'minimum allowed length is 3'},\n#   'email': {'email': 'invalid email address'}\n# }\n</code></pre> <p>See Error Format Documentation for complete error structure details.</p>"},{"location":"forms/#available-validators","title":"Available Validators","text":"<p>Rick includes many built-in validators. Common validators include:</p> <p>String Validators:</p> <ul> <li><code>required</code> - Field must be present and not empty</li> <li><code>alpha</code> - Alphabetic characters only</li> <li><code>alphanum</code> - Alphanumeric characters only</li> <li><code>minlen:N</code> - Minimum length</li> <li><code>maxlen:N</code> - Maximum length</li> </ul> <p>Numeric Validators:</p> <ul> <li><code>numeric</code> - Must be numeric</li> <li><code>int</code> - Must be integer</li> <li><code>decimal</code> - Must be decimal</li> <li><code>between:min,max</code> - Value range</li> </ul> <p>Network Validators:</p> <ul> <li><code>email</code> - Valid email address</li> <li><code>ipv4</code> / <code>ipv6</code> - IP addresses</li> <li><code>fqdn</code> - Fully qualified domain name</li> </ul> <p>See the Validators Documentation for the complete list.</p>"},{"location":"forms/#examples","title":"Examples","text":"<p>Rick includes comprehensive form examples in <code>examples/form/</code>:</p> <ul> <li>simple_form.py - Basic form usage</li> <li>custom_validation.py - Custom validators and business logic</li> <li>fieldset_example.py - Organizing forms with fieldsets</li> <li>request_record_example.py - API validation and nested records</li> </ul> <p>Run examples:</p> <pre><code>python examples/form/simple_form.py\n</code></pre>"},{"location":"forms/#see-also","title":"See Also","text":"<ul> <li>Form Class Reference - Complete Form API</li> <li>Field Class Reference - Field options and parameters</li> <li>RequestRecord Documentation - API request validation</li> <li>Error Format - Error message structure</li> <li>Validators - Available validation rules</li> </ul>"},{"location":"forms/errors/","title":"RequestRecord/Form error messages","text":"<p>RequestRecord and form error messages have the following structure:</p> <p><pre><code>{\n  field_name: {\n    validator_name: error_message,\n    validator_name: error_message\n  },\n  field-name: {...}\n}\n</code></pre> Where field_name is the field id, and validator_name either the name of the failing validator, or '*' for generic error messages for the field.</p> <p>Example result, with two failing validations on a single field: <pre><code> {\n\"age\": {\n\"between\": \"must be between 9 and 125\",\n\"numeric\": \"only digits allowed\"\n}\n}\n</code></pre></p>"},{"location":"forms/errors/#nested-records","title":"Nested Records","text":"<p>Nested record errors are signaled by using '_' as validator name. The nested record can either be a single record, or a list of records:</p> <p>Structure for single record: <pre><code>{\n  field_name: {\n    validator_name: error_message,\n    validator_name: error_message\n  },\n  field-name: {\n    validator_name: error_message,\n    \"_\": {\n        field_name: {\n            validator_name: error_message,\n            validator_name: error_message,\n        },\n        field_name: {\n            validator_name: error_message,\n            validator_name: error_message,\n        },\n    }\n  }\n}\n</code></pre></p> <p>Structure for a list of records (notice the sequence number to identify the failing record position): <pre><code>{\n  field_name: {\n    validator_name: error_message,\n    validator_name: error_message\n  },\n  field-name: {\n    validator_name: error_message,\n    \"_\": {\n        \"sequence number\": {\n            field_name: {\n                validator_name: error_message,\n                validator_name: error_message,\n            },\n            field_name: {\n                validator_name: error_message,\n                validator_name: error_message,\n            },\n        }\n    }\n  }\n}\n</code></pre></p>"},{"location":"forms/field.class/","title":"Class rick.form.Field","text":"<p>Base field class.</p>"},{"location":"forms/form.class/","title":"Class rick.form.Form","text":"<p>Base form class.</p>"},{"location":"forms/form.class/#property-formfields","title":"@property Form.fields","text":"<p>Form field dictionary, indexed by field id. Each entry is a Field object. </p>"},{"location":"forms/form.class/#forminittranslator-translator-none","title":"Form.init(translator: Translator = None)","text":"<p>Form Constructor. Initializes the form object, and optionally receives a Translator mixin to provide translation services to all the fields and fieldsets.</p>"},{"location":"forms/requests/","title":"Managing Requests","text":"<p>Rick provides several distinct classes to aid the management of request data: RequestRecord and Form. While these classes share a common syntax, their use cases are different. RequestRecord is designed to just handle structured request data; Form extends RequestRecord with additional control and grouping logic, useful for generating and processing HTML forms.</p>"},{"location":"forms/requests/#requestrecord","title":"RequestRecord","text":"<p>RequestRecord provides two ways for defining fields and field-related validation and filtering operations; A terse version, suitable for most usage scenarios, where the fields are specified directly in the class declaration (via fields attribute), or in runtime by using an initializer method, often called init().</p> <p>Declaring fields directly using class attributes:</p> <pre><code>from rick.form import RequestRecord, field\nclass UserRequest(RequestRecord):\nfields = {\n'id': field(validators=\"numeric\"),\n'name': field(validators=\"required|maxlen:128\"),\n'age': field(validators=\"required|numeric|between:18,120\")\n}\n</code></pre> <p>Declaring fields inside an initializer method:</p> <pre><code>from rick.form import RequestRecord\nfrom rick.mixin import Translator\n# Custom class using runtime field definitions, and a custom field validator\nclass UserRequest(RequestRecord):\ndef init(self):\nself.field('id', validators=\"required|minlen:4|maxlen:8\")\n.field('age', validators=\"required|numeric|between:9,125\")\n.field('phone', validators=\"numeric|minlen:8|maxlen:16\")\nreturn self\n</code></pre>"},{"location":"forms/requests/#requestrecord-validation","title":"RequestRecord validation","text":"<p>There are two levels of validation: a first one, using the declared validators, and a second one using optional methods to perform additional validation.</p> <p>Validation of data is done by using RequestRecord's is_valid() method. This method receives a dictionary of field names and values, and returns either True or False, reflecting if all the values for the defined fields pass the predefined validators or not, as well as the optional validation methods.</p> <p>Note: internally, the validation is performed as a two-step operation - if any of the declared field validators fail validation, no magic validation methods are called. Magic validation methods will only be executed for any given field if all the predefined field validations pass.</p> <p>The rationale for this is to avoid having to perform basic validations within the method body, simplifying the implementation of additional validation logic. This way, when any magic method is called, it is guaranteed that the available data passed the field validations.</p>"},{"location":"forms/requests/#field-validators","title":"Field validators","text":"<p>field validators can be specified using any format compatible with rick.Validator usage, but commonly will use the string Laravel-style compact form:</p> <pre><code>from rick.form import RequestRecord, field\nclass AgeRequest(RequestRecord):\nfields = {\n# age field with several validators\n'age': field(validators=\"required|numeric|between:18,120\")\n}\n# create the request validation object to be used\nreq = AgeRequest()\n# some invalid data to fail validation\ndata = {\n'name': 'John Connor',\n'age': '1a'\n}\n# validate data, should fail\nif not req.is_valid(data):\n# will print: \n# {'age': {'numeric': 'only digits allowed', 'between': 'must be between 18 and 120'}}\nprint(req.get_errors())\n</code></pre> <p>Each failing validator will generate an error message; it is possible to override all error messages for a given field by just providing a custom error message:</p> <pre><code>from rick.form import RequestRecord, field\nclass AgeRequest(RequestRecord):\nfields = {\n# age field with several validators\n'age': field(validators=\"required|numeric|between:18,120\", error=\"invalid age\")\n}\n# create the request validation object to be used\nreq = AgeRequest()\n# some invalid data to fail validation\ndata = {\n'name': 'John Connor',\n'age': '1a'\n}\n# validate data, should fail\nif not req.is_valid(data):\n# will print: \n# {'age': {'*': 'invalid age'}}\nprint(req.get_errors())\n</code></pre>"},{"location":"forms/requests/#method-validators","title":"Method validators","text":"<p>As mentioned, RequestRecord allows for the optional declaration of magic validation methods that are called automatically during the internal second validation step. These methods can be used to perform additional validation logic, such as dependencies between fields or database lookups.</p> <p>The methods must be named validator_(data, t:Translator) and conform to the defined interface: <pre><code>from rick.form import RequestRecord, field\nfrom rick.mixin import Translator\n# Custom class using runtime field definitions, and a custom field validator\nclass MyFieldRecord(RequestRecord):\nfields = {\n'name': field(validators=\"required|minlen:4|maxlen:8\"),\n'age': field(validators=\"required|numeric|between:9,125\"),\n'phone': field(validators=\"numeric|minlen:8|maxlen:16\")\n}\n# custom validator method for field 'name'\n# this will only be executed if all field validators are successful\ndef validator_name(self, data, t: Translator):\n# 'data' is the field:value dictionary passed to is_valid(); it\n# contains all raw field values\nif data['name'] == 'dave':\n# add a custom error for field 'name'\nself.add_error('name', 'Dave is not here, man')\nreturn False\nreturn True\ndata = {\n'name': 'dave',\n'age': 12,\n'phone': '12312312'\n}\nfrm = MyFieldRecord()\nif not frm.is_valid(data):\n# will print:\n# {'name': {'*': 'Dave is not here, man'}}\nprint(frm.get_errors())\n</code></pre>"},{"location":"forms/requests/#retrieving-validation-errors","title":"Retrieving validation errors","text":"<p>Validation errors are made available via get_errors(), using the documented format.</p>"},{"location":"forms/requests/#nested-requestrecord-structures","title":"Nested RequestRecord structures","text":"<p>RequestRecord classes can be nested to build complex request validation structures. This can be achieved using the record() helper function to describe dict-like records, or recordset() helper function to describe lists of dict-like records.</p> <p>Internally, records are also represented as fields, so filtered values can be accessed like any other regular field.</p> <p>Example:</p> <pre><code>from rick.form import RequestRecord, field, record, recordset\nfrom rick.mixin import Translator\n# Request class describing a player structure\nclass Player(RequestRecord):\nfields = {\n'name': field(validators=\"required|minlen:4|maxlen:32\"),\n'age': field(validators=\"required|numeric|between:9,125\"),\n}\n# Request class for a team\nclass TeamRequest(RequestRecord):\nfields = {\n'team_name': field(validators=\"required|minlen:4|maxlen:64\"),\n# specify a field 'players' as a list of type Player, for validation purposes\n'players': recordset(Player)\n}\n# Request class for a team leader\nclass TeamLeaderRequest(RequestRecord):\nfields = {\n'team_name': field(validators=\"required|minlen:4|maxlen:64\"),\n# specify a field 'players' as a single record of type Player, for validation purposes\n'leader': record(Player)\n}\n# sample request data for TeamRequest    \nteam_data = {\n'team_name': 'super team',\n'players': [\n{\n'name': 'susan',\n'age': 32\n},\n{\n'name': 'mary',\n'age': 21\n},\n]\n}\n# validate data for TeamRequest\nrequest = TeamRequest()\nif request.is_valid(team_data):\nprint('Team data is valid!')\n# sample request data for TeamLeaderRequest    \nteam_leader_data = {\n'team_name': 'super team',\n'leader': {\n'name': 'susan',\n'age': 32\n}\n}\n# validate data for TeamLeaderRequest\nrequest = TeamLeaderRequest()\nif request.is_valid(team_leader_data):\nprint('Team leader data is valid!')\n</code></pre>"},{"location":"forms/requests/#binding-request-data-to-objects","title":"Binding Request Data to Objects","text":"<p>RequestRecord can bind validated data directly to Python objects, making it easy to work with ORMs, dataclasses, or any Python class.</p>"},{"location":"forms/requests/#basic-binding","title":"Basic Binding","text":"<pre><code>from rick.form import RequestRecord, field\nclass UserRequest(RequestRecord):\nfields = {\n'username': field(validators='required|alphanum'),\n'email': field(validators='required|email'),\n'age': field(validators='numeric'),\n}\nclass User:\ndef __init__(self):\nself.username = None\nself.email = None\nself.age = None\n# Validate and bind\nrequest = UserRequest()\ndata = {'username': 'alice', 'email': 'alice@example.com', 'age': '25'}\nif request.is_valid(data):\n# Bind to new instance\nuser = request.bind(User)\nprint(f\"User: {user.username}, {user.email}, {user.age}\")\n# Or bind to existing instance\nexisting_user = User()\nrequest.bind(existing_user)\n</code></pre>"},{"location":"forms/requests/#custom-field-name-binding","title":"Custom Field Name Binding","text":"<p>Use the <code>bind</code> parameter to map form fields to different object attribute names:</p> <pre><code>from rick.form import RequestRecord, field\nclass UserRequest(RequestRecord):\nfields = {\n'user_name': field(validators='required', bind='username'),\n'user_email': field(validators='required|email', bind='email'),\n}\nclass DbUser:\nusername = None\nemail = None\nrequest = UserRequest()\nform_data = {'user_name': 'alice', 'user_email': 'alice@example.com'}\nif request.is_valid(form_data):\n# Maps user_name -&gt; username, user_email -&gt; email\ndb_user = request.bind(DbUser)\n</code></pre>"},{"location":"forms/requests/#binding-with-unmapped-values","title":"Binding with Unmapped Values","text":"<p>Use <code>bindx()</code> to get both the bound object and any unmapped values:</p> <pre><code>class User:\nusername = None\nemail = None\n# No 'age' attribute\nrequest = UserRequest()\ndata = {'username': 'alice', 'email': 'alice@example.com', 'age': '25'}\nif request.is_valid(data):\nuser, unmapped = request.bindx(User)\n# user.username = 'alice'\n# user.email = 'alice@example.com'\n# unmapped = {'age': '25'}\n</code></pre>"},{"location":"forms/requests/#binding-notes","title":"Binding Notes","text":"<ul> <li>Only non-None values are bound (prevents overwriting existing values like primary keys)</li> <li>If <code>cls_obj</code> is a class, a new instance is created</li> <li>If <code>cls_obj</code> is an object, it's updated in place</li> <li>Attributes not present in the target object are ignored (or returned by <code>bindx()</code>)</li> <li>Works great with ORMs, dataclasses, and RickDB Records</li> </ul>"},{"location":"mixins/translator.class/","title":"Mixin rick.mixin.Translator","text":"<p>Mixin to provide an interface for string translation</p>"},{"location":"mixins/translator.class/#translatorttext-str-str","title":"Translator.t(text: str) -&gt; str:","text":"<p>Method signature to perform a string translation. By default, the mixin implementation returns the passed text value.</p>"},{"location":"resources/","title":"Resources","text":"<p>Rick provides resource management components for working with external systems and services. These components offer standardized interfaces and utilities for common operations like caching, configuration management, file operations, and stream processing.</p>"},{"location":"resources/#overview","title":"Overview","text":"<p>The resource module includes components for:</p> <ul> <li>Caching - Redis-based caching with optional encryption</li> <li>Configuration - Environment variables, JSON, TOML, and hybrid configuration loaders</li> <li>File Operations - File handling utilities</li> <li>Stream Processing - Multipart stream reading and processing</li> <li>Console Output - Colored console output and formatting</li> </ul>"},{"location":"resources/#cache-interface","title":"Cache Interface","text":"<p>All cache implementations in Rick follow the <code>CacheInterface</code> protocol:</p> <pre><code>from rick.resource import CacheInterface\nclass CacheInterface:\ndef get(self, key):\n\"\"\"Retrieve value by key\"\"\"\npass\ndef set(self, key, value, ttl=None):\n\"\"\"Store value with optional TTL (time-to-live)\"\"\"\npass\ndef has(self, key):\n\"\"\"Check if key exists\"\"\"\npass\ndef remove(self, key):\n\"\"\"Remove key\"\"\"\npass\ndef purge(self):\n\"\"\"Clear all cached data\"\"\"\npass\ndef set_prefix(self, prefix):\n\"\"\"Set key prefix for namespacing\"\"\"\npass\n</code></pre> <p>This standardized interface allows you to swap cache implementations without changing your application code.</p>"},{"location":"resources/#available-resources","title":"Available Resources","text":""},{"location":"resources/#redis-cache","title":"Redis Cache","text":"<p>Rick provides two Redis cache implementations:</p> <ul> <li>RedisCache - Basic Redis caching with pickle serialization</li> <li>CryptRedisCache - Encrypted Redis cache for sensitive data</li> </ul> <p>Features:</p> <ul> <li>Full Redis client access for advanced operations</li> <li>Configurable serialization (pickle, JSON, MessagePack, etc.)</li> <li>Key prefixing for namespace isolation</li> <li>TTL (time-to-live) support</li> <li>Connection pooling and SSL support</li> <li>Backend wrapping of existing Redis clients</li> </ul> <p>Read full Redis documentation</p>"},{"location":"resources/#configuration-loaders","title":"Configuration Loaders","text":"<p>Rick provides multiple configuration loaders:</p> <ul> <li>EnvironmentConfig - Load configuration from environment variables with type conversion</li> <li>JsonFileConfig - Load configuration from JSON files</li> <li>TomlFileConfig - Load configuration from TOML files</li> <li>HybridFileConfig - Auto-detect file format (JSON or TOML)</li> </ul> <p>Features:</p> <ul> <li>Automatic type conversion based on default values</li> <li>Custom validation functions with <code>validate_*</code> methods</li> <li>Default values with file/environment overrides</li> <li>StrOrFile wrapper for loading secrets from files</li> <li>Nested configuration support</li> <li>Configuration reload without restart</li> <li>Prefix support for environment variable namespacing</li> </ul> <p>Read full Configuration documentation</p>"},{"location":"resources/#file-operations","title":"File Operations","text":"<p>Rick provides enhanced file handling utilities:</p> <ul> <li>FileReader - Enhanced multipart file reader with metadata</li> <li>FilePart - File part representation</li> </ul> <p>Features:</p> <ul> <li>File metadata (name, content type, custom attributes)</li> <li>Chunked reading for memory efficiency</li> <li>Multipart file handling</li> <li>Process uploaded files or split archives</li> <li>Built on top of stream processing utilities</li> </ul> <p>Read full File Operations documentation</p>"},{"location":"resources/#stream-processing","title":"Stream Processing","text":"<p>Rick provides stream processing utilities for handling multipart data streams:</p> <ul> <li>MultiPartReader - Combine multiple data sources into a seekable stream</li> <li>FileSlice - Read file slices from disk</li> <li>BytesIOSlice - Read slices from memory buffers</li> </ul> <p>Features:</p> <ul> <li>Minimal memory usage for large files</li> <li>Seek support for random access</li> <li>Combine files, buffers, and custom sources</li> <li>Stream processing with efficient chunking</li> <li>Custom slice implementations</li> </ul> <p>Read full Stream Processing documentation</p>"},{"location":"resources/#console-output","title":"Console Output","text":"<p>Rick provides utilities for colored and formatted console output:</p> <ul> <li>AnsiColor - ANSI color formatting with 16 colors and text attributes</li> <li>ConsoleWriter - High-level console writer with semantic methods</li> </ul> <p>Features:</p> <ul> <li>16 foreground and background colors (standard and light variants)</li> <li>Text attributes (bold, dim, underline, reversed)</li> <li>Semantic output methods (success, error, warning, header)</li> <li>Separate stdout and stderr streams</li> <li>Custom colorization and styling</li> </ul> <p>Read full Console Output documentation</p>"},{"location":"resources/#common-use-cases","title":"Common Use Cases","text":""},{"location":"resources/#colored-console-output","title":"Colored Console Output","text":"<pre><code>from rick.resource.console import ConsoleWriter, AnsiColor\n# High-level semantic output\nconsole = ConsoleWriter()\nconsole.header('Application Startup')\nconsole.success('Database connection established')\nconsole.warn('Cache is disabled')\nconsole.error('Failed to load plugin')\n# Low-level color formatting\ncolor = AnsiColor()\nprint(color.red('Error message', attr='bold'))\nprint(color.green('Success', 'white', ['bold', 'underline']))\nprint(color.blue('[INFO]', attr='bold') + ' Application started')\n</code></pre>"},{"location":"resources/#cli-progress-output","title":"CLI Progress Output","text":"<pre><code>from rick.resource.console import ConsoleWriter\nconsole = ConsoleWriter()\nsteps = ['Loading config', 'Connecting DB', 'Starting services']\nfor step in steps:\nconsole.write(f'{step}...', eol=False)\n# Do work...\nconsole.success(' Done')\nconsole.write('')\nconsole.success('Application ready')\n</code></pre>"},{"location":"resources/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Redis Cache for detailed caching documentation</li> <li>Learn about Configuration for configuration management</li> <li>Check Console Output for CLI formatting</li> <li>Review Serializers for efficient data encoding</li> </ul>"},{"location":"resources/config/","title":"Configuration Loaders","text":"<p>Rick provides flexible configuration loading utilities for managing application settings from multiple sources. The configuration module supports environment variables, JSON files, TOML files, and hybrid configurations with validation and type conversion.</p> <p>Location: <code>rick.resource.config</code></p>"},{"location":"resources/config/#overview","title":"Overview","text":"<p>Configuration management in Rick provides:</p> <ul> <li>Environment Variable Loading - Load settings from environment variables with type conversion</li> <li>File-Based Configuration - Load from JSON or TOML files</li> <li>Default Values - Define fallback values for missing configuration</li> <li>Validation - Custom validation functions to ensure configuration correctness</li> <li>Type Conversion - Automatic type conversion based on default values</li> <li>Hybrid Loading - Auto-detect file format or combine multiple sources</li> <li>StrOrFile Support - Load values from files when needed</li> </ul>"},{"location":"resources/config/#available-configuration-loaders","title":"Available Configuration Loaders","text":""},{"location":"resources/config/#environmentconfig","title":"EnvironmentConfig","text":"<p>Load configuration from environment variables with automatic type conversion.</p> <p>Location: <code>rick.resource.config.EnvironmentConfig</code></p>"},{"location":"resources/config/#jsonfileconfig","title":"JsonFileConfig","text":"<p>Load configuration from JSON files with validation support.</p> <p>Location: <code>rick.resource.config.JsonFileConfig</code></p>"},{"location":"resources/config/#tomlfileconfig","title":"TomlFileConfig","text":"<p>Load configuration from TOML files with validation support.</p> <p>Location: <code>rick.resource.config.TomlFileConfig</code></p>"},{"location":"resources/config/#hybridfileconfig","title":"HybridFileConfig","text":"<p>Auto-detect file format (JSON or TOML) based on file extension.</p> <p>Location: <code>rick.resource.config.HybridFileConfig</code></p>"},{"location":"resources/config/#environmentconfig_1","title":"EnvironmentConfig","text":""},{"location":"resources/config/#overview_1","title":"Overview","text":"<p><code>EnvironmentConfig</code> loads configuration from environment variables with automatic type conversion. Class attributes defined in uppercase are mapped to environment variables and converted to lowercase keys in the resulting configuration.</p>"},{"location":"resources/config/#features","title":"Features","text":"<ul> <li>Automatic type conversion (str, int, bool, list, dict)</li> <li>Environment variable override of default values</li> <li>Optional validation functions</li> <li>Prefix support for namespacing</li> <li>StrOrFile wrapper for loading values from files</li> </ul>"},{"location":"resources/config/#basic-usage","title":"Basic Usage","text":"<pre><code>from rick.resource.config import EnvironmentConfig\nclass DatabaseConfig(EnvironmentConfig):\n# Define configuration with default values\nDB_HOST = 'localhost'\nDB_PORT = 5432\nDB_NAME = 'myapp'\nDB_USERNAME = 'postgres'\nDB_PASSWORD = 'password'\nDB_SSL = False\n# Build configuration (environment variables override defaults)\nconfig = DatabaseConfig().build()\n# Access configuration (keys are lowercase)\nprint(config.db_host)  # 'localhost' or value from DB_HOST env var\nprint(config.db_port)  # 5432 or value from DB_PORT env var\nprint(config.db_ssl)  # False or value from DB_SSL env var\n</code></pre>"},{"location":"resources/config/#type-conversion","title":"Type Conversion","text":"<p>Environment variables are automatically converted to the type of the default value:</p> <pre><code>from rick.resource.config import EnvironmentConfig\nclass AppConfig(EnvironmentConfig):\n# Type hints via default values\nAPI_KEY = None  # str - None defaults to string\nDEBUG_MODE = False  # bool - converted from env var\nMAX_WORKERS = 4  # int - parsed from env string\nALLOWED_HOSTS = []  # list - split by comma separator\nFEATURE_FLAGS = {}  # dict - parsed as JSON\n# Set environment variables:\n# export DEBUG_MODE=true\n# export MAX_WORKERS=8\n# export ALLOWED_HOSTS=localhost,127.0.0.1,example.com\n# export FEATURE_FLAGS='{\"new_ui\": true, \"beta_features\": false}'\nconfig = AppConfig().build()\nprint(config.debug_mode)  # True (bool)\nprint(config.max_workers)  # 8 (int)\nprint(config.allowed_hosts)  # ['localhost', '127.0.0.1', 'example.com']\nprint(config.feature_flags)  # {'new_ui': True, 'beta_features': False}\n</code></pre>"},{"location":"resources/config/#supported-types","title":"Supported Types","text":"Default Type Environment Value Result Type Example <code>None</code> Any string <code>str</code> <code>\"value\"</code> <code>\"\"</code> Any string <code>str</code> <code>\"hello\"</code> <code>0</code> Numeric string <code>int</code> <code>42</code> <code>False</code> Bool string <code>bool</code> <code>True</code> <code>[]</code> Comma-separated <code>list</code> <code>['a', 'b']</code> <code>{}</code> JSON string <code>dict</code> <code>{'key': 'val'}</code>"},{"location":"resources/config/#custom-list-separator","title":"Custom List Separator","text":"<pre><code>from rick.resource.config import EnvironmentConfig\nclass CustomConfig(EnvironmentConfig):\n# Change list separator from comma to semicolon\nlist_separator = \";\"\nSERVERS = []\n# export SERVERS=server1;server2;server3\nconfig = CustomConfig().build()\nprint(config.servers)  # ['server1', 'server2', 'server3']\n</code></pre>"},{"location":"resources/config/#validation","title":"Validation","text":"<p>Add custom validation by defining methods that start with <code>validate_</code>:</p> <pre><code>from rick.resource.config import EnvironmentConfig\nclass ValidatedConfig(EnvironmentConfig):\nDB_HOST = 'localhost'\nDB_PORT = 5432\nAPI_KEY = None\nMAX_CONNECTIONS = 10\ndef validate_database(self, data: dict):\n\"\"\"Validate database configuration\"\"\"\nif not data.get('db_host'):\nraise ValueError(\"Database host is required\")\nport = data.get('db_port', 0)\nif not (1 &lt;= port &lt;= 65535):\nraise ValueError(\"Database port must be between 1 and 65535\")\ndef validate_api_key(self, data: dict):\n\"\"\"Validate API key format\"\"\"\napi_key = data.get('api_key')\nif not api_key:\nraise ValueError(\"API key is required\")\nif len(api_key) &lt; 32:\nraise ValueError(\"API key must be at least 32 characters\")\ndef validate_connections(self, data: dict):\n\"\"\"Validate connection pool settings\"\"\"\nmax_conn = data.get('max_connections', 0)\nif max_conn &lt;= 0:\nraise ValueError(\"Max connections must be positive\")\n# Will raise ValueError if validation fails\nconfig = ValidatedConfig().build()\n</code></pre>"},{"location":"resources/config/#prefix-support","title":"Prefix Support","text":"<p>Use prefixes to namespace environment variables:</p> <pre><code>from rick.resource.config import EnvironmentConfig\nclass PrefixedConfig(EnvironmentConfig):\nDB_HOST = 'localhost'\nDB_PORT = 5432\nAPI_KEY = None\n# Set environment variables with prefix:\n# export MYAPP_DB_HOST=production-server\n# export MYAPP_DB_PORT=3306\n# export MYAPP_API_KEY=secret123\n# Build with prefix\nconfig = PrefixedConfig().build(prefix=\"MYAPP_\")\nprint(config.db_host)  # 'production-server'\nprint(config.db_port)  # 3306\n</code></pre>"},{"location":"resources/config/#strorfile-wrapper","title":"StrOrFile Wrapper","text":"<p>Load values from files when environment variable points to a file path:</p> <pre><code>from rick.resource.config import EnvironmentConfig, StrOrFile\nclass SecureConfig(EnvironmentConfig):\nAPI_KEY = StrOrFile(None)\nDB_PASSWORD = StrOrFile(None)\n# Set environment variables:\n# export API_KEY=/secrets/api-key.txt\n# export DB_PASSWORD=plaintext_password\n# Build configuration\nconfig = SecureConfig().build()\n# If API_KEY starts with '/' or './', content is read from file\n# Otherwise, the value is used as-is\nprint(config.api_key)  # Content of /secrets/api-key.txt\nprint(config.db_password)  # \"plaintext_password\"\n</code></pre> <p>StrOrFile Rules:</p> <ul> <li>If value starts with <code>/</code> or <code>./</code>, it's treated as a file path</li> <li>File content is read and whitespace is stripped</li> <li>If file doesn't exist, <code>ValueError</code> is raised (unless <code>silent=True</code>)</li> <li>Use <code>StrOrFile(value, silent=True)</code> to return value as-is if file missing</li> </ul>"},{"location":"resources/config/#complete-example","title":"Complete Example","text":"<pre><code>import os\nfrom rick.resource.config import EnvironmentConfig, StrOrFile\nclass ProductionConfig(EnvironmentConfig):\n# Database settings\nDB_HOST = 'localhost'\nDB_PORT = 5432\nDB_NAME = 'production'\nDB_USER = 'postgres'\nDB_PASSWORD = StrOrFile(None)\n# Application settings\nDEBUG = False\nSECRET_KEY = StrOrFile(None)\nALLOWED_HOSTS = []\n# Feature flags\nENABLE_CACHING = True\nENABLE_MONITORING = True\nMAX_UPLOAD_SIZE = 10485760  # 10MB in bytes\n# API configuration\nAPI_RATE_LIMIT = 100\nAPI_TIMEOUT = 30\ndef validate_database(self, data: dict):\n\"\"\"Ensure database is properly configured\"\"\"\nrequired = ['db_host', 'db_name', 'db_user', 'db_password']\nfor field in required:\nif not data.get(field):\nraise ValueError(f\"Database configuration missing: {field}\")\ndef validate_security(self, data: dict):\n\"\"\"Ensure security settings are production-ready\"\"\"\nif data.get('debug'):\nraise ValueError(\"DEBUG must be False in production\")\nif not data.get('secret_key'):\nraise ValueError(\"SECRET_KEY is required\")\nif len(data.get('secret_key', '')) &lt; 32:\nraise ValueError(\"SECRET_KEY must be at least 32 characters\")\ndef validate_rate_limit(self, data: dict):\n\"\"\"Validate rate limiting configuration\"\"\"\nrate_limit = data.get('api_rate_limit', 0)\nif rate_limit &lt;= 0:\nraise ValueError(\"API rate limit must be positive\")\n# Set environment variables\nos.environ['DB_PASSWORD'] = '/secrets/db-password.txt'\nos.environ['SECRET_KEY'] = '/secrets/secret-key.txt'\nos.environ['ALLOWED_HOSTS'] = 'api.example.com,www.example.com'\n# Build and validate configuration\nconfig = ProductionConfig().build()\n# Use configuration\nprint(f\"Connecting to {config.db_host}:{config.db_port}/{config.db_name}\")\n</code></pre>"},{"location":"resources/config/#jsonfileconfig_1","title":"JsonFileConfig","text":""},{"location":"resources/config/#overview_2","title":"Overview","text":"<p><code>JsonFileConfig</code> loads configuration from JSON files with support for default values, validation, and runtime overrides.</p>"},{"location":"resources/config/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from rick.resource.config import JsonFileConfig\nclass DatabaseConfig(JsonFileConfig):\n# Default values\ndb_host = \"localhost\"\ndb_port = 5432\ndb_name = \"myapp\"\napi_key = None\ndebug = False\n# Load from file (values in file override defaults)\nconfig = DatabaseConfig(\"config.json\").build()\nprint(config.db_host)  # Value from config.json or default\nprint(config.db_port)  # Value from config.json or default\n</code></pre>"},{"location":"resources/config/#example-json-file","title":"Example JSON File","text":"<p>config.json:</p> <pre><code>{\n\"db_host\": \"production-server.example.com\",\n\"db_port\": 3306,\n\"db_name\": \"production_db\",\n\"api_key\": \"prod_api_key_1234567890abcdef\",\n\"debug\": false,\n\"features\": {\n\"enable_caching\": true,\n\"max_connections\": 100\n}\n}\n</code></pre>"},{"location":"resources/config/#with-validation","title":"With Validation","text":"<pre><code>from rick.resource.config import JsonFileConfig\nclass ValidatedConfig(JsonFileConfig):\ndb_host = \"localhost\"\ndb_port = 5432\napi_key = None\ndef validate_database(self, data: dict):\n\"\"\"Validate database configuration\"\"\"\nif not data.get('db_host'):\nraise ValueError(\"Database host is required\")\nport = data.get('db_port', 0)\nif not (1 &lt;= port &lt;= 65535):\nraise ValueError(\"Port must be between 1 and 65535\")\ndef validate_api_key(self, data: dict):\n\"\"\"Validate API key\"\"\"\napi_key = data.get('api_key')\nif not api_key:\nraise ValueError(\"API key is required\")\nif len(api_key) &lt; 16:\nraise ValueError(\"API key must be at least 16 characters\")\n# Raises ValueError if validation fails\nconfig = ValidatedConfig(\"config.json\").build()\n</code></pre>"},{"location":"resources/config/#runtime-overrides","title":"Runtime Overrides","text":"<pre><code>from rick.resource.config import JsonFileConfig\nclass AppConfig(JsonFileConfig):\ndebug = False\nport = 8000\nhost = \"0.0.0.0\"\n# Load from file with runtime overrides\nconfig = AppConfig(\"config.json\").build(override_data={\n'debug': True,\n'port': 9000\n})\nprint(config.debug)  # True (overridden)\nprint(config.port)  # 9000 (overridden)\nprint(config.host)  # Value from file or default\n</code></pre>"},{"location":"resources/config/#reload-configuration","title":"Reload Configuration","text":"<pre><code>from rick.resource.config import JsonFileConfig\nclass ReloadableConfig(JsonFileConfig):\nsetting1 = \"default\"\nsetting2 = 42\nconfig_loader = ReloadableConfig(\"config.json\")\nconfig = config_loader.build()\n# Modify config.json...\n# Reload from disk\nconfig = config_loader.reload()\n</code></pre>"},{"location":"resources/config/#tomlfileconfig_1","title":"TomlFileConfig","text":""},{"location":"resources/config/#overview_3","title":"Overview","text":"<p><code>TomlFileConfig</code> loads configuration from TOML files. Requires Python 3.11+ (built-in <code>tomllib</code>) or the <code>tomli</code> package for older versions.</p>"},{"location":"resources/config/#installation","title":"Installation","text":"<p>For Python &lt; 3.11:</p> <pre><code>pip install tomli\n</code></pre>"},{"location":"resources/config/#basic-usage_2","title":"Basic Usage","text":"<pre><code>from rick.resource.config import TomlFileConfig\nclass AppConfig(TomlFileConfig):\n# Default values\napp_name = \"MyApp\"\nversion = \"1.0.0\"\ndebug = False\n# Nested structures are supported\ndatabase = {}\nlogging = {}\n# Load from TOML file\nconfig = AppConfig(\"config.toml\").build()\nprint(config.app_name)  # Value from config.toml or default\nprint(config.database)  # Nested dict from TOML\n</code></pre>"},{"location":"resources/config/#example-toml-file","title":"Example TOML File","text":"<p>config.toml:</p> <pre><code>app_name = \"Production App\"\nversion = \"2.1.0\"\ndebug = false\n[database]\nhost = \"db.example.com\"\nport = 5432\nname = \"production_db\"\npool_size = 20\n[logging]\nlevel = \"INFO\"\nformat = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\nhandlers = [\"console\", \"file\"]\n[api]\nbase_url = \"https://api.example.com\"\ntimeout = 30\nretry_attempts = 3\n[[services]]\nname = \"auth\"\nurl = \"https://auth.example.com\"\nenabled = true\n[[services]]\nname = \"billing\"\nurl = \"https://billing.example.com\"\nenabled = false\n</code></pre>"},{"location":"resources/config/#with-validation_1","title":"With Validation","text":"<pre><code>from rick.resource.config import TomlFileConfig\nclass ValidatedTomlConfig(TomlFileConfig):\napp_name = \"MyApp\"\ndatabase = {}\nlogging = {}\ndef validate_database(self, data: dict):\n\"\"\"Validate database configuration\"\"\"\ndb = data.get('database', {})\nif not db.get('host'):\nraise ValueError(\"Database host is required\")\nport = db.get('port', 0)\nif not (1 &lt;= port &lt;= 65535):\nraise ValueError(\"Database port must be between 1 and 65535\")\ndef validate_logging(self, data: dict):\n\"\"\"Validate logging configuration\"\"\"\nlogging = data.get('logging', {})\nlevel = logging.get('level', 'INFO')\nvalid_levels = ['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL']\nif level not in valid_levels:\nraise ValueError(f\"Invalid log level: {level}\")\nconfig = ValidatedTomlConfig(\"config.toml\").build()\n</code></pre>"},{"location":"resources/config/#hybridfileconfig_1","title":"HybridFileConfig","text":""},{"location":"resources/config/#overview_4","title":"Overview","text":"<p><code>HybridFileConfig</code> automatically detects the file format (JSON or TOML) based on the file extension and loads accordingly.</p>"},{"location":"resources/config/#supported-extensions","title":"Supported Extensions","text":"<ul> <li><code>.json</code> - Loaded as JSON</li> <li><code>.toml</code> - Loaded as TOML</li> <li><code>.tml</code> - Loaded as TOML</li> </ul>"},{"location":"resources/config/#basic-usage_3","title":"Basic Usage","text":"<pre><code>from rick.resource.config import HybridFileConfig\nclass FlexibleConfig(HybridFileConfig):\ndebug = False\nport = 8000\nhost = \"localhost\"\ndef validate_port(self, data: dict):\nport = data.get('port', 0)\nif not (1 &lt;= port &lt;= 65535):\nraise ValueError(\"Port must be between 1 and 65535\")\n# Works with either format\nconfig1 = FlexibleConfig(\"config.json\").build()\nconfig2 = FlexibleConfig(\"config.toml\").build()\nconfig3 = FlexibleConfig(\"settings.tml\").build()\n</code></pre>"},{"location":"resources/config/#use-case","title":"Use Case","text":"<p>Useful for applications that need to support multiple configuration formats:</p> <pre><code>import sys\nfrom rick.resource.config import HybridFileConfig\nclass AppConfig(HybridFileConfig):\n# Defaults\napp_name = \"MyApp\"\ndebug = False\nport = 8000\n# Load configuration from command line argument\nconfig_file = sys.argv[1] if len(sys.argv) &gt; 1 else \"config.json\"\ntry:\nconfig = AppConfig(config_file).build()\nprint(f\"Loaded configuration from {config_file}\")\nexcept Exception as e:\nprint(f\"Error loading config: {e}\")\nsys.exit(1)\n</code></pre>"},{"location":"resources/config/#convenience-functions","title":"Convenience Functions","text":"<p>Rick provides simple functions for quick configuration loading without defining classes:</p>"},{"location":"resources/config/#json_config_file","title":"json_config_file()","text":"<p>Load JSON configuration file directly:</p> <pre><code>from rick.resource.config import json_config_file\n# Simple loading\nconfig = json_config_file(\"config.json\")\nprint(config.db_host)\nprint(config.api_key)\n</code></pre>"},{"location":"resources/config/#toml_config_file","title":"toml_config_file()","text":"<p>Load TOML configuration file directly:</p> <pre><code>from rick.resource.config import toml_config_file\n# Simple loading\nconfig = toml_config_file(\"config.toml\")\nprint(config.app_name)\nprint(config.database)\n</code></pre>"},{"location":"resources/config/#config_file","title":"config_file()","text":"<p>Auto-detect and load configuration file:</p> <pre><code>from rick.resource.config import config_file\n# Auto-detect format based on extension\nconfig = config_file(\"config.json\")  # or config.toml\nprint(config.debug)\nprint(config.port)\n</code></pre>"},{"location":"resources/config/#json_file-legacy","title":"json_file() (Legacy)","text":"<p>Simple JSON file loader (legacy function):</p> <pre><code>from rick.resource.config import json_file\n# Basic JSON loading\nconfig = json_file(\"config.json\")\n</code></pre>"},{"location":"resources/config/#error-handling","title":"Error Handling","text":""},{"location":"resources/config/#fileconfigerror","title":"FileConfigError","text":"<p>All file configuration classes raise <code>FileConfigError</code> for configuration-related errors:</p> <pre><code>from rick.resource.config import JsonFileConfig, FileConfigError\nclass MyConfig(JsonFileConfig):\ndebug = False\ntry:\nconfig = MyConfig(\"nonexistent.json\").build()\nexcept FileConfigError as e:\nprint(f\"Configuration error: {e}\")\n# Handle error: use defaults, exit, etc.\n</code></pre>"},{"location":"resources/config/#validation-errors","title":"Validation Errors","text":"<p>Validation functions should raise <code>ValueError</code> for validation failures:</p> <pre><code>from rick.resource.config import EnvironmentConfig\nclass StrictConfig(EnvironmentConfig):\nAPI_KEY = None\ndef validate_api_key(self, data: dict):\nif not data.get('api_key'):\nraise ValueError(\"API_KEY is required\")\ntry:\nconfig = StrictConfig().build()\nexcept ValueError as e:\nprint(f\"Validation failed: {e}\")\n</code></pre>"},{"location":"resources/config/#best-practices","title":"Best Practices","text":""},{"location":"resources/config/#1-use-validation-for-critical-settings","title":"1. Use Validation for Critical Settings","text":"<pre><code>from rick.resource.config import JsonFileConfig\nclass ProductionConfig(JsonFileConfig):\nsecret_key = None\ndatabase_url = None\ndef validate_production(self, data: dict):\n\"\"\"Ensure production-critical settings are present\"\"\"\nif not data.get('secret_key'):\nraise ValueError(\"SECRET_KEY is required in production\")\nif not data.get('database_url'):\nraise ValueError(\"DATABASE_URL is required in production\")\nconfig = ProductionConfig(\"production.json\").build()\n</code></pre>"},{"location":"resources/config/#2-provide-sensible-defaults","title":"2. Provide Sensible Defaults","text":"<pre><code>from rick.resource.config import EnvironmentConfig\nclass AppConfig(EnvironmentConfig):\n# Good: sensible defaults for development\nDEBUG = True\nLOG_LEVEL = 'DEBUG'\nMAX_WORKERS = 4\nCACHE_TTL = 300\n# Override in production via environment variables\n</code></pre>"},{"location":"resources/config/#3-use-type-hints-via-default-values","title":"3. Use Type Hints via Default Values","text":"<pre><code>from rick.resource.config import EnvironmentConfig\nclass TypedConfig(EnvironmentConfig):\n# Type is inferred from default value\nPORT = 8000  # int\nDEBUG = False  # bool\nALLOWED_HOSTS = []  # list\nDATABASE_CONFIG = {}  # dict\nAPI_KEY = None  # str (None defaults to str)\n</code></pre>"},{"location":"resources/config/#4-separate-concerns-with-multiple-configs","title":"4. Separate Concerns with Multiple Configs","text":"<pre><code>from rick.resource.config import JsonFileConfig\nclass DatabaseConfig(JsonFileConfig):\nhost = \"localhost\"\nport = 5432\ndef validate_database(self, data):\n# Database-specific validation\npass\nclass CacheConfig(JsonFileConfig):\nredis_host = \"localhost\"\nredis_port = 6379\ndef validate_cache(self, data):\n# Cache-specific validation\npass\n# Load separate configs\ndb_config = DatabaseConfig(\"database.json\").build()\ncache_config = CacheConfig(\"cache.json\").build()\n</code></pre>"},{"location":"resources/config/#5-use-strorfile-for-secrets","title":"5. Use StrOrFile for Secrets","text":"<pre><code>from rick.resource.config import EnvironmentConfig, StrOrFile\nclass SecureConfig(EnvironmentConfig):\n# Load from files in production, plain values in development\nDB_PASSWORD = StrOrFile(None)\nAPI_SECRET = StrOrFile(None)\nJWT_KEY = StrOrFile(None)\n# Development: export DB_PASSWORD=dev_password\n# Production: export DB_PASSWORD=/secrets/db-password\nconfig = SecureConfig().build()\n</code></pre>"},{"location":"resources/config/#6-environment-specific-configuration","title":"6. Environment-Specific Configuration","text":"<pre><code>import os\nfrom rick.resource.config import JsonFileConfig\nclass AppConfig(JsonFileConfig):\ndebug = False\nport = 8000\n# Load config based on environment\nenv = os.getenv('APP_ENV', 'development')\nconfig_files = {\n'development': 'config.dev.json',\n'staging': 'config.staging.json',\n'production': 'config.prod.json'\n}\nconfig_file = config_files.get(env, 'config.json')\nconfig = AppConfig(config_file).build()\n</code></pre>"},{"location":"resources/config/#7-combine-environment-and-file-configuration","title":"7. Combine Environment and File Configuration","text":"<pre><code>from rick.resource.config import EnvironmentConfig, JsonFileConfig\n# Load base config from file\nclass BaseConfig(JsonFileConfig):\napp_name = \"MyApp\"\nport = 8000\nfile_config = BaseConfig(\"config.json\").build()\n# Override with environment variables\nclass EnvConfig(EnvironmentConfig):\nAPP_NAME = file_config.app_name\nPORT = file_config.port\nDEBUG = False  # Override in env\nfinal_config = EnvConfig().build()\n</code></pre>"},{"location":"resources/config/#complete-example_1","title":"Complete Example","text":"<pre><code>import os\nimport sys\nfrom rick.resource.config import HybridFileConfig, EnvironmentConfig, StrOrFile\nclass ApplicationConfig(HybridFileConfig):\n\"\"\"File-based configuration with defaults\"\"\"\n# Application settings\napp_name = \"MyApplication\"\nversion = \"1.0.0\"\ndebug = False\n# Server settings\nhost = \"0.0.0.0\"\nport = 8000\nworkers = 4\n# Database settings\ndatabase = {\n\"host\": \"localhost\",\n\"port\": 5432,\n\"name\": \"myapp\",\n\"pool_size\": 10\n}\n# Cache settings\ncache = {\n\"enabled\": True,\n\"backend\": \"redis\",\n\"ttl\": 300\n}\n# Validation\ndef validate_server(self, data: dict):\nport = data.get('port', 0)\nif not (1 &lt;= port &lt;= 65535):\nraise ValueError(\"Port must be between 1 and 65535\")\nworkers = data.get('workers', 0)\nif workers &lt;= 0:\nraise ValueError(\"Workers must be positive\")\ndef validate_database(self, data: dict):\ndb = data.get('database', {})\nif not db.get('host'):\nraise ValueError(\"Database host is required\")\nclass RuntimeConfig(EnvironmentConfig):\n\"\"\"Environment-based runtime overrides\"\"\"\n# Sensitive values loaded from environment\nSECRET_KEY = StrOrFile(None)\nDATABASE_PASSWORD = StrOrFile(None)\nAPI_KEY = StrOrFile(None)\n# Runtime overrides\nDEBUG = False\nPORT = 8000\nWORKERS = 4\ndef validate_secrets(self, data: dict):\nif not data.get('secret_key'):\nraise ValueError(\"SECRET_KEY is required\")\nif len(data.get('secret_key', '')) &lt; 32:\nraise ValueError(\"SECRET_KEY must be at least 32 characters\")\ndef load_configuration():\n\"\"\"Load application configuration\"\"\"\n# Determine config file\nenv = os.getenv('APP_ENV', 'development')\nconfig_file = f\"config.{env}.json\"  # or .toml\ntry:\n# Load base configuration from file\nfile_config = ApplicationConfig(config_file).build()\n# Load runtime configuration from environment\nruntime_config = RuntimeConfig().build()\n# Merge configurations\nfinal_config = file_config.asdict()\nfinal_config.update(runtime_config.asdict())\nfrom rick.base import ShallowContainer\nreturn ShallowContainer(final_config)\nexcept Exception as e:\nprint(f\"Failed to load configuration: {e}\", file=sys.stderr)\nsys.exit(1)\n# Use in application\nif __name__ == \"__main__\":\nconfig = load_configuration()\nprint(f\"Starting {config.app_name} v{config.version}\")\nprint(f\"Server: {config.host}:{config.port}\")\nprint(f\"Workers: {config.workers}\")\nprint(f\"Debug: {config.debug}\")\nprint(f\"Database: {config.database['host']}:{config.database['port']}\")\n</code></pre>"},{"location":"resources/config/#related-topics","title":"Related Topics","text":"<ul> <li>Redis Cache - Use configuration to set up Redis caching</li> <li>Serializers - JSON serialization used in config files</li> <li>Validators - Validation patterns similar to config validation</li> </ul>"},{"location":"resources/console/","title":"Console Output","text":"<p>Rick provides utilities for colored and formatted console output through the <code>AnsiColor</code> and <code>ConsoleWriter</code> classes. These components make it easy to create visually appealing command-line interfaces with colored text, backgrounds, and text attributes.</p> <p>Location: <code>rick.resource.console</code></p>"},{"location":"resources/console/#overview","title":"Overview","text":"<p>Console output utilities in Rick provide:</p> <ul> <li>ANSI Color Support - 16 foreground and background colors (standard and light variants)</li> <li>Text Attributes - Bold, dim, underline, and reversed text</li> <li>High-Level Writer - Pre-configured methods for common output types (success, error, warning, header)</li> <li>Stream Control - Separate stdout and stderr output</li> <li>Flexible Styling - Combine colors, backgrounds, and attributes</li> </ul>"},{"location":"resources/console/#available-components","title":"Available Components","text":""},{"location":"resources/console/#ansicolor","title":"AnsiColor","text":"<p>Low-level ANSI color formatting for text output.</p> <p>Location: <code>rick.resource.console.AnsiColor</code></p>"},{"location":"resources/console/#consolewriter","title":"ConsoleWriter","text":"<p>High-level console writer with semantic output methods.</p> <p>Location: <code>rick.resource.console.ConsoleWriter</code></p>"},{"location":"resources/console/#ansicolor_1","title":"AnsiColor","text":""},{"location":"resources/console/#overview_1","title":"Overview","text":"<p><code>AnsiColor</code> provides dynamic color methods for all supported colors. Each color can be called as a method with optional background color and text attributes.</p>"},{"location":"resources/console/#supported-colors","title":"Supported Colors","text":"<p>Foreground Colors:</p> Color Method Color Method Black <code>black()</code> Light Black <code>light_black()</code> Red <code>red()</code> Light Red <code>light_red()</code> Green <code>green()</code> Light Green <code>light_green()</code> Yellow <code>yellow()</code> Light Yellow <code>light_yellow()</code> Blue <code>blue()</code> Light Blue <code>light_blue()</code> Magenta <code>magenta()</code> Light Magenta <code>light_magenta()</code> Cyan <code>cyan()</code> Light Cyan <code>light_cyan()</code> White <code>white()</code> Light White <code>light_white()</code> <p>Background Colors:</p> <p>All foreground colors can be used as background colors by passing them as the second parameter.</p> <p>Text Attributes:</p> Attribute Description <code>bold</code> Bold text <code>dim</code> Dimmed text <code>underline</code> Underlined text <code>reversed</code> Reversed foreground/background"},{"location":"resources/console/#basic-usage","title":"Basic Usage","text":"<pre><code>from rick.resource.console import AnsiColor\ncolor = AnsiColor()\n# Simple colored text\nprint(color.red('This is red text'))\nprint(color.green('This is green text'))\nprint(color.blue('This is blue text'))\n# Light color variants\nprint(color.light_red('Light red text'))\nprint(color.light_green('Light green text'))\nprint(color.light_blue('Light blue text'))\n</code></pre>"},{"location":"resources/console/#with-background-colors","title":"With Background Colors","text":"<pre><code>from rick.resource.console import AnsiColor\ncolor = AnsiColor()\n# Text with background color\nprint(color.red('Red text on white background', 'white'))\nprint(color.green('Green text on black background', 'black'))\nprint(color.yellow('Yellow text on blue background', 'blue'))\n# Light backgrounds\nprint(color.black('Black text on light_yellow background', 'light_yellow'))\n</code></pre>"},{"location":"resources/console/#with-text-attributes","title":"With Text Attributes","text":"<pre><code>from rick.resource.console import AnsiColor\ncolor = AnsiColor()\n# Single attribute\nprint(color.red('Bold red text', attr='bold'))\nprint(color.blue('Underlined blue text', attr='underline'))\nprint(color.green('Dim green text', attr='dim'))\n# Multiple attributes\nprint(color.yellow('Bold and underlined', attr=['bold', 'underline']))\nprint(color.magenta('Bold, dim, and underlined', attr=['bold', 'dim', 'underline']))\n</code></pre>"},{"location":"resources/console/#complete-styling","title":"Complete Styling","text":"<pre><code>from rick.resource.console import AnsiColor\ncolor = AnsiColor()\n# Combine color, background, and attributes\nmessage = color.green(\n'SUCCESS: Operation completed',\n'white',\n['bold', 'underline']\n)\nprint(message)\n# Build formatted output\nerror = color.red('ERROR:', attr='bold')\ndetails = color.white('File not found: config.json')\nprint(f\"{error} {details}\")\n</code></pre>"},{"location":"resources/console/#method-signature","title":"Method Signature","text":"<p>All color methods follow this signature:</p> <pre><code>color.COLOR_NAME(message, bg_color=None, attr=None)\n</code></pre> <p>Parameters:</p> <ul> <li><code>message</code> (str) - Text to colorize</li> <li><code>bg_color</code> (str, optional) - Background color name</li> <li><code>attr</code> (str or list, optional) - Single attribute or list of attributes</li> </ul> <p>Returns: Formatted string with ANSI escape codes</p>"},{"location":"resources/console/#color-combinations","title":"Color Combinations","text":"<pre><code>from rick.resource.console import AnsiColor\ncolor = AnsiColor()\n# Info message\ninfo = color.blue('[INFO]', attr='bold')\nprint(f\"{info} Application started\")\n# Success message\nsuccess = color.green('[SUCCESS]', attr='bold')\nprint(f\"{success} Database connection established\")\n# Warning message\nwarning = color.yellow('[WARNING]', 'black', 'bold')\nprint(f\"{warning} Low disk space\")\n# Error message\nerror = color.red('[ERROR]', attr=['bold', 'underline'])\nprint(f\"{error} Failed to load configuration\")\n</code></pre>"},{"location":"resources/console/#building-status-indicators","title":"Building Status Indicators","text":"<pre><code>from rick.resource.console import AnsiColor\ncolor = AnsiColor()\ndef print_status(status, message):\n\"\"\"Print status with color coding\"\"\"\nif status == 'success':\nicon = color.green('\u2713', attr='bold')\nelif status == 'error':\nicon = color.red('\u2717', attr='bold')\nelif status == 'warning':\nicon = color.yellow('!', attr='bold')\nelse:\nicon = color.blue('i', attr='bold')\nprint(f\"{icon} {message}\")\n# Usage\nprint_status('success', 'All tests passed')\nprint_status('error', 'Connection failed')\nprint_status('warning', 'Deprecated API usage')\nprint_status('info', 'Loading configuration')\n</code></pre>"},{"location":"resources/console/#consolewriter_1","title":"ConsoleWriter","text":""},{"location":"resources/console/#overview_2","title":"Overview","text":"<p><code>ConsoleWriter</code> provides a high-level interface for console output with pre-configured semantic methods for common output types. It integrates with <code>AnsiColor</code> to provide colored output.</p>"},{"location":"resources/console/#constructor","title":"Constructor","text":"<pre><code>ConsoleWriter(stdout=sys.stdout, stderr=sys.stderr, colorizer=AnsiColor())\n</code></pre> <p>Parameters:</p> <ul> <li><code>stdout</code> - Output stream for standard output (default: <code>sys.stdout</code>)</li> <li><code>stderr</code> - Output stream for error output (default: <code>sys.stderr</code>)</li> <li><code>colorizer</code> - AnsiColor instance for colorization (default: new <code>AnsiColor()</code>)</li> </ul>"},{"location":"resources/console/#methods","title":"Methods","text":""},{"location":"resources/console/#headermessage-eoltrue","title":"header(message, eol=True)","text":"<p>Write a header message in bold white.</p> <pre><code>from rick.resource.console import ConsoleWriter\nconsole = ConsoleWriter()\nconsole.header('Application Configuration')\nconsole.header('=' * 40)\n</code></pre>"},{"location":"resources/console/#successmessage-eoltrue","title":"success(message, eol=True)","text":"<p>Write a success message in green.</p> <pre><code>from rick.resource.console import ConsoleWriter\nconsole = ConsoleWriter()\nconsole.success('Configuration loaded successfully')\nconsole.success('Database connection established')\n</code></pre>"},{"location":"resources/console/#warnmessage-eoltrue","title":"warn(message, eol=True)","text":"<p>Write a warning message in yellow.</p> <pre><code>from rick.resource.console import ConsoleWriter\nconsole = ConsoleWriter()\nconsole.warn('Configuration file not found, using defaults')\nconsole.warn('API rate limit approaching threshold')\n</code></pre>"},{"location":"resources/console/#errormessage-eoltrue","title":"error(message, eol=True)","text":"<p>Write an error message in red to stderr.</p> <pre><code>from rick.resource.console import ConsoleWriter\nconsole = ConsoleWriter()\nconsole.error('Failed to connect to database')\nconsole.error('Invalid configuration format')\n</code></pre>"},{"location":"resources/console/#writemessage-eoltrue","title":"write(message, eol=True)","text":"<p>Write a plain message to stdout.</p> <pre><code>from rick.resource.console import ConsoleWriter\nconsole = ConsoleWriter()\nconsole.write('Starting application...')\nconsole.write('Processing data...', eol=False)  # No newline\nconsole.write(' Done')\n</code></pre>"},{"location":"resources/console/#write_errormessage-eoltrue","title":"write_error(message, eol=True)","text":"<p>Write a plain message to stderr.</p> <pre><code>from rick.resource.console import ConsoleWriter\nconsole = ConsoleWriter()\nconsole.write_error('Critical: System resources low')\n</code></pre>"},{"location":"resources/console/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from rick.resource.console import ConsoleWriter\nconsole = ConsoleWriter()\n# Application startup\nconsole.header('My Application v1.0')\nconsole.header('=' * 50)\nconsole.write('')\n# Status messages\nconsole.write('Loading configuration...')\nconsole.success('Configuration loaded')\nconsole.write('Connecting to database...')\nconsole.success('Database connection established')\n# Warning\nconsole.warn('Cache is disabled')\n# Error\nconsole.error('Failed to load plugin: analytics')\n</code></pre> <p>Output:</p> <pre><code>My Application v1.0  (bold white)\n================================================== (bold white)\n\nLoading configuration...\nConfiguration loaded  (green)\nConnecting to database...\nDatabase connection established  (green)\nCache is disabled  (yellow)\nFailed to load plugin: analytics  (red, to stderr)\n</code></pre>"},{"location":"resources/console/#building-cli-applications","title":"Building CLI Applications","text":"<pre><code>import sys\nfrom rick.resource.console import ConsoleWriter\ndef main():\nconsole = ConsoleWriter()\nconsole.header('Database Migration Tool')\nconsole.header('=' * 40)\nconsole.write('')\n# Step 1\nconsole.write('Step 1: Checking database connection...')\ntry:\ncheck_database()\nconsole.success('  Database is accessible')\nexcept Exception as e:\nconsole.error(f'  Connection failed: {e}')\nreturn 1\n# Step 2\nconsole.write('Step 2: Running migrations...')\ntry:\nrun_migrations()\nconsole.success('  All migrations applied')\nexcept Exception as e:\nconsole.error(f'  Migration failed: {e}')\nreturn 1\n# Step 3\nconsole.write('Step 3: Verifying data integrity...')\ntry:\nverify_data()\nconsole.success('  Data integrity verified')\nexcept Exception as e:\nconsole.warn(f'  Verification warning: {e}')\nconsole.write('')\nconsole.success('Migration completed successfully')\nreturn 0\nif __name__ == '__main__':\nsys.exit(main())\n</code></pre>"},{"location":"resources/console/#progress-indicators","title":"Progress Indicators","text":"<pre><code>from rick.resource.console import ConsoleWriter\nimport time\nconsole = ConsoleWriter()\ntasks = [\n'Loading configuration',\n'Initializing database',\n'Starting services',\n'Running health checks'\n]\nfor task in tasks:\nconsole.write(f'{task}...', eol=False)\ntime.sleep(1)  # Simulate work\nconsole.success(' Done')\nconsole.write('')\nconsole.success('All tasks completed')\n</code></pre>"},{"location":"resources/console/#custom-output-streams","title":"Custom Output Streams","text":"<pre><code>from rick.resource.console import ConsoleWriter\nfrom io import StringIO\n# Capture output to strings\nstdout_buffer = StringIO()\nstderr_buffer = StringIO()\nconsole = ConsoleWriter(stdout=stdout_buffer, stderr=stderr_buffer)\nconsole.success('Success message')\nconsole.error('Error message')\n# Get captured output\nstdout_content = stdout_buffer.getvalue()\nstderr_content = stderr_buffer.getvalue()\nprint(f\"Stdout: {stdout_content}\")\nprint(f\"Stderr: {stderr_content}\")\n</code></pre>"},{"location":"resources/console/#integration-with-ansicolor","title":"Integration with AnsiColor","text":"<pre><code>from rick.resource.console import ConsoleWriter, AnsiColor\ncolor = AnsiColor()\nconsole = ConsoleWriter(colorizer=color)\n# Use ConsoleWriter for semantic messages\nconsole.header('Processing Files')\n# Use AnsiColor for custom styling\nfilename = color.cyan('config.json', attr='bold')\nconsole.write(f'Reading {filename}')\nstatus = color.green('OK', attr='bold')\nconsole.write(f'Status: {status}')\n</code></pre>"},{"location":"resources/console/#advanced-usage","title":"Advanced Usage","text":""},{"location":"resources/console/#custom-console-class","title":"Custom Console Class","text":"<pre><code>from rick.resource.console import ConsoleWriter, AnsiColor\nclass CustomConsole(ConsoleWriter):\ndef info(self, message, eol=True):\n\"\"\"Add info method\"\"\"\nformatted = self.colorizer.blue(f'[INFO] {message}')\nself.write(formatted, eol)\ndef debug(self, message, eol=True):\n\"\"\"Add debug method\"\"\"\nformatted = self.colorizer.light_black(f'[DEBUG] {message}')\nself.write(formatted, eol)\ndef critical(self, message, eol=True):\n\"\"\"Add critical method\"\"\"\nformatted = self.colorizer.red(f'[CRITICAL] {message}', attr='bold')\nself.write_error(formatted, eol)\n# Usage\nconsole = CustomConsole()\nconsole.info('Application started')\nconsole.debug('Loading configuration from /etc/app/config.json')\nconsole.critical('System out of memory')\n</code></pre>"},{"location":"resources/console/#logging-integration","title":"Logging Integration","text":"<pre><code>from rick.resource.console import ConsoleWriter, AnsiColor\nimport logging\nclass ColoredConsoleHandler(logging.Handler):\ndef __init__(self):\nsuper().__init__()\nself.console = ConsoleWriter()\ndef emit(self, record):\nmsg = self.format(record)\nif record.levelno &gt;= logging.ERROR:\nself.console.error(msg)\nelif record.levelno &gt;= logging.WARNING:\nself.console.warn(msg)\nelif record.levelno &gt;= logging.INFO:\nself.console.write(msg)\nelse:  # DEBUG\ncolor = AnsiColor()\nself.console.write(color.light_black(msg))\n# Setup logging\nlogger = logging.getLogger('myapp')\nlogger.addHandler(ColoredConsoleHandler())\nlogger.setLevel(logging.DEBUG)\n# Use logger\nlogger.debug('Debug message')\nlogger.info('Info message')\nlogger.warning('Warning message')\nlogger.error('Error message')\n</code></pre>"},{"location":"resources/console/#table-output","title":"Table Output","text":"<pre><code>from rick.resource.console import ConsoleWriter, AnsiColor\ndef print_table(headers, rows):\n\"\"\"Print a formatted table with colors\"\"\"\nconsole = ConsoleWriter()\ncolor = AnsiColor()\n# Print header\nheader_text = ' | '.join(headers)\nconsole.header(header_text)\nconsole.header('-' * len(header_text))\n# Print rows\nfor row in rows:\n# Color first column\nfirst = color.cyan(str(row[0]), attr='bold')\nrest = ' | '.join(str(cell) for cell in row[1:])\nconsole.write(f'{first} | {rest}')\n# Usage\nheaders = ['ID', 'Name', 'Status', 'Count']\nrows = [\n[1, 'Item A', 'Active', 100],\n[2, 'Item B', 'Inactive', 50],\n[3, 'Item C', 'Active', 75]\n]\nprint_table(headers, rows)\n</code></pre>"},{"location":"resources/console/#progress-bar","title":"Progress Bar","text":"<pre><code>from rick.resource.console import ConsoleWriter, AnsiColor\nimport time\ndef progress_bar(total, console, color):\n\"\"\"Simple progress bar\"\"\"\nbar_length = 40\nfor i in range(total + 1):\npercent = i / total\nfilled = int(bar_length * percent)\nbar = '\u2588' * filled + '-' * (bar_length - filled)\nif percent &lt; 0.5:\nbar_colored = color.red(bar)\nelif percent &lt; 0.8:\nbar_colored = color.yellow(bar)\nelse:\nbar_colored = color.green(bar)\nconsole.write(f'\\r[{bar_colored}] {int(percent * 100)}%', eol=False)\ntime.sleep(0.1)\nconsole.write('')  # New line\n# Usage\nconsole = ConsoleWriter()\ncolor = AnsiColor()\nconsole.header('Processing Files')\nprogress_bar(100, console, color)\nconsole.success('Processing complete')\n</code></pre>"},{"location":"resources/console/#interactive-menu","title":"Interactive Menu","text":"<pre><code>from rick.resource.console import ConsoleWriter, AnsiColor\ndef show_menu():\n\"\"\"Display an interactive menu\"\"\"\nconsole = ConsoleWriter()\ncolor = AnsiColor()\nconsole.header('Main Menu')\nconsole.header('=' * 40)\nconsole.write('')\noptions = [\n('1', 'Start Application', 'green'),\n('2', 'Stop Application', 'red'),\n('3', 'View Logs', 'blue'),\n('4', 'Configuration', 'yellow'),\n('Q', 'Quit', 'white')\n]\nfor key, label, text_color in options:\nkey_colored = color.cyan(f'[{key}]', attr='bold')\nlabel_colored = getattr(color, text_color)(label)\nconsole.write(f'  {key_colored} {label_colored}')\nconsole.write('')\nreturn input('Select option: ')\n# Usage\nchoice = show_menu()\n</code></pre>"},{"location":"resources/console/#best-practices","title":"Best Practices","text":""},{"location":"resources/console/#1-use-semantic-methods","title":"1. Use Semantic Methods","text":"<pre><code>from rick.resource.console import ConsoleWriter\nconsole = ConsoleWriter()\n# Good: Use semantic methods\nconsole.success('Operation completed')\nconsole.error('Operation failed')\nconsole.warn('Low memory')\n# Less clear: Using write for everything\nconsole.write('Operation completed')\nconsole.write('Operation failed')\nconsole.write('Low memory')\n</code></pre>"},{"location":"resources/console/#2-consistent-color-scheme","title":"2. Consistent Color Scheme","text":"<pre><code>from rick.resource.console import AnsiColor\ncolor = AnsiColor()\n# Define consistent color scheme\nSTATUS_COLORS = {\n'active': 'green',\n'inactive': 'red',\n'pending': 'yellow',\n'unknown': 'light_black'\n}\ndef colorize_status(status):\ncolor_name = STATUS_COLORS.get(status, 'white')\nreturn getattr(color, color_name)(status.upper(), attr='bold')\n# Usage\nprint(f\"Server status: {colorize_status('active')}\")\n</code></pre>"},{"location":"resources/console/#3-handle-no-color-environments","title":"3. Handle No-Color Environments","text":"<pre><code>import os\nfrom rick.resource.console import ConsoleWriter, AnsiColor\ndef create_console():\n\"\"\"Create console with color support detection\"\"\"\n# Check for NO_COLOR environment variable\nif os.getenv('NO_COLOR'):\n# Return console without colorization\nreturn PlainConsole()\nreturn ConsoleWriter()\nclass PlainConsole:\n\"\"\"Console without colors for CI/CD environments\"\"\"\ndef header(self, message, eol=True):\nprint(message)\ndef success(self, message, eol=True):\nprint(f'[SUCCESS] {message}')\ndef warn(self, message, eol=True):\nprint(f'[WARNING] {message}')\ndef error(self, message, eol=True):\nprint(f'[ERROR] {message}')\n</code></pre>"},{"location":"resources/console/#4-separate-stdout-and-stderr","title":"4. Separate stdout and stderr","text":"<pre><code>from rick.resource.console import ConsoleWriter\nconsole = ConsoleWriter()\n# Good: Errors to stderr\nconsole.error('Connection failed')\n# Good: Normal output to stdout\nconsole.write('Processing data...')\nconsole.success('Processing complete')\n</code></pre>"},{"location":"resources/console/#5-use-eol-parameter-for-dynamic-output","title":"5. Use eol Parameter for Dynamic Output","text":"<pre><code>from rick.resource.console import ConsoleWriter\nimport time\nconsole = ConsoleWriter()\n# Progress indicator\nconsole.write('Loading', eol=False)\nfor i in range(5):\nconsole.write('.', eol=False)\ntime.sleep(0.5)\nconsole.write(' Done')\n</code></pre>"},{"location":"resources/console/#terminal-compatibility","title":"Terminal Compatibility","text":"<p>ANSI color codes are supported on:</p> <ul> <li>Linux/Unix - Full support in all modern terminals</li> <li>macOS - Full support in Terminal.app and iTerm2</li> <li>Windows 10+ - Full support in Windows Terminal and PowerShell</li> <li>Windows (older) - Limited support (may require ANSICON or colorama)</li> </ul> <p>For maximum compatibility, consider using environment detection:</p> <pre><code>import sys\nimport os\ndef supports_color():\n\"\"\"Check if terminal supports ANSI colors\"\"\"\n# Check for NO_COLOR environment variable\nif os.getenv('NO_COLOR'):\nreturn False\n# Check if stdout is a TTY\nif not hasattr(sys.stdout, 'isatty'):\nreturn False\nif not sys.stdout.isatty():\nreturn False\n# Windows check\nif sys.platform == 'win32':\nreturn sys.version_info &gt;= (3, 6)\nreturn True\n</code></pre>"},{"location":"resources/console/#related-topics","title":"Related Topics","text":"<ul> <li>Configuration - Use console output in configuration loaders</li> <li>Forms - Display form validation errors with colors</li> <li>Validators - Show validation results with formatting</li> </ul>"},{"location":"resources/file/","title":"File Operations","text":"<p>Rick provides file handling utilities built on top of the stream processing module. The file module offers enhanced file reading capabilities with metadata support, chunked reading, and multipart file handling.</p>"},{"location":"resources/file/#overview","title":"Overview","text":"<p>The file module includes:</p> <ul> <li>FilePart - Alias for FileSlice, representing a file part</li> <li>FileReader - Enhanced multipart file reader with metadata and chunked reading</li> </ul>"},{"location":"resources/file/#why-filereader","title":"Why FileReader?","text":"<p>FileReader extends MultiPartReader with file-specific features:</p> <ul> <li>Store file metadata (name, content type, custom attributes)</li> <li>Read files in fixed-size chunks</li> <li>Handle multipart files with metadata</li> <li>Process uploaded files or split archives</li> <li>Manage file streams with additional context</li> </ul>"},{"location":"resources/file/#filepart","title":"FilePart","text":"<p><code>FilePart</code> is an alias for <code>FileSlice</code> from the stream module, providing semantic clarity when working with file parts.</p> <pre><code>from rick.resource.file import FilePart\n# Create a file part\npart = FilePart('/path/to/file.dat')\n# FilePart is identical to FileSlice\nprint(f\"Part size: {part.size} bytes\")\n</code></pre> <p>See FileSlice documentation for detailed usage.</p>"},{"location":"resources/file/#filereader","title":"FileReader","text":"<p>Enhanced file reader with metadata support and chunked reading capabilities.</p>"},{"location":"resources/file/#basic-usage","title":"Basic Usage","text":"<pre><code>from rick.resource.file import FileReader, FilePart\n# Create parts\nparts = [\nFilePart('/tmp/file1.dat'),\nFilePart('/tmp/file2.dat'),\n]\n# Create file reader with metadata\nreader = FileReader(\nparts=parts,\nname='document.pdf',\ncontent_type='application/pdf'\n)\n# Access metadata\nprint(f\"Filename: {reader.name}\")\nprint(f\"Content-Type: {reader.content_type}\")\nprint(f\"Total size: {reader.size} bytes\")\n# Read entire file as BytesIO\nbuffer = reader.read_block()\nprint(f\"Read {buffer.getbuffer().nbytes} bytes\")\n# Read in fixed-size chunks\nfor chunk in reader.read_chunked(1024 * 1024):  # 1MB chunks\nprocess_chunk(chunk)\n</code></pre>"},{"location":"resources/file/#constructor","title":"Constructor","text":"<p>FileReader(parts, name=\"\", content_type=\"application/octet-stream\", **kwargs)</p> <p>Creates a new FileReader instance with metadata.</p> <p>Parameters:</p> <ul> <li><code>parts</code> (list): List of FilePart or SliceReader objects</li> <li><code>name</code> (str): Filename (default: \"\")</li> <li><code>content_type</code> (str): MIME type (default: \"application/octet-stream\")</li> <li><code>**kwargs</code>: Custom properties to attach to the reader</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: If a custom property name conflicts with existing attributes</li> </ul> <p>Attributes:</p> <ul> <li><code>name</code>: Filename</li> <li><code>content_type</code>: MIME type</li> <li><code>parts</code>: List of file parts</li> <li><code>size</code>: Total size of all parts</li> <li><code>offset</code>: Current stream position</li> <li>Custom attributes from kwargs</li> </ul> <p>Example:</p> <pre><code>from rick.resource.file import FileReader, FilePart\nparts = [FilePart('/data/video.mp4')]\nreader = FileReader(\nparts=parts,\nname='vacation.mp4',\ncontent_type='video/mp4',\nupload_id='abc123',\nuser_id=42\n)\nprint(f\"File: {reader.name}\")\nprint(f\"Type: {reader.content_type}\")\nprint(f\"Upload ID: {reader.upload_id}\")\nprint(f\"User ID: {reader.user_id}\")\n</code></pre>"},{"location":"resources/file/#methods","title":"Methods","text":""},{"location":"resources/file/#read_blockoffset0-limit-1-bytesio","title":"read_block(offset=0, limit=-1) -&gt; BytesIO","text":"<p>Read data as a single BytesIO buffer.</p> <p>Parameters:</p> <ul> <li><code>offset</code> (int): Starting byte position (default: 0)</li> <li><code>limit</code> (int): Number of bytes to read (default: -1 for all)</li> </ul> <p>Returns:</p> <ul> <li><code>BytesIO</code>: Buffer containing the read data (position at end, use seek(0) to read)</li> </ul> <p>Example:</p> <pre><code>reader = FileReader(parts=[FilePart('/data/file.bin')])\n# Read entire file\nbuffer = reader.read_block()\nbuffer.seek(0)  # Reset position to beginning\ndata = buffer.read()\n# Read first 1KB\nbuffer = reader.read_block(offset=0, limit=1024)\nbuffer.seek(0)\nheader = buffer.read()\n# Read 1KB starting at position 1000\nbuffer = reader.read_block(offset=1000, limit=1024)\nbuffer.seek(0)\nchunk = buffer.read()\n</code></pre>"},{"location":"resources/file/#read_chunkedblock_size-int-iteratorbytesio","title":"read_chunked(block_size: int) -&gt; Iterator[BytesIO]","text":"<p>Read file in fixed-size chunks as BytesIO buffers.</p> <p>Parameters:</p> <ul> <li><code>block_size</code> (int): Size of each chunk in bytes</li> </ul> <p>Returns:</p> <ul> <li>Iterator yielding <code>BytesIO</code>: Buffers of size block_size (last chunk may be smaller)</li> </ul> <p>Example:</p> <pre><code>reader = FileReader(parts=[FilePart('/data/largefile.bin')])\n# Process file in 1MB chunks\nchunk_size = 1024 * 1024\nfor chunk in reader.read_chunked(chunk_size):\ndata = chunk.read()\nprocess_data(data)\nprint(f\"Processed {len(data)} bytes\")\n</code></pre>"},{"location":"resources/file/#inherited-methods","title":"Inherited Methods","text":"<p>FileReader inherits all methods from MultiPartReader:</p> <ul> <li><code>read(offset, length)</code> - Read as iterator of bytes</li> <li><code>seek(offset, whence)</code> - Seek to position</li> <li><code>seekable()</code> - Check if seekable (always True)</li> </ul> <p>See MultiPartReader documentation for details.</p>"},{"location":"resources/file/#examples","title":"Examples","text":""},{"location":"resources/file/#simple-file-reading","title":"Simple File Reading","text":"<pre><code>from rick.resource.file import FileReader, FilePart\n# Read a single file\nparts = [FilePart('/tmp/document.pdf')]\nreader = FileReader(parts=parts, name='document.pdf', content_type='application/pdf')\n# Read entire file to disk\nwith open('/tmp/copy.pdf', 'wb') as output:\nbuffer = reader.read_block()\nbuffer.seek(0)\noutput.write(buffer.read())\nprint(f\"Copied {reader.size} bytes\")\n</code></pre>"},{"location":"resources/file/#multipart-file-reading","title":"Multipart File Reading","text":"<pre><code>from rick.resource.file import FileReader, FilePart\n# Read file split into multiple parts\nparts = [\nFilePart('/downloads/video.mp4.part1'),\nFilePart('/downloads/video.mp4.part2'),\nFilePart('/downloads/video.mp4.part3'),\n]\nreader = FileReader(\nparts=parts,\nname='video.mp4',\ncontent_type='video/mp4'\n)\n# Combine parts into single file\nwith open('/videos/video.mp4', 'wb') as output:\nfor chunk in reader.read_chunked(1024 * 1024):  # 1MB chunks\noutput.write(chunk.read())\nprint(f\"Reassembled {reader.name}: {reader.size} bytes\")\n</code></pre>"},{"location":"resources/file/#custom-metadata","title":"Custom Metadata","text":"<pre><code>from rick.resource.file import FileReader, FilePart\nparts = [FilePart('/uploads/photo.jpg')]\nreader = FileReader(\nparts=parts,\nname='vacation.jpg',\ncontent_type='image/jpeg',\n# Custom attributes\nupload_timestamp='2024-01-15 10:30:00',\nuser_id=123,\ntags=['vacation', 'beach', 'sunset'],\nmetadata={'camera': 'Canon EOS R5', 'iso': 400}\n)\n# Access custom attributes\nprint(f\"Uploaded: {reader.upload_timestamp}\")\nprint(f\"User: {reader.user_id}\")\nprint(f\"Tags: {', '.join(reader.tags)}\")\nprint(f\"Camera: {reader.metadata['camera']}\")\n</code></pre>"},{"location":"resources/file/#file-upload-processing","title":"File Upload Processing","text":"<pre><code>from rick.resource.file import FileReader, FilePart\nimport hashlib\ndef process_upload(file_parts, filename, content_type):\n\"\"\"Process uploaded file\"\"\"\nreader = FileReader(\nparts=file_parts,\nname=filename,\ncontent_type=content_type\n)\n# Validate file size\nmax_size = 10 * 1024 * 1024  # 10MB\nif reader.size &gt; max_size:\nraise ValueError(f\"File too large: {reader.size} bytes\")\n# Calculate hash while saving\nhasher = hashlib.sha256()\noutput_path = f'/uploads/{filename}'\nwith open(output_path, 'wb') as output:\nfor chunk in reader.read_chunked(64 * 1024):  # 64KB chunks\ndata = chunk.read()\nhasher.update(data)\noutput.write(data)\nreturn {\n'filename': reader.name,\n'size': reader.size,\n'content_type': reader.content_type,\n'sha256': hasher.hexdigest(),\n'path': output_path\n}\n# Example usage\nparts = [FilePart('/tmp/uploaded_file.dat')]\nresult = process_upload(parts, 'document.pdf', 'application/pdf')\nprint(f\"Saved: {result['filename']} ({result['size']} bytes)\")\nprint(f\"SHA256: {result['sha256']}\")\n</code></pre>"},{"location":"resources/file/#chunked-file-transfer","title":"Chunked File Transfer","text":"<pre><code>from rick.resource.file import FileReader, FilePart\ndef transfer_file(source_path, destination, chunk_size=1024 * 1024):\n\"\"\"Transfer file in chunks with progress\"\"\"\nparts = [FilePart(source_path)]\nreader = FileReader(parts=parts)\ntotal_bytes = reader.size\ntransferred = 0\nwith open(destination, 'wb') as output:\nfor chunk in reader.read_chunked(chunk_size):\ndata = chunk.read()\noutput.write(data)\ntransferred += len(data)\n# Progress reporting\nprogress = (transferred / total_bytes) * 100\nprint(f\"\\rProgress: {progress:.1f}%\", end='')\nprint(f\"\\nTransferred {transferred} bytes\")\n# Transfer with 2MB chunks\ntransfer_file('/data/largefile.bin', '/backup/largefile.bin', 2 * 1024 * 1024)\n</code></pre>"},{"location":"resources/file/#file-validation-and-processing","title":"File Validation and Processing","text":"<pre><code>from rick.resource.file import FileReader, FilePart\nfrom rick.crypto import sha256_hash\ndef validate_and_process(file_path, expected_hash):\n\"\"\"Validate file hash and process if valid\"\"\"\nparts = [FilePart(file_path)]\nreader = FileReader(\nparts=parts,\nname=file_path.split('/')[-1]\n)\n# Read entire file and verify hash\nbuffer = reader.read_block()\nbuffer.seek(0)\nactual_hash = sha256_hash(buffer)\nif actual_hash != expected_hash:\nraise ValueError(\nf\"Hash mismatch: expected {expected_hash}, got {actual_hash}\"\n)\n# Process file in chunks\nbuffer.seek(0)  # Reset buffer position\nreader.seek(0)  # Reset reader position\nresults = []\nfor chunk in reader.read_chunked(1024 * 1024):\nresult = process_chunk(chunk)\nresults.append(result)\nreturn results\ndef process_chunk(chunk):\n\"\"\"Process a chunk of data\"\"\"\ndata = chunk.read()\n# Your processing logic here\nreturn len(data)\n# Validate and process\nresults = validate_and_process(\n'/downloads/data.bin',\n'a1b2c3d4e5f6...'  # Expected SHA-256 hash\n)\nprint(f\"Processed {len(results)} chunks\")\n</code></pre>"},{"location":"resources/file/#combining-multiple-files","title":"Combining Multiple Files","text":"<pre><code>from rick.resource.file import FileReader, FilePart\nfrom pathlib import Path\ndef combine_logs(log_directory, output_file):\n\"\"\"Combine multiple log files into one\"\"\"\n# Find all log files\nlog_dir = Path(log_directory)\nlog_files = sorted(log_dir.glob('*.log'))\nif not log_files:\nraise ValueError(\"No log files found\")\n# Create parts\nparts = [FilePart(str(f)) for f in log_files]\n# Create reader\nreader = FileReader(\nparts=parts,\nname=Path(output_file).name,\ncontent_type='text/plain',\nsource_files=[str(f) for f in log_files],\nfile_count=len(log_files)\n)\n# Write combined file\nwith open(output_file, 'wb') as output:\nfor chunk in reader.read_chunked(1024 * 1024):\noutput.write(chunk.read())\nprint(f\"Combined {reader.file_count} files:\")\nfor f in reader.source_files:\nprint(f\"  - {f}\")\nprint(f\"Total size: {reader.size} bytes\")\n# Combine all logs\ncombine_logs('/var/log/myapp', '/tmp/combined.log')\n</code></pre>"},{"location":"resources/file/#archive-extraction-simulation","title":"Archive Extraction Simulation","text":"<pre><code>from rick.resource.file import FileReader, FilePart\ndef process_split_archive(archive_parts, extract_to):\n\"\"\"Process split archive files\"\"\"\n# Archive split into multiple files\nparts = [FilePart(part) for part in archive_parts]\nreader = FileReader(\nparts=parts,\nname='archive.tar.gz',\ncontent_type='application/x-tar',\npart_count=len(parts)\n)\nprint(f\"Processing {reader.part_count}-part archive\")\nprint(f\"Total size: {reader.size} bytes\")\n# Save reassembled archive\narchive_path = f\"{extract_to}/{reader.name}\"\nwith open(archive_path, 'wb') as output:\nbytes_written = 0\nfor chunk in reader.read_chunked(512 * 1024):  # 512KB chunks\ndata = chunk.read()\noutput.write(data)\nbytes_written += len(data)\nprint(f\"Reassembled archive: {archive_path}\")\nreturn archive_path\n# Process split archive\nparts = [\n'/downloads/archive.tar.gz.001',\n'/downloads/archive.tar.gz.002',\n'/downloads/archive.tar.gz.003',\n]\narchive = process_split_archive(parts, '/tmp')\n</code></pre>"},{"location":"resources/file/#streaming-http-upload","title":"Streaming HTTP Upload","text":"<pre><code>from rick.resource.file import FileReader, FilePart\ndef upload_to_server(file_path, url, chunk_size=1024 * 1024):\n\"\"\"Upload file to server in chunks\"\"\"\nparts = [FilePart(file_path)]\nreader = FileReader(\nparts=parts,\nname=file_path.split('/')[-1],\ncontent_type='application/octet-stream'\n)\nprint(f\"Uploading {reader.name} ({reader.size} bytes)\")\nuploaded = 0\nfor chunk in reader.read_chunked(chunk_size):\ndata = chunk.read()\n# Send chunk to server\nresponse = send_chunk_to_server(url, data)\nif response.status_code != 200:\nraise RuntimeError(f\"Upload failed: {response.status_code}\")\nuploaded += len(data)\nprogress = (uploaded / reader.size) * 100\nprint(f\"\\rProgress: {progress:.1f}%\", end='')\nprint(\"\\nUpload complete\")\ndef send_chunk_to_server(url, data):\n\"\"\"Stub for sending data to server\"\"\"\n# Your HTTP upload logic here\npass\n# Upload file\nupload_to_server('/data/video.mp4', 'https://example.com/upload')\n</code></pre>"},{"location":"resources/file/#custom-properties-for-processing-context","title":"Custom Properties for Processing Context","text":"<pre><code>from rick.resource.file import FileReader, FilePart\nfrom datetime import datetime\ndef process_with_context(file_path, **context):\n\"\"\"Process file with additional context\"\"\"\nparts = [FilePart(file_path)]\nreader = FileReader(\nparts=parts,\nname=file_path.split('/')[-1],\ncontent_type='application/octet-stream',\n# Add context as custom properties\n**context\n)\nprint(f\"Processing: {reader.name}\")\nprint(f\"User: {reader.user_name}\")\nprint(f\"Department: {reader.department}\")\nprint(f\"Priority: {reader.priority}\")\n# Process based on context\nif reader.priority == 'high':\nchunk_size = 2 * 1024 * 1024  # 2MB for high priority\nelse:\nchunk_size = 512 * 1024  # 512KB for normal\nfor chunk in reader.read_chunked(chunk_size):\nprocess_chunk_with_context(chunk, reader)\ndef process_chunk_with_context(chunk, reader):\n\"\"\"Process chunk with reader context\"\"\"\ndata = chunk.read()\n# Use reader.user_name, reader.department, etc.\nprint(f\"  Processed {len(data)} bytes for {reader.user_name}\")\n# Process with context\nprocess_with_context(\n'/uploads/report.pdf',\nuser_name='Alice',\ndepartment='Finance',\npriority='high',\ntimestamp=datetime.now().isoformat()\n)\n</code></pre>"},{"location":"resources/file/#performance-considerations","title":"Performance Considerations","text":""},{"location":"resources/file/#memory-efficiency","title":"Memory Efficiency","text":"<p>FileReader uses MultiPartReader internally, providing efficient streaming:</p> <pre><code>from rick.resource.file import FileReader, FilePart\n# Even with a 10GB file, memory usage stays low\nparts = [FilePart('/data/huge_10gb_file.bin')]\nreader = FileReader(parts=parts)\n# Process in 1MB chunks - only 1MB in memory at a time\nwith open('/backup/huge_10gb_file.bin', 'wb') as output:\nfor chunk in reader.read_chunked(1024 * 1024):\noutput.write(chunk.read())\n# Memory usage remains constant\n</code></pre>"},{"location":"resources/file/#chunk-size-selection","title":"Chunk Size Selection","text":"<p>Choose appropriate chunk sizes based on your use case:</p> <pre><code>from rick.resource.file import FileReader, FilePart\nparts = [FilePart('/data/file.bin')]\nreader = FileReader(parts=parts)\n# Small chunks (64KB) - low memory, more overhead\nfor chunk in reader.read_chunked(64 * 1024):\nprocess(chunk)\n# Medium chunks (1MB) - balanced\nfor chunk in reader.read_chunked(1024 * 1024):\nprocess(chunk)\n# Large chunks (10MB) - higher memory, less overhead\nfor chunk in reader.read_chunked(10 * 1024 * 1024):\nprocess(chunk)\n</code></pre>"},{"location":"resources/file/#read_block-vs-read_chunked","title":"read_block() vs read_chunked()","text":"<p>Use <code>read_block()</code> for small files, <code>read_chunked()</code> for large files:</p> <pre><code>from rick.resource.file import FileReader, FilePart\nparts = [FilePart('/data/file.bin')]\nreader = FileReader(parts=parts)\n# Small file - read_block() is fine\nif reader.size &lt; 10 * 1024 * 1024:  # &lt; 10MB\nbuffer = reader.read_block()\nbuffer.seek(0)\nprocess_all(buffer.read())\n# Large file - use read_chunked()\nelse:\nfor chunk in reader.read_chunked(1024 * 1024):\nprocess_chunk(chunk.read())\n</code></pre>"},{"location":"resources/file/#error-handling","title":"Error Handling","text":"<pre><code>from rick.resource.file import FileReader, FilePart\ntry:\n# FilePart validates file exists\nparts = [FilePart('/path/to/nonexistent.txt')]\nexcept ValueError as e:\nprint(f\"File error: {e}\")\ntry:\nparts = [FilePart('/tmp/file.txt')]\n# Reserved names raise ValueError\nreader = FileReader(\nparts=parts,\nname='test.txt',\nsize=100  # 'size' is reserved\n)\nexcept ValueError as e:\nprint(f\"Property error: {e}\")\ntry:\nparts = [FilePart('/tmp/file.txt')]\nreader = FileReader(parts=parts)\n# Seek/read errors from MultiPartReader\nreader.seek(-100)  # Negative offset\nexcept ValueError as e:\nprint(f\"Seek error: {e}\")\n</code></pre>"},{"location":"resources/file/#api-reference","title":"API Reference","text":""},{"location":"resources/file/#filepart_1","title":"FilePart","text":"<p>Alias for FileSlice. See FileSlice API.</p>"},{"location":"resources/file/#filereader_1","title":"FileReader","text":"<p>Inherits from MultiPartReader with additional features.</p>"},{"location":"resources/file/#constructor_1","title":"Constructor","text":"Parameter Type Default Description <code>parts</code> list required List of FilePart/SliceReader objects <code>name</code> str \"\" Filename <code>content_type</code> str \"application/octet-stream\" MIME type <code>**kwargs</code> any - Custom properties to attach"},{"location":"resources/file/#methods_1","title":"Methods","text":"Method Returns Description <code>read_block(offset, limit)</code> BytesIO Read as single buffer <code>read_chunked(block_size)</code> Iterator[BytesIO] Read in fixed-size chunks <code>read(offset, length)</code> Iterator[bytes] Read as iterator (inherited) <code>seek(offset, whence)</code> int Seek to position (inherited) <code>seekable()</code> bool Check if seekable (inherited)"},{"location":"resources/file/#attributes","title":"Attributes","text":"Attribute Type Description <code>name</code> str Filename <code>content_type</code> str MIME type <code>parts</code> list List of file parts <code>size</code> int Total size in bytes <code>offset</code> int Current stream position <code>opened</code> bool Whether stream has been read Custom attrs any User-defined properties from kwargs"},{"location":"resources/file/#see-also","title":"See Also","text":"<ul> <li>Stream Processing - Underlying multipart stream functionality</li> <li>Resources Overview - Overview of all resource utilities</li> <li>Redis Cache - Redis caching with serialization</li> <li>Configuration - Configuration management</li> </ul>"},{"location":"resources/redis/","title":"Redis Cache","text":"<p>Rick provides Redis-based caching implementations with support for custom serialization, encryption, and full Redis client access. The module offers two cache classes: <code>RedisCache</code> for standard caching and <code>CryptRedisCache</code> for encrypted caching of sensitive data.</p> <p>Location: <code>rick.resource.redis</code></p>"},{"location":"resources/redis/#overview","title":"Overview","text":"<p>Redis caching in Rick provides:</p> <ul> <li>Standardized Interface - Implements <code>CacheInterface</code> for consistency</li> <li>Flexible Serialization - Support for pickle, JSON, MessagePack, or custom serializers</li> <li>Encryption Support - Built-in encrypted caching with Fernet256</li> <li>Key Prefixing - Namespace isolation for multiple applications or environments</li> <li>TTL Support - Automatic expiration of cached data</li> <li>Full Client Access - Direct access to underlying Redis client for advanced operations</li> <li>Backend Wrapping - Wrap existing Redis clients with cache interface</li> </ul>"},{"location":"resources/redis/#rediscache","title":"RedisCache","text":"<p>Basic Redis cache implementation with pickle serialization by default.</p> <p>Location: <code>rick.resource.redis.RedisCache</code></p>"},{"location":"resources/redis/#constructor-parameters","title":"Constructor Parameters","text":"<pre><code>RedisCache(**kwargs)\n</code></pre> <p>Redis Connection Parameters:</p> Parameter Type Default Description <code>host</code> str 'localhost' Redis server hostname <code>port</code> int 6379 Redis server port <code>db</code> int 0 Redis database number <code>password</code> str None Redis password <code>socket_timeout</code> float None Socket timeout in seconds <code>socket_connect_timeout</code> float None Connection timeout in seconds <code>socket_keepalive</code> bool None Enable TCP keepalive <code>socket_keepalive_options</code> dict None TCP keepalive options <code>connection_pool</code> ConnectionPool None Custom connection pool <code>unix_socket_path</code> str None Unix socket path <code>encoding</code> str 'utf-8' String encoding <code>encoding_errors</code> str 'strict' Encoding error handling <code>decode_responses</code> bool False Decode responses to strings <code>retry_on_timeout</code> bool False Retry on timeout <code>ssl</code> bool False Enable SSL <code>ssl_keyfile</code> str None SSL key file path <code>ssl_certfile</code> str None SSL certificate file path <code>ssl_cert_reqs</code> str 'required' SSL certificate requirements <code>ssl_ca_certs</code> str None SSL CA certificates path <code>max_connections</code> int None Maximum connections in pool <code>single_connection_client</code> bool False Use single connection <code>health_check_interval</code> int 0 Health check interval in seconds <p>Cache-Specific Parameters:</p> Parameter Type Default Description <code>backend</code> redis.Redis None Wrap existing Redis client <code>serializer</code> callable pickle.dumps Function to serialize values <code>deserializer</code> callable pickle.loads Function to deserialize values <code>prefix</code> str \"\" Key prefix for namespacing"},{"location":"resources/redis/#methods","title":"Methods","text":""},{"location":"resources/redis/#getkey","title":"get(key)","text":"<p>Retrieve a value from the cache.</p> <pre><code>value = cache.get('user:123')\n</code></pre> <p>Parameters:</p> <ul> <li><code>key</code> (str) - Cache key</li> </ul> <p>Returns: Cached value or <code>None</code> if not found</p>"},{"location":"resources/redis/#setkey-value-ttlnone","title":"set(key, value, ttl=None)","text":"<p>Store a value in the cache.</p> <pre><code>cache.set('user:123', user_data, ttl=3600)\n</code></pre> <p>Parameters:</p> <ul> <li><code>key</code> (str) - Cache key</li> <li><code>value</code> (any) - Value to cache (must be serializable)</li> <li><code>ttl</code> (int, optional) - Time-to-live in seconds</li> </ul> <p>Returns: True if successful</p>"},{"location":"resources/redis/#haskey","title":"has(key)","text":"<p>Check if a key exists in the cache.</p> <pre><code>if cache.has('user:123'):\nprint(\"Key exists\")\n</code></pre> <p>Parameters:</p> <ul> <li><code>key</code> (str) - Cache key</li> </ul> <p>Returns: <code>True</code> if key exists, <code>False</code> otherwise</p>"},{"location":"resources/redis/#removekey","title":"remove(key)","text":"<p>Remove a key from the cache.</p> <pre><code>cache.remove('user:123')\n</code></pre> <p>Parameters:</p> <ul> <li><code>key</code> (str) - Cache key</li> </ul> <p>Returns: <code>True</code> if key was removed, <code>False</code> if key didn't exist</p>"},{"location":"resources/redis/#purge","title":"purge()","text":"<p>Clear all keys from the current database.</p> <pre><code>cache.purge()\n</code></pre> <p>Warning: This flushes the entire Redis database. Use with caution.</p> <p>Returns: True if successful</p>"},{"location":"resources/redis/#client","title":"client()","text":"<p>Get the underlying Redis client for advanced operations.</p> <pre><code>redis_client = cache.client()\nredis_client.pipeline()\n</code></pre> <p>Returns: <code>redis.Redis</code> instance</p>"},{"location":"resources/redis/#close","title":"close()","text":"<p>Close the Redis connection.</p> <pre><code>cache.close()\n</code></pre>"},{"location":"resources/redis/#set_prefixprefix","title":"set_prefix(prefix)","text":"<p>Change the key prefix.</p> <pre><code>cache.set_prefix('myapp:prod:')\n</code></pre> <p>Parameters:</p> <ul> <li><code>prefix</code> (str) - New key prefix</li> </ul>"},{"location":"resources/redis/#cryptrediscache","title":"CryptRedisCache","text":"<p>Encrypted Redis cache implementation that extends <code>RedisCache</code> with automatic encryption/decryption using Fernet256.</p> <p>Location: <code>rick.resource.redis.CryptRedisCache</code></p>"},{"location":"resources/redis/#constructor-parameters_1","title":"Constructor Parameters","text":"<pre><code>CryptRedisCache(key, **kwargs)\n</code></pre> <p>Required Parameter:</p> Parameter Type Description <code>key</code> str 64-character encryption key (will be base64 encoded) <p>Additional Parameters: All parameters from <code>RedisCache</code> are supported.</p> <p>Important: The encryption key must be exactly 64 characters long. The key is base64-encoded internally to create a Fernet256 key.</p>"},{"location":"resources/redis/#generating-encryption-keys","title":"Generating Encryption Keys","text":"<pre><code>import secrets\n# Generate a secure 64-character key\nencryption_key = secrets.token_hex(32)  # Generates 64 hex characters\nprint(f\"Key: {encryption_key}\")\n</code></pre>"},{"location":"resources/redis/#methods_1","title":"Methods","text":"<p><code>CryptRedisCache</code> inherits all methods from <code>RedisCache</code>. Values are automatically encrypted on <code>set()</code> and decrypted on <code>get()</code>.</p>"},{"location":"resources/redis/#basic-usage-examples","title":"Basic Usage Examples","text":""},{"location":"resources/redis/#simple-caching","title":"Simple Caching","text":"<pre><code>from rick.resource.redis import RedisCache\n# Create cache instance\ncache = RedisCache(host='localhost', port=6379, db=0)\n# Store value\ncache.set('greeting', 'Hello, World!')\n# Retrieve value\nmessage = cache.get('greeting')\nprint(message)  # Output: Hello, World!\n# Check existence\nif cache.has('greeting'):\nprint(\"Key exists\")\n# Remove key\ncache.remove('greeting')\n# Close connection\ncache.close()\n</code></pre>"},{"location":"resources/redis/#caching-with-ttl","title":"Caching with TTL","text":"<pre><code>from rick.resource.redis import RedisCache\nfrom time import sleep\ncache = RedisCache(host='localhost')\n# Cache with 60-second expiration\ncache.set('temp_data', {'status': 'processing'}, ttl=60)\n# Data is available\nprint(cache.has('temp_data'))  # True\n# Wait for expiration\nsleep(61)\n# Data is gone\nprint(cache.has('temp_data'))  # False\n</code></pre>"},{"location":"resources/redis/#caching-complex-objects","title":"Caching Complex Objects","text":"<pre><code>from rick.resource.redis import RedisCache\nfrom datetime import datetime\nfrom decimal import Decimal\ncache = RedisCache(host='localhost')\n# Cache complex data structures\nuser_data = {\n'id': 123,\n'name': 'John Doe',\n'balance': Decimal('1234.56'),\n'created_at': datetime.now(),\n'preferences': {\n'theme': 'dark',\n'notifications': True\n}\n}\ncache.set('user:123', user_data)\nretrieved = cache.get('user:123')\n# All types are preserved with pickle\nassert isinstance(retrieved['balance'], Decimal)\nassert isinstance(retrieved['created_at'], datetime)\n</code></pre>"},{"location":"resources/redis/#using-key-prefixes","title":"Using Key Prefixes","text":"<pre><code>from rick.resource.redis import RedisCache\n# Create caches with different prefixes\ndev_cache = RedisCache(host='localhost', prefix='dev:')\nprod_cache = RedisCache(host='localhost', prefix='prod:')\n# Same key, different namespaces\ndev_cache.set('config', {'debug': True})\nprod_cache.set('config', {'debug': False})\n# Keys don't conflict\nprint(dev_cache.get('config'))  # {'debug': True}\nprint(prod_cache.get('config'))  # {'debug': False}\n</code></pre>"},{"location":"resources/redis/#encrypted-caching","title":"Encrypted Caching","text":""},{"location":"resources/redis/#basic-encrypted-cache","title":"Basic Encrypted Cache","text":"<pre><code>from rick.resource.redis import CryptRedisCache\n# Create encrypted cache (key must be 64 characters)\ncache = CryptRedisCache(\nkey='0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef',\nhost='localhost',\nport=6379\n)\n# Store sensitive data (automatically encrypted)\ncache.set('api_token', {'token': 'secret123', 'expires': '2025-12-31'})\n# Retrieve (automatically decrypted)\ntoken = cache.get('api_token')\nprint(token)  # {'token': 'secret123', 'expires': '2025-12-31'}\ncache.close()\n</code></pre>"},{"location":"resources/redis/#encrypted-session-storage","title":"Encrypted Session Storage","text":"<pre><code>from rick.resource.redis import CryptRedisCache\nfrom datetime import datetime\nimport secrets\n# Generate encryption key\nENCRYPTION_KEY = secrets.token_hex(32)\n# Create encrypted cache for sessions\nsession_cache = CryptRedisCache(\nkey=ENCRYPTION_KEY,\nhost='localhost',\nprefix='session:'\n)\n# Store session data securely\nsession_id = secrets.token_urlsafe(32)\nsession_data = {\n'user_id': 123,\n'username': 'jdoe',\n'roles': ['user', 'admin'],\n'created_at': datetime.now(),\n'csrf_token': secrets.token_hex(32)\n}\n# Store with 1-hour expiration\nsession_cache.set(session_id, session_data, ttl=3600)\n# Retrieve session\nsession = session_cache.get(session_id)\n# Data is decrypted automatically\nprint(session['username'])  # 'jdoe'\n</code></pre>"},{"location":"resources/redis/#encrypted-api-key-storage","title":"Encrypted API Key Storage","text":"<pre><code>from rick.resource.redis import CryptRedisCache\n# Cache for encrypted API keys\napi_cache = CryptRedisCache(\nkey='your-64-character-key-here-replace-with-actual-key-value-ok',\nhost='localhost',\ndb=1,\nprefix='api:keys:'\n)\n# Store API key securely\napi_cache.set('service:github', {\n'api_key': 'ghp_xxxxxxxxxxxx',\n'api_secret': 'secret_value',\n'rate_limit': 5000\n})\n# Retrieve when needed\ngithub_creds = api_cache.get('service:github')\n</code></pre>"},{"location":"resources/redis/#custom-serialization","title":"Custom Serialization","text":""},{"location":"resources/redis/#using-messagepack","title":"Using MessagePack","text":"<pre><code>from rick.resource.redis import RedisCache\nfrom rick.serializer.msgpack import msgpack\nfrom datetime import datetime\nfrom decimal import Decimal\n# Create cache with MessagePack serialization\ncache = RedisCache(\nhost='localhost',\nserializer=msgpack.packb,\ndeserializer=msgpack.unpackb\n)\n# MessagePack efficiently handles complex types\ndata = {\n'timestamp': datetime.now(),\n'amount': Decimal('999.99'),\n'status': 'active'\n}\ncache.set('transaction:001', data)\nretrieved = cache.get('transaction:001')\n# Types are preserved\nassert isinstance(retrieved['timestamp'], datetime)\nassert isinstance(retrieved['amount'], Decimal)\n</code></pre>"},{"location":"resources/redis/#using-json","title":"Using JSON","text":"<pre><code>from rick.resource.redis import RedisCache\nfrom rick.serializer.json.json import ExtendedJsonEncoder\nimport json\nfrom datetime import datetime\n# JSON serializer for interoperability\ndef json_serializer(obj):\nreturn json.dumps(obj, cls=ExtendedJsonEncoder).encode('utf-8')\ndef json_deserializer(data):\n# Note: JSON deserialization doesn't restore types\nreturn json.loads(data.decode('utf-8'))\ncache = RedisCache(\nhost='localhost',\nserializer=json_serializer,\ndeserializer=json_deserializer\n)\n# Store data (types will be converted to JSON-compatible formats)\ncache.set('data', {\n'timestamp': datetime.now(),  # Becomes ISO string\n'count': 42\n})\nretrieved = cache.get('data')\n# Note: timestamp is now a string, not datetime\n</code></pre>"},{"location":"resources/redis/#custom-serializer","title":"Custom Serializer","text":"<pre><code>from rick.resource.redis import RedisCache\nimport json\nclass CustomSerializer:\n@staticmethod\ndef serialize(obj):\n# Add metadata\nwrapped = {\n'_type': type(obj).__name__,\n'_data': obj\n}\nreturn json.dumps(wrapped).encode('utf-8')\n@staticmethod\ndef deserialize(data):\nwrapped = json.loads(data.decode('utf-8'))\nreturn wrapped['_data']\ncache = RedisCache(\nhost='localhost',\nserializer=CustomSerializer.serialize,\ndeserializer=CustomSerializer.deserialize\n)\ncache.set('custom', {'value': 42})\n</code></pre>"},{"location":"resources/redis/#wrapping-existing-redis-client","title":"Wrapping Existing Redis Client","text":""},{"location":"resources/redis/#basic-wrapping","title":"Basic Wrapping","text":"<pre><code>import redis\nfrom rick.resource.redis import RedisCache\n# Create your own Redis client with custom configuration\nmy_redis = redis.Redis(\nhost='localhost',\nport=6379,\ndb=0,\nmax_connections=50,\nsocket_keepalive=True\n)\n# Wrap with RedisCache interface\ncache = RedisCache(backend=my_redis)\n# Use cache interface\ncache.set('key', 'value')\n# Still have access to raw client\ncache.client().info()\n</code></pre>"},{"location":"resources/redis/#with-connection-pool","title":"With Connection Pool","text":"<pre><code>import redis\nfrom rick.resource.redis import RedisCache\n# Create custom connection pool\npool = redis.ConnectionPool(\nhost='localhost',\nport=6379,\nmax_connections=100,\nsocket_keepalive=True,\nsocket_connect_timeout=5\n)\n# Create Redis client with pool\nredis_client = redis.Redis(connection_pool=pool)\n# Wrap with cache interface\ncache = RedisCache(backend=redis_client)\n</code></pre>"},{"location":"resources/redis/#sentinel-configuration","title":"Sentinel Configuration","text":"<pre><code>import redis\nfrom redis.sentinel import Sentinel\nfrom rick.resource.redis import RedisCache\n# Setup Redis Sentinel\nsentinel = Sentinel([\n('sentinel1', 26379),\n('sentinel2', 26379),\n('sentinel3', 26379)\n], socket_timeout=0.5)\n# Get master client\nmaster = sentinel.master_for('mymaster', socket_timeout=0.5)\n# Wrap with RedisCache\ncache = RedisCache(backend=master)\n</code></pre>"},{"location":"resources/redis/#advanced-usage","title":"Advanced Usage","text":""},{"location":"resources/redis/#pipeline-operations","title":"Pipeline Operations","text":"<pre><code>from rick.resource.redis import RedisCache\ncache = RedisCache(host='localhost')\n# Use pipeline for bulk operations\nclient = cache.client()\npipe = client.pipeline()\n# Queue multiple operations\nfor i in range(100):\npipe.set(f'key:{i}', f'value:{i}')\n# Execute all at once\npipe.execute()\n</code></pre>"},{"location":"resources/redis/#pubsub-with-cache","title":"Pub/Sub with Cache","text":"<pre><code>from rick.resource.redis import RedisCache\ncache = RedisCache(host='localhost')\npubsub = cache.client().pubsub()\n# Subscribe to channel\npubsub.subscribe('notifications')\n# Publish message\ncache.client().publish('notifications', 'New update available')\n# Listen for messages\nfor message in pubsub.listen():\nif message['type'] == 'message':\nprint(f\"Received: {message['data']}\")\n</code></pre>"},{"location":"resources/redis/#cache-statistics","title":"Cache Statistics","text":"<pre><code>from rick.resource.redis import RedisCache\ncache = RedisCache(host='localhost', prefix='myapp:')\n# Get Redis info\ninfo = cache.client().info()\nprint(f\"Used memory: {info['used_memory_human']}\")\nprint(f\"Connected clients: {info['connected_clients']}\")\n# Get key count for namespace\nkeys = cache.client().keys('myapp:*')\nprint(f\"Keys in namespace: {len(keys)}\")\n</code></pre>"},{"location":"resources/redis/#cache-aside-pattern","title":"Cache-Aside Pattern","text":"<pre><code>from rick.resource.redis import RedisCache\ncache = RedisCache(host='localhost')\ndef get_user(user_id):\n\"\"\"Cache-aside pattern implementation\"\"\"\ncache_key = f'user:{user_id}'\n# Try cache first\nuser = cache.get(cache_key)\nif user is None:\n# Cache miss - load from database\nuser = database.load_user(user_id)\nif user is not None:\n# Store in cache for 1 hour\ncache.set(cache_key, user, ttl=3600)\nreturn user\ndef update_user(user_id, user_data):\n\"\"\"Update user and invalidate cache\"\"\"\n# Update database\ndatabase.update_user(user_id, user_data)\n# Invalidate cache\ncache.remove(f'user:{user_id}')\n</code></pre>"},{"location":"resources/redis/#write-through-cache","title":"Write-Through Cache","text":"<pre><code>from rick.resource.redis import RedisCache\ncache = RedisCache(host='localhost')\ndef save_user(user):\n\"\"\"Write-through cache pattern\"\"\"\n# Write to database\ndatabase.save_user(user)\n# Write to cache\ncache.set(f\"user:{user['id']}\", user, ttl=3600)\ndef get_user(user_id):\n\"\"\"Always try cache first\"\"\"\nreturn cache.get(f'user:{user_id}')\n</code></pre>"},{"location":"resources/redis/#rate-limiting","title":"Rate Limiting","text":"<pre><code>from rick.resource.redis import RedisCache\nfrom time import time\ncache = RedisCache(host='localhost')\ndef rate_limit(user_id, max_requests=100, window=60):\n\"\"\"Simple rate limiting with Redis\"\"\"\nkey = f'rate_limit:{user_id}:{int(time() // window)}'\n# Get current count\ncurrent = cache.get(key)\nif current is None:\n# First request in window\ncache.set(key, 1, ttl=window)\nreturn True\nif current &gt;= max_requests:\n# Rate limit exceeded\nreturn False\n# Increment counter\ncache.client().incr(key)\nreturn True\n# Usage\nif rate_limit('user:123', max_requests=10, window=60):\nprocess_request()\nelse:\nraise RateLimitExceeded()\n</code></pre>"},{"location":"resources/redis/#error-handling","title":"Error Handling","text":""},{"location":"resources/redis/#connection-errors","title":"Connection Errors","text":"<pre><code>from rick.resource.redis import RedisCache\nimport redis\ncache = RedisCache(host='localhost', port=6379)\ntry:\ncache.set('key', 'value')\nexcept redis.ConnectionError as e:\nprint(f\"Cannot connect to Redis: {e}\")\n# Fallback to alternative storage or raise\nexcept redis.TimeoutError as e:\nprint(f\"Redis operation timed out: {e}\")\n# Retry or use fallback\n</code></pre>"},{"location":"resources/redis/#serialization-errors","title":"Serialization Errors","text":"<pre><code>from rick.resource.redis import RedisCache\nimport pickle\ncache = RedisCache(host='localhost')\nclass UnserializableObject:\ndef __init__(self):\nself.file_handle = open('/tmp/test', 'w')  # Cannot pickle file handles\ntry:\ncache.set('bad_data', UnserializableObject())\nexcept (pickle.PicklingError, TypeError) as e:\nprint(f\"Cannot serialize object: {e}\")\n</code></pre>"},{"location":"resources/redis/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>from rick.resource.redis import RedisCache\nfrom rick.resource import CacheNull\nimport redis\ndef create_cache():\n\"\"\"Create cache with fallback\"\"\"\ntry:\ncache = RedisCache(host='localhost', port=6379, socket_connect_timeout=2)\n# Test connection\ncache.client().ping()\nreturn cache\nexcept (redis.ConnectionError, redis.TimeoutError):\n# Fallback to null cache (no-op)\nprint(\"Warning: Redis unavailable, using null cache\")\nreturn CacheNull()\n# Use cache (works even if Redis is down)\ncache = create_cache()\ncache.set('key', 'value')  # No-op if Redis unavailable\n</code></pre>"},{"location":"resources/redis/#troubleshooting","title":"Troubleshooting","text":""},{"location":"resources/redis/#connection-issues","title":"Connection Issues","text":"<pre><code># Test Redis connection\nimport redis\ntry:\nclient = redis.Redis(host='localhost', port=6379, socket_connect_timeout=5)\nclient.ping()\nprint(\"Connection successful\")\nexcept redis.ConnectionError:\nprint(\"Cannot connect to Redis\")\n</code></pre>"},{"location":"resources/redis/#memory-issues","title":"Memory Issues","text":"<pre><code># Check memory usage\ncache = RedisCache(host='localhost')\ninfo = cache.client().info('memory')\nprint(f\"Used memory: {info['used_memory_human']}\")\nprint(f\"Peak memory: {info['used_memory_peak_human']}\")\n# Set maxmemory policy in redis.conf:\n# maxmemory 256mb\n# maxmemory-policy allkeys-lru\n</code></pre>"},{"location":"resources/redis/#key-expiration-issues","title":"Key Expiration Issues","text":"<pre><code># Check TTL\ncache = RedisCache(host='localhost')\nttl = cache.client().ttl('mykey')\nif ttl == -1:\nprint(\"Key exists but has no expiration\")\nelif ttl == -2:\nprint(\"Key does not exist\")\nelse:\nprint(f\"Key expires in {ttl} seconds\")\n</code></pre>"},{"location":"resources/redis/#related-topics","title":"Related Topics","text":"<ul> <li>Serializers - Efficient data serialization options</li> <li>Crypto - Encryption utilities used by CryptRedisCache</li> <li>Configuration - Loading Redis configuration from files</li> </ul>"},{"location":"resources/stream/","title":"Stream Processing","text":"<p>Rick provides stream processing utilities for handling multipart data streams with minimal memory usage. The stream module is designed for efficiently reading data from multiple sources (files, memory buffers) as a unified stream with seek support.</p>"},{"location":"resources/stream/#overview","title":"Overview","text":"<p>The stream module includes:</p> <ul> <li>SliceReader - Abstract base class for reading data slices</li> <li>FileSlice - Read file slices from disk</li> <li>BytesIOSlice - Read slices from memory buffers</li> <li>MultiPartReader - Combine multiple slices into a single seekable stream</li> </ul>"},{"location":"resources/stream/#why-multipartreader","title":"Why MultiPartReader?","text":"<p>When working with large files or multipart data, loading everything into memory is inefficient. MultiPartReader allows you to:</p> <ul> <li>Read data from multiple sources as a unified stream</li> <li>Seek to specific positions without loading entire file</li> <li>Process large files with minimal memory footprint</li> <li>Combine file chunks, memory buffers, and other data sources</li> <li>Stream data efficiently for uploads, downloads, or processing</li> </ul>"},{"location":"resources/stream/#slicereader-base-class","title":"SliceReader Base Class","text":"<p><code>SliceReader</code> is the abstract base class for all slice implementations.</p> <pre><code>from rick.resource.stream import SliceReader\nclass SliceReader:\ndef __init__(self, identifier, size: int = 0):\nself.identifier = identifier\nself.size = size\ndef read(self, offset=0, length=-1):\n\"\"\"Read data from slice\n        Args:\n            offset: Starting position (default: 0)\n            length: Number of bytes to read (default: -1 for all)\n        Returns:\n            bytes: Data read from slice\n        \"\"\"\npass\n</code></pre>"},{"location":"resources/stream/#fileslice","title":"FileSlice","text":"<p>Read slices from files on disk.</p>"},{"location":"resources/stream/#basic-usage","title":"Basic Usage","text":"<pre><code>from rick.resource.stream import FileSlice\n# Create a file slice\nfile_slice = FileSlice('/path/to/file.dat')\n# Get file size\nprint(f\"File size: {file_slice.size} bytes\")\n# Read entire file\ndata = file_slice.read()\n# Read first 100 bytes\ndata = file_slice.read(offset=0, length=100)\n# Read 50 bytes starting at position 1000\ndata = file_slice.read(offset=1000, length=50)\n</code></pre>"},{"location":"resources/stream/#constructor","title":"Constructor","text":"<p>FileSlice(file_path: str)</p> <p>Creates a new FileSlice instance.</p> <p>Parameters:</p> <ul> <li><code>file_path</code> (str): Path to the file</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: If file does not exist or is not a regular file</li> </ul> <p>Attributes:</p> <ul> <li><code>identifier</code>: Path object pointing to the file</li> <li><code>size</code>: File size in bytes</li> </ul>"},{"location":"resources/stream/#methods","title":"Methods","text":"<p>read(offset=0, length=-1) -&gt; bytes</p> <p>Read data from the file.</p> <p>Parameters:</p> <ul> <li><code>offset</code> (int): Starting byte position (default: 0)</li> <li><code>length</code> (int): Number of bytes to read (default: -1 for entire file)</li> </ul> <p>Returns:</p> <ul> <li><code>bytes</code>: Data read from file</li> </ul>"},{"location":"resources/stream/#bytesioslice","title":"BytesIOSlice","text":"<p>Read slices from BytesIO memory buffers.</p>"},{"location":"resources/stream/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from io import BytesIO\nfrom rick.resource.stream import BytesIOSlice\n# Create a memory buffer\nbuffer = BytesIO(b\"Hello, World! This is a test.\")\n# Create a BytesIO slice\nbytes_slice = BytesIOSlice(buffer)\n# Get buffer size\nprint(f\"Buffer size: {bytes_slice.size} bytes\")\n# Read entire buffer\ndata = bytes_slice.read()\n# Read first 5 bytes\ndata = bytes_slice.read(offset=0, length=5)  # b\"Hello\"\n# Read bytes 7-12\ndata = bytes_slice.read(offset=7, length=5)  # b\"World\"\n</code></pre>"},{"location":"resources/stream/#constructor_1","title":"Constructor","text":"<p>BytesIOSlice(buf: BytesIO)</p> <p>Creates a new BytesIOSlice instance.</p> <p>Parameters:</p> <ul> <li><code>buf</code> (BytesIO): BytesIO object to wrap</li> </ul> <p>Attributes:</p> <ul> <li><code>identifier</code>: The BytesIO object</li> <li><code>size</code>: Buffer size in bytes</li> </ul>"},{"location":"resources/stream/#methods_1","title":"Methods","text":"<p>read(offset=0, length=-1) -&gt; bytes</p> <p>Read data from the buffer.</p> <p>Parameters:</p> <ul> <li><code>offset</code> (int): Starting byte position (default: 0)</li> <li><code>length</code> (int): Number of bytes to read (default: -1 for entire buffer)</li> </ul> <p>Returns:</p> <ul> <li><code>bytes</code>: Data read from buffer</li> </ul>"},{"location":"resources/stream/#multipartreader","title":"MultiPartReader","text":"<p>Combine multiple slices into a single seekable stream.</p>"},{"location":"resources/stream/#basic-usage_2","title":"Basic Usage","text":"<pre><code>from rick.resource.stream import FileSlice, BytesIOSlice, MultiPartReader\nfrom io import BytesIO\n# Create multiple parts\npart1 = FileSlice('/path/to/file1.dat')\npart2 = BytesIOSlice(BytesIO(b\"Middle section\"))\npart3 = FileSlice('/path/to/file2.dat')\n# Create multipart reader\nreader = MultiPartReader(parts=[part1, part2, part3])\n# Get total size\nprint(f\"Total size: {reader.size} bytes\")\n# Read all data\nfor chunk in reader.read():\nprocess_chunk(chunk)\n# Read specific range (bytes 100-200)\nfor chunk in reader.read(offset=100, length=100):\nprocess_chunk(chunk)\n</code></pre>"},{"location":"resources/stream/#constructor_2","title":"Constructor","text":"<p>MultiPartReader(parts: list = None)</p> <p>Creates a new MultiPartReader instance.</p> <p>Parameters:</p> <ul> <li><code>parts</code> (list): List of SliceReader objects (default: empty list)</li> </ul> <p>Attributes:</p> <ul> <li><code>parts</code>: List of SliceReader objects</li> <li><code>size</code>: Total size of all parts combined</li> <li><code>offset</code>: Current stream position (-1 if not opened)</li> <li><code>opened</code>: Boolean indicating if stream has been read</li> </ul>"},{"location":"resources/stream/#methods_2","title":"Methods","text":""},{"location":"resources/stream/#readoffset-int-none-length-1","title":"read(offset: int = None, length=-1)","text":"<p>Read data from the multipart stream as an iterator.</p> <p>Parameters:</p> <ul> <li><code>offset</code> (int): Starting byte position (default: current offset or 0)</li> <li><code>length</code> (int): Number of bytes to read (default: -1 for all remaining)</li> </ul> <p>Returns:</p> <ul> <li>Iterator yielding <code>bytes</code>: Chunks of data from the stream</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: If offset is negative</li> </ul> <p>Example:</p> <pre><code>reader = MultiPartReader(parts=my_parts)\n# Read entire stream\nfor chunk in reader.read():\noutput.write(chunk)\n# Read 1000 bytes starting at position 500\nfor chunk in reader.read(offset=500, length=1000):\noutput.write(chunk)\n</code></pre>"},{"location":"resources/stream/#seekoffset-int-whence-int-0-int","title":"seek(offset: int, whence: int = 0) -&gt; int","text":"<p>Seek to a position in the stream.</p> <p>Parameters:</p> <ul> <li><code>offset</code> (int): Target byte position</li> <li><code>whence</code> (int): Reference point (only SEEK_SET/0 is supported)</li> </ul> <p>Returns:</p> <ul> <li><code>int</code>: New position in stream</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: If whence is not SEEK_SET or offset is negative</li> </ul> <p>Example:</p> <pre><code>reader = MultiPartReader(parts=my_parts)\n# Seek to byte 1000\nreader.seek(1000)\n# Read from current position\nfor chunk in reader.read():\nprocess_chunk(chunk)\n</code></pre>"},{"location":"resources/stream/#seekable-bool","title":"seekable() -&gt; bool","text":"<p>Check if stream supports seeking.</p> <p>Returns:</p> <ul> <li><code>bool</code>: Always returns True</li> </ul>"},{"location":"resources/stream/#advanced-examples","title":"Advanced Examples","text":""},{"location":"resources/stream/#combining-multiple-files","title":"Combining Multiple Files","text":"<pre><code>from rick.resource.stream import FileSlice, MultiPartReader\n# Create parts for multiple log files\nparts = [\nFileSlice('/var/log/app.log.3'),\nFileSlice('/var/log/app.log.2'),\nFileSlice('/var/log/app.log.1'),\nFileSlice('/var/log/app.log'),\n]\n# Read all logs as single stream\nreader = MultiPartReader(parts=parts)\nwith open('/tmp/combined.log', 'wb') as output:\nfor chunk in reader.read():\noutput.write(chunk)\nprint(f\"Combined {len(parts)} files ({reader.size} bytes)\")\n</code></pre>"},{"location":"resources/stream/#streaming-upload","title":"Streaming Upload","text":"<pre><code>from rick.resource.stream import FileSlice, BytesIOSlice, MultiPartReader\nfrom io import BytesIO\n# Build multipart upload with header, file, and footer\nheader = BytesIOSlice(BytesIO(b\"--boundary\\r\\n\"))\nfile_data = FileSlice('/path/to/upload.jpg')\nfooter = BytesIOSlice(BytesIO(b\"\\r\\n--boundary--\\r\\n\"))\nreader = MultiPartReader(parts=[header, file_data, footer])\n# Stream to server\nfor chunk in reader.read():\nupload_to_server(chunk)\n</code></pre>"},{"location":"resources/stream/#partial-file-processing","title":"Partial File Processing","text":"<pre><code>from rick.resource.stream import FileSlice, MultiPartReader\n# Process specific sections of large file\nlarge_file = FileSlice('/data/largefile.bin')\nreader = MultiPartReader(parts=[large_file])\n# Process first megabyte\nprint(\"Processing header...\")\nfor chunk in reader.read(offset=0, length=1024 * 1024):\nprocess_header(chunk)\n# Seek to middle and process 1MB\nmiddle = reader.size // 2\nreader.seek(middle)\nprint(\"Processing middle section...\")\nfor chunk in reader.read(offset=middle, length=1024 * 1024):\nprocess_data(chunk)\n# Process last megabyte\nend_offset = reader.size - (1024 * 1024)\nreader.seek(end_offset)\nprint(\"Processing footer...\")\nfor chunk in reader.read(offset=end_offset, length=1024 * 1024):\nprocess_footer(chunk)\n</code></pre>"},{"location":"resources/stream/#custom-slice-implementation","title":"Custom Slice Implementation","text":"<pre><code>from rick.resource.stream import SliceReader, MultiPartReader\nclass DatabaseSlice(SliceReader):\n\"\"\"Read data from database BLOB\"\"\"\ndef __init__(self, db_connection, blob_id):\n# Get blob size from database\nsize = db_connection.get_blob_size(blob_id)\nsuper().__init__(blob_id, size=size)\nself.db = db_connection\ndef read(self, offset=0, length=-1):\nif length &lt; 0:\nlength = self.size\n# Read chunk from database\nreturn self.db.read_blob_chunk(\nself.identifier,\noffset,\nlength\n)\n# Use custom slice in MultiPartReader\nblob1 = DatabaseSlice(db, 'blob_001')\nblob2 = DatabaseSlice(db, 'blob_002')\nreader = MultiPartReader(parts=[blob1, blob2])\n# Stream database blobs as single file\nwith open('/tmp/output.dat', 'wb') as f:\nfor chunk in reader.read():\nf.write(chunk)\n</code></pre>"},{"location":"resources/stream/#memory-efficient-file-concatenation","title":"Memory-Efficient File Concatenation","text":"<pre><code>from rick.resource.stream import FileSlice, BytesIOSlice, MultiPartReader\nfrom io import BytesIO\n# Add separator between files\nseparator = BytesIOSlice(BytesIO(b\"\\n---\\n\"))\n# Build parts list with separators\nparts = []\nfiles = ['/tmp/part1.txt', '/tmp/part2.txt', '/tmp/part3.txt']\nfor i, filepath in enumerate(files):\nparts.append(FileSlice(filepath))\nif i &lt; len(files) - 1:\nparts.append(separator)\n# Process as single stream without loading everything in memory\nreader = MultiPartReader(parts=parts)\ntotal_bytes = 0\nwith open('/tmp/combined.txt', 'wb') as output:\nfor chunk in reader.read():\noutput.write(chunk)\ntotal_bytes += len(chunk)\nprint(f\"Concatenated {len(files)} files: {total_bytes} bytes\")\n</code></pre>"},{"location":"resources/stream/#range-request-handling","title":"Range Request Handling","text":"<pre><code>from rick.resource.stream import FileSlice, MultiPartReader\ndef handle_range_request(file_path, range_start, range_end):\n\"\"\"Handle HTTP range request efficiently\"\"\"\nfile_slice = FileSlice(file_path)\nreader = MultiPartReader(parts=[file_slice])\n# Calculate length\nif range_end is None:\nrange_end = reader.size - 1\nlength = range_end - range_start + 1\n# Stream only requested range\nresponse_data = b''\nfor chunk in reader.read(offset=range_start, length=length):\nresponse_data += chunk\nreturn response_data\n# Example: Client requests bytes 1000-1999\ndata = handle_range_request('/videos/movie.mp4', 1000, 1999)\n</code></pre>"},{"location":"resources/stream/#performance-considerations","title":"Performance Considerations","text":""},{"location":"resources/stream/#memory-usage","title":"Memory Usage","text":"<p>MultiPartReader is designed for minimal memory usage:</p> <pre><code>from rick.resource.stream import FileSlice, MultiPartReader\n# These 3 files total 3GB, but we never load more than\n# one chunk into memory at a time\nparts = [\nFileSlice('/data/file1.bin'),  # 1GB\nFileSlice('/data/file2.bin'),  # 1GB\nFileSlice('/data/file3.bin'),  # 1GB\n]\nreader = MultiPartReader(parts=parts)\n# Stream to destination with minimal memory footprint\nwith open('/data/combined.bin', 'wb') as output:\nfor chunk in reader.read():\noutput.write(chunk)\n# Each chunk is typically 8KB-64KB\n# Total memory usage stays constant\n</code></pre>"},{"location":"resources/stream/#seeking-efficiency","title":"Seeking Efficiency","text":"<p>Seeking is efficient as it calculates positions without reading data:</p> <pre><code>from rick.resource.stream import FileSlice, MultiPartReader\nparts = [FileSlice(f'/data/chunk{i}.bin') for i in range(100)]\nreader = MultiPartReader(parts=parts)\n# Seeking is O(n) where n is number of parts\n# No data is read during seek\nreader.seek(1024 * 1024 * 500)  # Seek to 500MB\n# Only reads data from this point forward\nfor chunk in reader.read(length=1024):\nprocess_chunk(chunk)\n</code></pre>"},{"location":"resources/stream/#buffering-strategy","title":"Buffering Strategy","text":"<p>For optimal performance with many small parts, consider buffering:</p> <pre><code>from rick.resource.stream import BytesIOSlice, MultiPartReader\nfrom io import BytesIO\n# Instead of many small parts...\n# BAD: many parts = many read() calls\nparts_bad = [BytesIOSlice(BytesIO(b'x' * 10)) for _ in range(1000)]\n# GOOD: combine small parts into larger buffers\nbuffer = BytesIO()\nfor i in range(1000):\nbuffer.write(b'x' * 10)\nbuffer.seek(0)\nparts_good = [BytesIOSlice(buffer)]\n# Good approach has better performance\nreader = MultiPartReader(parts=parts_good)\n</code></pre>"},{"location":"resources/stream/#common-patterns","title":"Common Patterns","text":""},{"location":"resources/stream/#write-once-read-many","title":"Write Once, Read Many","text":"<pre><code>from rick.resource.stream import FileSlice, MultiPartReader\n# Build multipart stream once\nparts = [FileSlice(f) for f in my_files]\nreader = MultiPartReader(parts=parts)\n# Read multiple times with seeking\nfor iteration in range(3):\nreader.seek(0)  # Reset to beginning\nfor chunk in reader.read():\nprocess_chunk(iteration, chunk)\n</code></pre>"},{"location":"resources/stream/#chunked-processing","title":"Chunked Processing","text":"<pre><code>from rick.resource.stream import FileSlice, MultiPartReader\nCHUNK_SIZE = 1024 * 1024  # 1MB chunks\nfile_slice = FileSlice('/data/large.bin')\nreader = MultiPartReader(parts=[file_slice])\noffset = 0\nwhile offset &lt; reader.size:\nfor chunk in reader.read(offset=offset, length=CHUNK_SIZE):\nprocess_chunk(chunk)\noffset += CHUNK_SIZE\n</code></pre>"},{"location":"resources/stream/#error-handling","title":"Error Handling","text":"<pre><code>from rick.resource.stream import FileSlice, MultiPartReader\ntry:\n# FileSlice validates file exists\nslice1 = FileSlice('/path/to/file.dat')\nexcept ValueError as e:\nprint(f\"File error: {e}\")\ntry:\nreader = MultiPartReader(parts=[slice1])\n# Negative offsets raise ValueError\nreader.seek(-100)\nexcept ValueError as e:\nprint(f\"Seek error: {e}\")\ntry:\n# Only SEEK_SET (0) is supported\nfrom io import SEEK_END\nreader.seek(0, SEEK_END)\nexcept ValueError as e:\nprint(f\"Whence error: {e}\")\n</code></pre>"},{"location":"resources/stream/#api-reference","title":"API Reference","text":""},{"location":"resources/stream/#slicereader","title":"SliceReader","text":"Method Description <code>__init__(identifier, size)</code> Initialize slice with identifier and size <code>read(offset, length)</code> Read data from slice (must be implemented by subclass)"},{"location":"resources/stream/#fileslice_1","title":"FileSlice","text":"Method Description <code>__init__(file_path)</code> Create slice from file path <code>read(offset, length)</code> Read data from file Attribute Type Description <code>identifier</code> Path Path object for the file <code>size</code> int File size in bytes"},{"location":"resources/stream/#bytesioslice_1","title":"BytesIOSlice","text":"Method Description <code>__init__(buf)</code> Create slice from BytesIO buffer <code>read(offset, length)</code> Read data from buffer Attribute Type Description <code>identifier</code> BytesIO The BytesIO buffer <code>size</code> int Buffer size in bytes"},{"location":"resources/stream/#multipartreader_1","title":"MultiPartReader","text":"Method Description <code>__init__(parts)</code> Create reader with list of SliceReader parts <code>read(offset, length)</code> Read data as iterator of chunks <code>seek(offset, whence)</code> Seek to position (SEEK_SET only) <code>seekable()</code> Returns True (seeking is supported) Attribute Type Description <code>parts</code> list List of SliceReader objects <code>size</code> int Total size of all parts <code>offset</code> int Current stream position <code>opened</code> bool Whether stream has been read"},{"location":"resources/stream/#see-also","title":"See Also","text":"<ul> <li>Resources Overview - Overview of all resource utilities</li> <li>Redis Cache - Redis caching with serialization</li> <li>Configuration - Configuration management</li> <li>Serializers - Data serialization formats</li> </ul>"},{"location":"serializers/","title":"Serializers","text":"<p>Rick provides serializers for converting Python objects to and from various data formats. The serializer module offers extended support for complex Python types that standard serializers don't handle natively.</p>"},{"location":"serializers/#overview","title":"Overview","text":"<p>Serializers in Rick extend standard serialization libraries with support for:</p> <ul> <li>datetime.date and datetime.datetime objects</li> <li>decimal.Decimal for precise numeric operations</li> <li>uuid.UUID objects</li> <li>Dataclasses with nested support</li> <li>Custom Python objects with <code>__dict__</code> attributes</li> <li>Memoryview and bytes objects</li> </ul>"},{"location":"serializers/#available-serializers","title":"Available Serializers","text":"<p>Rick currently provides two serializers:</p> <ul> <li>JSON Serializer - Extended JSON encoding with support for Python types</li> <li>MessagePack Serializer - Binary serialization and deserialization with custom type extensions</li> </ul>"},{"location":"serializers/#common-use-cases","title":"Common Use Cases","text":""},{"location":"serializers/#api-responses","title":"API Responses","text":"<pre><code>from rick.serializer.json import ExtendedJsonEncoder\nimport json\ndata = {\n'user_id': uuid.uuid4(),\n'created_at': datetime.datetime.now(),\n'balance': decimal.Decimal('123.45')\n}\n# Serialize for API response\nresponse = json.dumps(data, cls=ExtendedJsonEncoder)\n</code></pre>"},{"location":"serializers/#data-caching","title":"Data Caching","text":"<pre><code>from rick.serializer.msgpack import msgpack\n# Serialize for cache storage\ncached_data = msgpack.packb(complex_object)\n# Deserialize from cache\nrestored_data = msgpack.unpackb(cached_data)\n</code></pre>"},{"location":"serializers/#configuration-with-custom-types","title":"Configuration with Custom Types","text":"<pre><code>from rick.serializer.json import ExtendedJsonEncoder\nimport json\nconfig = {\n'api_key': uuid.uuid4(),\n'timeout': decimal.Decimal('30.5'),\n'last_updated': datetime.datetime.now()\n}\n# Save configuration\nwith open('config.json', 'w') as f:\njson.dump(config, f, cls=ExtendedJsonEncoder, indent=2)\n</code></pre>"},{"location":"serializers/#type-support","title":"Type Support","text":"Type JSON MessagePack datetime.date ISO string Binary extension datetime.datetime ISO string Binary extension decimal.Decimal String String in extension uuid.UUID String 16-byte binary Dataclass Dict Dict with class info Custom objects Dict Dict with reconstruction Memoryview UTF-8 string Binary bytes UTF-8 string Binary"},{"location":"serializers/json/","title":"JSON Serializer","text":"<p>The JSON serializer in Rick extends Python's built-in <code>json</code> module with support for additional Python types commonly used in applications.</p>"},{"location":"serializers/json/#available-encoders","title":"Available Encoders","text":"<p>Rick provides two JSON encoder classes:</p>"},{"location":"serializers/json/#extendedjsonencoder","title":"ExtendedJsonEncoder","text":"<p>A general-purpose JSON encoder that preserves field naming conventions (snake_case).</p> <p>Location: <code>rick.serializer.json.ExtendedJsonEncoder</code></p>"},{"location":"serializers/json/#camelcasejsonencoder","title":"CamelCaseJsonEncoder","text":"<p>A specialized JSON encoder that converts Python snake_case field names to JavaScript-friendly camelCase.</p> <p>Location: <code>rick.serializer.json.CamelCaseJsonEncoder</code></p>"},{"location":"serializers/json/#supported-types","title":"Supported Types","text":"<p>Both encoders support the following Python types:</p> Type Serialization Method <code>datetime.date</code> ISO 8601 format string via <code>isoformat()</code> <code>datetime.datetime</code> ISO 8601 format string via <code>isoformat()</code> <code>decimal.Decimal</code> String representation <code>uuid.UUID</code> String representation Dataclasses Dictionary via <code>dataclasses.asdict()</code> Objects with <code>__html__()</code> String via <code>str(__html__())</code> Objects with <code>asdict()</code> Dictionary via <code>obj.asdict()</code> <code>memoryview</code> UTF-8 decoded string <code>bytes</code> UTF-8 decoded string Objects with <code>__dict__</code> Dictionary via <code>obj.__dict__</code>"},{"location":"serializers/json/#basic-usage","title":"Basic Usage","text":""},{"location":"serializers/json/#using-extendedjsonencoder","title":"Using ExtendedJsonEncoder","text":"<pre><code>import json\nimport datetime\nimport decimal\nimport uuid\nfrom dataclasses import dataclass\nfrom rick.serializer.json.json import ExtendedJsonEncoder\n# Create data with complex types\ndata = {\n'id': uuid.uuid4(),\n'created_at': datetime.datetime.now(),\n'modified_date': datetime.date.today(),\n'price': decimal.Decimal('99.99'),\n'quantity': 5\n}\n# Serialize to JSON string\njson_string = json.dumps(data, cls=ExtendedJsonEncoder)\nprint(json_string)\n# Serialize to file\nwith open('data.json', 'w') as f:\njson.dump(data, f, cls=ExtendedJsonEncoder, indent=2)\n</code></pre> <p>Output:</p> <pre><code>{\n\"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n\"created_at\": \"2025-11-06T10:30:45.123456\",\n\"modified_date\": \"2025-11-06\",\n\"price\": \"99.99\",\n\"quantity\": 5\n}\n</code></pre>"},{"location":"serializers/json/#using-camelcasejsonencoder","title":"Using CamelCaseJsonEncoder","text":"<pre><code>import json\nfrom dataclasses import dataclass\nfrom rick.serializer.json.json import CamelCaseJsonEncoder\n@dataclass\nclass UserProfile:\nuser_id: int\nfirst_name: str\nlast_name: str\nemail_address: str\nis_active: bool\nprofile = UserProfile(\nuser_id=123,\nfirst_name=\"John\",\nlast_name=\"Doe\",\nemail_address=\"john.doe@example.com\",\nis_active=True\n)\n# Convert to camelCase JSON\njson_string = json.dumps(profile, cls=CamelCaseJsonEncoder)\nprint(json_string)\n</code></pre> <p>Output:</p> <pre><code>{\n\"userId\": 123,\n\"firstName\": \"John\",\n\"lastName\": \"Doe\",\n\"emailAddress\": \"john.doe@example.com\",\n\"isActive\": true\n}\n</code></pre>"},{"location":"serializers/json/#working-with-dataclasses","title":"Working with Dataclasses","text":"<p>Both encoders have excellent support for dataclasses:</p> <pre><code>import json\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom rick.serializer.json.json import ExtendedJsonEncoder\n@dataclass\nclass Product:\nproduct_id: int\nname: str\nprice: Decimal\ncreated_at: datetime\n@dataclass\nclass Order:\norder_id: int\nproducts: list[Product]\ntotal: Decimal\n# Create nested dataclass structure\norder = Order(\norder_id=1001,\nproducts=[\nProduct(1, \"Widget\", Decimal(\"19.99\"), datetime.now()),\nProduct(2, \"Gadget\", Decimal(\"29.99\"), datetime.now())\n],\ntotal=Decimal(\"49.98\")\n)\n# Serialize nested dataclasses\nresult = json.dumps(order, cls=ExtendedJsonEncoder, indent=2)\nprint(result)\n</code></pre>"},{"location":"serializers/json/#custom-objects","title":"Custom Objects","text":"<p>The encoder can handle custom objects with <code>__dict__</code> attributes:</p> <pre><code>import json\nfrom datetime import datetime\nfrom rick.serializer.json.json import ExtendedJsonEncoder\nclass CustomObject:\ndef __init__(self, name, created_at):\nself.name = name\nself.created_at = created_at\nself.internal_id = id(self)\nobj = CustomObject(\"test\", datetime.now())\nresult = json.dumps(obj, cls=ExtendedJsonEncoder)\nprint(result)\n</code></pre>"},{"location":"serializers/json/#objects-with-asdict-method","title":"Objects with asdict() Method","text":"<p>If your object implements an <code>asdict()</code> method, the encoder will use it:</p> <pre><code>import json\nfrom rick.serializer.json.json import ExtendedJsonEncoder\nclass CustomSerializable:\ndef __init__(self, value):\nself._value = value\nself._internal = \"hidden\"\ndef asdict(self):\n# Control exactly what gets serialized\nreturn {\n'value': self._value,\n'type': self.__class__.__name__\n}\nobj = CustomSerializable(42)\nresult = json.dumps(obj, cls=ExtendedJsonEncoder)\nprint(result)\n# Output: {\"value\": 42, \"type\": \"CustomSerializable\"}\n</code></pre>"},{"location":"serializers/json/#html-objects","title":"HTML Objects","text":"<p>Objects with <code>__html__()</code> method are serialized via their HTML representation:</p> <pre><code>import json\nfrom rick.serializer.json.json import ExtendedJsonEncoder\nclass HTMLWidget:\ndef __init__(self, content):\nself.content = content\ndef __html__(self):\nreturn f\"&lt;div&gt;{self.content}&lt;/div&gt;\"\nwidget = HTMLWidget(\"Hello World\")\nresult = json.dumps({'widget': widget}, cls=ExtendedJsonEncoder)\nprint(result)\n# Output: {\"widget\": \"&lt;div&gt;Hello World&lt;/div&gt;\"}\n</code></pre>"},{"location":"serializers/json/#working-with-binary-data","title":"Working with Binary Data","text":"<p>Both encoders can handle binary data types:</p> <pre><code>import json\nfrom rick.serializer.json.json import ExtendedJsonEncoder\ndata = {\n'binary': b'Hello, World!',\n'memory': memoryview(b'Memory data')\n}\nresult = json.dumps(data, cls=ExtendedJsonEncoder)\nprint(result)\n# Output: {\"binary\": \"Hello, World!\", \"memory\": \"Memory data\"}\n</code></pre>"},{"location":"serializers/json/#api-response-example","title":"API Response Example","text":"<p>A complete example for building API responses:</p> <pre><code>import json\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom dataclasses import dataclass\nfrom uuid import uuid4\nfrom rick.serializer.json.json import CamelCaseJsonEncoder\n@dataclass\nclass ApiResponse:\nrequest_id: str\ntimestamp: datetime\nsuccess: bool\ndata: dict\nerror_message: str | None = None\ndef create_api_response(data, success=True, error=None):\nresponse = ApiResponse(\nrequest_id=str(uuid4()),\ntimestamp=datetime.now(),\nsuccess=success,\ndata=data,\nerror_message=error\n)\nreturn json.dumps(response, cls=CamelCaseJsonEncoder, indent=2)\n# Success response\nresult = create_api_response({\n'user_count': 150,\n'total_revenue': Decimal('12345.67')\n})\nprint(result)\n</code></pre> <p>Output:</p> <pre><code>{\n\"requestId\": \"550e8400-e29b-41d4-a716-446655440000\",\n\"timestamp\": \"2025-11-06T10:30:45.123456\",\n\"success\": true,\n\"data\": {\n\"userCount\": 150,\n\"totalRevenue\": \"12345.67\"\n},\n\"errorMessage\": null\n}\n</code></pre>"},{"location":"serializers/json/#error-handling","title":"Error Handling","text":"<p>If an object cannot be serialized, the encoder raises a <code>RuntimeError</code>:</p> <pre><code>import json\nfrom rick.serializer.json.json import ExtendedJsonEncoder\nclass UnserializableObject:\n__slots__ = ['value']  # No __dict__\ndef __init__(self, value):\nself.value = value\ntry:\nobj = UnserializableObject(42)\njson.dumps(obj, cls=ExtendedJsonEncoder)\nexcept RuntimeError as e:\nprint(f\"Serialization error: {e}\")\n# Output: Serialization error: cannot serialize type '&lt;class 'UnserializableObject'&gt;' to Json\n</code></pre>"},{"location":"serializers/json/#deserialization-note","title":"Deserialization Note","text":"<p>The Rick JSON encoders handle serialization (Python to JSON) only. For deserialization (JSON to Python), you'll need to:</p> <ol> <li>Use standard <code>json.loads()</code> to get dictionaries</li> <li>Manually convert strings back to complex types (datetime, Decimal, UUID)</li> <li>Reconstruct dataclasses or custom objects as needed</li> </ol> <p>Example deserialization:</p> <pre><code>import json\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom uuid import UUID\njson_string = '{\"id\": \"550e8400-e29b-41d4-a716-446655440000\", \"created_at\": \"2025-11-06T10:30:45.123456\", \"price\": \"99.99\"}'\n# Parse JSON\ndata = json.loads(json_string)\n# Convert back to typed objects\ndata['id'] = UUID(data['id'])\ndata['created_at'] = datetime.fromisoformat(data['created_at'])\ndata['price'] = Decimal(data['price'])\n</code></pre>"},{"location":"serializers/json/#related-topics","title":"Related Topics","text":"<ul> <li>MessagePack Serializer - For binary serialization with bidirectional support</li> <li>Validators - For validating deserialized data</li> <li>Forms - For handling request data with validation</li> </ul>"},{"location":"serializers/msgpack/","title":"MessagePack Serializer","text":"<p>The MessagePack serializer in Rick provides efficient binary serialization with full support for complex Python types. Unlike the JSON serializer, MessagePack supports bidirectional serialization (encoding and decoding) with type preservation.</p> <p>Location: <code>rick.serializer.msgpack</code></p>"},{"location":"serializers/msgpack/#overview","title":"Overview","text":"<p>Rick's MessagePack serializer extends the standard <code>msgpack</code> library with custom extension types for Python-specific objects.</p>"},{"location":"serializers/msgpack/#supported-types","title":"Supported Types","text":"<p>The serializer uses MessagePack extension types to preserve Python object types:</p> Type Extension Code Encoding Method Decoding Method <code>datetime.date</code> EXT_TYPE_DATE (1) ISO format string <code>fromisoformat()</code> <code>datetime.datetime</code> EXT_TYPE_DATETIME (2) ISO format string <code>fromisoformat()</code> <code>decimal.Decimal</code> EXT_TYPE_DECIMAL (3) String representation <code>Decimal()</code> constructor <code>uuid.UUID</code> EXT_TYPE_UUID (4) 16-byte binary <code>UUID(bytes=...)</code> Dataclasses EXT_TYPE_DATACLASS (5) Dict with class info Dynamic reconstruction <code>memoryview</code> EXT_TYPE_MEMORYVIEW (6) Binary bytes <code>memoryview()</code> constructor Custom objects EXT_TYPE_OBJECT (7) Dict with class info Dynamic reconstruction"},{"location":"serializers/msgpack/#api-functions","title":"API Functions","text":""},{"location":"serializers/msgpack/#packb","title":"packb()","text":"<p>Serialize a Python object to MessagePack bytes.</p> <pre><code>from rick.serializer.msgpack import msgpack\ndata = {'key': 'value', 'number': 42}\npacked = msgpack.packb(data)\n</code></pre> <p>Parameters:</p> <ul> <li><code>obj</code> - Object to serialize</li> <li><code>**kwargs</code> - Additional arguments passed to <code>msgpack.packb()</code></li> </ul> <p>Returns: Serialized bytes</p>"},{"location":"serializers/msgpack/#unpackb","title":"unpackb()","text":"<p>Deserialize MessagePack bytes to a Python object.</p> <pre><code>from rick.serializer import msgpack\npacked = b'\\x82\\xa3key\\xa5value\\xa6number*'\ndata = msgpack.unpackb(packed)\n</code></pre> <p>Parameters:</p> <ul> <li><code>packed</code> - Serialized bytes</li> <li><code>**kwargs</code> - Additional arguments passed to <code>msgpack.unpackb()</code></li> </ul> <p>Returns: Deserialized Python object</p>"},{"location":"serializers/msgpack/#pack","title":"pack()","text":"<p>Serialize a Python object to a stream.</p> <pre><code>from rick.serializer import msgpack\nwith open('data.msgpack', 'wb') as f:\nmsgpack.pack({'key': 'value'}, f)\n</code></pre> <p>Parameters:</p> <ul> <li><code>obj</code> - Object to serialize</li> <li><code>stream</code> - File-like object to write to</li> <li><code>**kwargs</code> - Additional arguments passed to <code>msgpack.pack()</code></li> </ul>"},{"location":"serializers/msgpack/#unpack","title":"unpack()","text":"<p>Deserialize a Python object from a stream.</p> <pre><code>from rick.serializer import msgpack\nwith open('data.msgpack', 'rb') as f:\ndata = msgpack.unpack(f)\n</code></pre> <p>Parameters:</p> <ul> <li><code>stream</code> - File-like object to read from</li> <li><code>**kwargs</code> - Additional arguments passed to <code>msgpack.unpack()</code></li> </ul> <p>Returns: Deserialized Python object</p>"},{"location":"serializers/msgpack/#basic-usage-examples","title":"Basic Usage Examples","text":""},{"location":"serializers/msgpack/#simple-data-types","title":"Simple Data Types","text":"<pre><code>from rick.serializer import msgpack\n# Serialize basic types\ndata = {\n'string': 'hello',\n'integer': 42,\n'float': 3.14,\n'boolean': True,\n'list': [1, 2, 3],\n'nested': {'a': 1, 'b': 2}\n}\npacked = msgpack.packb(data)\nrestored = msgpack.unpackb(packed)\nassert data == restored\n</code></pre>"},{"location":"serializers/msgpack/#datetime-objects","title":"DateTime Objects","text":"<pre><code>from datetime import datetime, date\nfrom rick.serializer import msgpack\ndata = {\n'created_at': datetime.now(),\n'birth_date': date(1990, 5, 15),\n'updated_at': datetime(2025, 11, 6, 10, 30, 45)\n}\n# Serialize with datetime preservation\npacked = msgpack.packb(data)\n# Deserialize - datetimes are fully restored\nrestored = msgpack.unpackb(packed)\nassert isinstance(restored['created_at'], datetime)\nassert isinstance(restored['birth_date'], date)\nassert restored['birth_date'] == date(1990, 5, 15)\n</code></pre>"},{"location":"serializers/msgpack/#decimal-numbers","title":"Decimal Numbers","text":"<pre><code>from decimal import Decimal\nfrom rick.serializer import msgpack\n# Financial data requiring precision\ninvoice = {\n'subtotal': Decimal('100.00'),\n'tax_rate': Decimal('0.085'),\n'tax': Decimal('8.50'),\n'total': Decimal('108.50')\n}\npacked = msgpack.packb(invoice)\nrestored = msgpack.unpackb(packed)\n# Decimal precision is preserved\nassert isinstance(restored['total'], Decimal)\nassert restored['total'] == Decimal('108.50')\n</code></pre>"},{"location":"serializers/msgpack/#uuid-objects","title":"UUID Objects","text":"<pre><code>from uuid import uuid4\nfrom rick.serializer import msgpack\ndata = {\n'user_id': uuid4(),\n'session_id': uuid4(),\n'request_id': uuid4()\n}\npacked = msgpack.packb(data)\nrestored = msgpack.unpackb(packed)\n# UUIDs are fully preserved\nassert isinstance(restored['user_id'], uuid.UUID)\nassert restored['user_id'] == data['user_id']\n</code></pre>"},{"location":"serializers/msgpack/#working-with-dataclasses","title":"Working with Dataclasses","text":"<p>The MessagePack serializer provides full dataclass support with automatic reconstruction:</p> <pre><code>from dataclasses import dataclass\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom rick.serializer.msgpack import msgpack\n@dataclass\nclass Product:\nproduct_id: int\nname: str\nprice: Decimal\ncreated_at: datetime\n@dataclass\nclass Order:\norder_id: int\ncustomer_name: str\nproducts: list[Product]\ntotal: Decimal\nordered_at: datetime\n# Create complex nested structure\norder = Order(\norder_id=1001,\ncustomer_name=\"John Doe\",\nproducts=[\nProduct(1, \"Widget\", Decimal(\"19.99\"), datetime.now()),\nProduct(2, \"Gadget\", Decimal(\"29.99\"), datetime.now())\n],\ntotal=Decimal(\"49.98\"),\nordered_at=datetime.now()\n)\n# Serialize\npacked = msgpack.packb(order)\n# Deserialize - full object reconstruction\nrestored = msgpack.unpackb(packed)\n# Type and data are preserved\nassert isinstance(restored, Order)\nassert restored.order_id == 1001\nassert isinstance(restored.products[0], Product)\nassert isinstance(restored.products[0].price, Decimal)\nassert isinstance(restored.products[0].created_at, datetime)\n</code></pre>"},{"location":"serializers/msgpack/#custom-objects","title":"Custom Objects","text":"<p>The serializer can handle custom Python objects:</p> <pre><code>from datetime import datetime\nfrom rick.serializer import msgpack\nclass UserSession:\ndef __init__(self, user_id, username, login_time):\nself.user_id = user_id\nself.username = username\nself.login_time = login_time\nself.active = True\n# Create instance\nsession = UserSession(123, \"jdoe\", datetime.now())\n# Serialize\npacked = msgpack.packb(session)\n# Deserialize - object is reconstructed\nrestored = msgpack.unpackb(packed)\nassert isinstance(restored, UserSession)\nassert restored.user_id == 123\nassert restored.username == \"jdoe\"\nassert isinstance(restored.login_time, datetime)\n</code></pre> <p>Important: For custom objects to be reconstructable:</p> <ol> <li>The class must be importable from the same module path</li> <li>The class should have a no-argument <code>__new__()</code> method (most classes do)</li> <li>Instance variables are restored via <code>setattr()</code></li> </ol>"},{"location":"serializers/msgpack/#file-io-operations","title":"File I/O Operations","text":""},{"location":"serializers/msgpack/#writing-to-files","title":"Writing to Files","text":"<pre><code>from rick.serializer import msgpack\nfrom datetime import datetime\ndata = {\n'version': '1.0',\n'created': datetime.now(),\n'records': [\n{'id': 1, 'value': 'first'},\n{'id': 2, 'value': 'second'}\n]\n}\n# Write to file\nwith open('data.msgpack', 'wb') as f:\nmsgpack.pack(data, f)\n</code></pre>"},{"location":"serializers/msgpack/#reading-from-files","title":"Reading from Files","text":"<pre><code>from rick.serializer.msgpack import msgpack\n# Read from file\nwith open('data.msgpack', 'rb') as f:\ndata = msgpack.unpack(f)\nprint(data['version'])\nprint(data['created'])\n</code></pre>"},{"location":"serializers/msgpack/#caching-example","title":"Caching Example","text":"<p>MessagePack is ideal for caching due to its compact size and speed:</p> <pre><code>from rick.serializer import msgpack\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\nfrom dataclasses import dataclass\n@dataclass\nclass CacheEntry:\nkey: str\nvalue: dict\ncreated_at: datetime\nexpires_at: datetime\nclass Cache:\ndef __init__(self):\nself.storage = {}\ndef set(self, key, value, ttl_seconds=3600):\nnow = datetime.now()\nentry = CacheEntry(\nkey=key,\nvalue=value,\ncreated_at=now,\nexpires_at=now + timedelta(seconds=ttl_seconds)\n)\n# Serialize to bytes for storage\nself.storage[key] = msgpack.packb(entry)\ndef get(self, key):\nif key not in self.storage:\nreturn None\n# Deserialize from bytes\nentry = msgpack.unpackb(self.storage[key])\n# Check expiration\nif datetime.now() &gt; entry.expires_at:\ndel self.storage[key]\nreturn None\nreturn entry.value\n# Usage\ncache = Cache()\ncache.set('user:123', {\n'name': 'John Doe',\n'balance': Decimal('1000.50'),\n'last_login': datetime.now()\n})\nuser_data = cache.get('user:123')\n</code></pre>"},{"location":"serializers/msgpack/#error-handling","title":"Error Handling","text":""},{"location":"serializers/msgpack/#serialization-errors","title":"Serialization Errors","text":"<p>If an object type is not supported, a <code>TypeError</code> is raised:</p> <pre><code>from rick.serializer import msgpack\nclass UnsupportedType:\n__slots__ = []  # No __dict__ and not a dataclass\ntry:\nmsgpack.packb(UnsupportedType())\nexcept TypeError as e:\nprint(f\"Cannot serialize: {e}\")\n# Output: Cannot serialize: Unknown type: &lt;class 'UnsupportedType'&gt;\n</code></pre>"},{"location":"serializers/msgpack/#deserialization-errors","title":"Deserialization Errors","text":"<p>If a dataclass or custom object cannot be reconstructed, the serializer falls back to returning a dictionary with error information:</p> <pre><code>from dataclasses import dataclass\nfrom rick.serializer import msgpack\n@dataclass\nclass OriginalClass:\nvalue: int\n# Serialize\ndata = OriginalClass(42)\npacked = msgpack.packb(data)\n# Simulate class no longer available (rename it)\nOriginalClass.__name__ = \"RenamedClass\"\n# Deserialize - reconstruction fails, returns dict\nrestored = msgpack.unpackb(packed)\n# Check for reconstruction error\nif isinstance(restored, dict) and '__reconstruction_error__' in restored:\nprint(f\"Reconstruction failed: {restored['__reconstruction_error__']}\")\nprint(f\"Original class: {restored['__dataclass__']}\")\nprint(f\"Data: {restored['value']}\")\n</code></pre>"},{"location":"serializers/msgpack/#performance-comparison","title":"Performance Comparison","text":"<p>Comparing MessagePack to JSON serialization:</p> <pre><code>import json\nimport time\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom rick.serializer.json.json import ExtendedJsonEncoder\nfrom rick.serializer import msgpack\n# Create test data\ndata = {\n'records': [\n{\n'id': i,\n'timestamp': datetime.now(),\n'value': Decimal(f'{i}.99'),\n'active': True\n}\nfor i in range(1000)\n]\n}\n# JSON serialization\nstart = time.time()\njson_data = json.dumps(data, cls=ExtendedJsonEncoder)\njson_time = time.time() - start\njson_size = len(json_data)\n# MessagePack serialization\nstart = time.time()\nmsgpack_data = msgpack.packb(data)\nmsgpack_time = time.time() - start\nmsgpack_size = len(msgpack_data)\nprint(f\"JSON: {json_size} bytes in {json_time:.4f}s\")\nprint(f\"MessagePack: {msgpack_size} bytes in {msgpack_time:.4f}s\")\nprint(f\"Size reduction: {(1 - msgpack_size / json_size) * 100:.1f}%\")\nprint(f\"Speed improvement: {(json_time / msgpack_time):.2f}x faster\")\n</code></pre> <p>Typical results:</p> <ul> <li>MessagePack is 30-50% smaller</li> <li>MessagePack is 2-4x faster for serialization</li> <li>MessagePack is 3-5x faster for deserialization</li> </ul>"},{"location":"serializers/msgpack/#binary-data-handling","title":"Binary Data Handling","text":"<pre><code>from rick.serializer import msgpack\ndata = {\n'filename': 'image.png',\n'content': b'\\x89PNG\\r\\n\\x1a\\n...',  # Binary image data\n'view': memoryview(b'Memory buffer data')\n}\n# Binary data is efficiently stored\npacked = msgpack.packb(data)\nrestored = msgpack.unpackb(packed)\nassert isinstance(restored['content'], bytes)\nassert isinstance(restored['view'], memoryview)\n</code></pre>"},{"location":"serializers/msgpack/#how-to-handle-reconstruction-failures","title":"How to handle Reconstruction Failures","text":"<pre><code>from rick.serializer.msgpack import msgpack\ndef safe_unpack(packed_data):\nresult = msgpack.unpackb(packed_data)\n# Check if reconstruction failed\nif isinstance(result, dict):\nif '__reconstruction_error__' in result:\nprint(f\"Warning: Could not reconstruct {result.get('__dataclass__', result.get('__object__'))}\")\n# Handle gracefully - use dict representation\nreturn result\nreturn result\n</code></pre>"},{"location":"serializers/msgpack/#security-considerations","title":"Security Considerations","text":"<p>When deserializing MessagePack data:</p> <ol> <li> <p>Code Execution Risk: The serializer dynamically imports modules and creates objects. Only deserialize data from    trusted sources.</p> </li> <li> <p>Module Imports: Dataclass and object reconstruction requires importing the original class. Ensure the module is    available and safe.</p> </li> </ol>"},{"location":"serializers/msgpack/#limitations","title":"Limitations","text":"<ol> <li>Class Availability: Custom classes and dataclasses must be importable at deserialization time</li> <li>Circular References: Not supported (like standard JSON)</li> <li>Class Evolution: Changing a dataclass structure may cause deserialization issues</li> <li>Module Paths: Class module paths must remain consistent</li> </ol>"},{"location":"serializers/msgpack/#related-topics","title":"Related Topics","text":"<ul> <li>JSON Serializer - For human-readable serialization</li> <li>Redis Cache - Uses serialization for caching</li> <li>Forms - For handling and validating incoming data</li> </ul>"},{"location":"validators/","title":"Validators","text":"<p>Rick validators is a registry-based reusable approach to validation operations. It implements a programmatic approach of validating a dictionary of fields and values against a predefined validation specification. This specification can either  be in dictionary format (suitable when specs are read from external sources, such as JSON), or in compact format, a string-based format based on PHP Laravel's validator specification, suitable for inline or programmatic usage.</p>"},{"location":"validators/#tldr-example","title":"TL;DR; Example","text":"<pre><code>from rick.validator import Validator\n# a compact spec example\nspec_compact = {\n'field1': 'required|maxlen:3',  # field is required, maximum length is 3\n'field2': 'minlen:4', # field is optional, minimum length is 4\n'field3': 'required|numeric|len:2,4' # field is required, must be digits, with a length between 2 and 4\n}\n# a dict spec example\nspec_dict = {\n'field1': {\n'required': None,\n'maxlen': 3,\n},\n'field2': {\n'minlen': 4,\n},\n'field3': {\n'required': None,\n'numeric': None,\n'len': [2, 4],\n}\n}\n# field data dict to perform validation on\nfields_values = {\n'field1': 'abc',\n'field2': 'def',\n'field3': 12345\n}\n# validate compact notation\nv = Validator(spec_compact)\n# perform validation, should return False with errors in field2 and field3\nvalid = v.is_valid(fields_values)\n#\n# console output:\n# False {'field2': {'minlen': 'minimum allowed length is 4'}, 'field3': {'len': 'length must be between [2, 4]'}}\nprint(valid, v.get_errors())\n# validate with dict notation\nv = Validator(spec_dict)\n# perform validation, should return False with errors in field2 and field3\nvalid = v.is_valid(fields_values)\n#\n# console output:\n# False {'field2': {'minlen': 'minimum allowed length is 4'}, 'field3': {'len': 'length must be between [2, 4]'}}\nprint(valid, v.get_errors())\n# retrieve errors for specific fields\n#\n# console output: {'minlen': 'minimum allowed length is 4'}\nprint(v.get_errors('field2'))\n#\n# console output: {'len': 'length must be between [2, 4]'}\nprint(v.get_errors('field3'))\n# Simulate optional field - remove field2 from value dictionary\n# the validation result should fail, but without any error for field2, because its absent\nfields_values.pop('field2')\nvalid = v.is_valid(fields_values)\n#\n# console output:\n# False {'field3': {'len': 'length must be between [2, 4]'}}\nprint(valid, v.get_errors())\n</code></pre>"},{"location":"validators/#specification-dict-format","title":"Specification: Dict format","text":"<p>The dict format spectification is a 2-level dictionary, where the first level keys are field names, and the second level keys are validator names and optional parameters.</p> <p>Example of a dict format specification with 2 validators, one of them (len) with validator parameters: <pre><code>spec = {\n'field_name': {\n'required': None,\n'len':[2,4]\n}\n}\n</code></pre></p>"},{"location":"validators/#specification-compact-format","title":"Specification: Compact format","text":"<p>The compact format specification is a string with one or several validator names concatenated with '|'. Some validators require one or more parameters; these are specified as a comma-separared list after a ':' following the validator name.</p> <p>Example of a compact format specification with 2 validators, one of them (len) with validator parameters: <pre><code>spec = {\n'field_name': 'required|len:2,4'\n}\n</code></pre></p>"},{"location":"validators/#available-validators","title":"Available validators","text":"<p>The complete list of available validators is available here.</p>"},{"location":"validators/#optional-fields-and-aborting-on-first-fail","title":"Optional fields and aborting on first fail","text":""},{"location":"validators/#chaining-validators","title":"Chaining validators","text":""},{"location":"validators/#validator-class","title":"Validator Class","text":""},{"location":"validators/#adding-custom-validators","title":"Adding custom Validators","text":""},{"location":"validators/validator_list/","title":"Available validators","text":""},{"location":"validators/validator_list/#general-validators","title":"General Validators","text":"Name Parameters Description required Value is required bail Special validator to skip running all validators on failure id Value must be a positive numeric greater than 0 uuid Value must be a valid UUID notempty Value must not be empty in list,of,values... Value must be in the specified list of values notin list,of,values... Value must not be in the specified list of values strin list,of,values... Value is a string and must be in the specified list of values strnotin list,of,values... Value is a string and must not be in the specified list of values bool Value must be a valid bool representation: 0, 1, y, t, true, n, f, false iso8601 Value must be a valid iso8601 date string"},{"location":"validators/validator_list/#string-validators","title":"String Validators","text":"Name Parameters Description alpha Value must contain only letters a-z and A-Z alphanum Value must contain only letters a-z and A-Z or digits 0-9 slug Value must be an alphanum string, but that can contain '-' and '_' len min,max Value char length must be between min and max minlen min Value char length must be at least min chars maxlen max Value char length must be upto max chars"},{"location":"validators/validator_list/#list-validators","title":"List Validators","text":"Name Parameters Description list Value must be a list of items listlen min[, max]] Item list must have at least min elements and optionally max elements idlist Value must be a list of ids (positive numeric greater than 0)"},{"location":"validators/validator_list/#numeric-validators","title":"Numeric Validators","text":"Name Parameters Description between min,max Value must be numeric between min and max; Floats are supported numeric Value must be a numeral (digits only) decimal Value must be a valid decimal numeral int Value must be a valid integer"},{"location":"validators/validator_list/#network-validators","title":"Network Validators","text":"Name Parameters Description ipv4 Value must be a valid IPv4 address ipv6 Value must be a valid IPv6 address ip Value must be a valid IPv4 or IPv6 address fqdn Value must be a valid fqdn (fully qualified domain name) email Value must be a valid email address mac Value must be a valid MAC address"},{"location":"validators/validator_list/#hash-validators","title":"Hash Validators","text":"Name Parameters Description md5 Value must be a valid MD5 hash sha1 Value must be a valid SHA1 hash sha256 Value must be a valid SHA256 hash sha512 Value must be a valid SHA512 hash"}]}